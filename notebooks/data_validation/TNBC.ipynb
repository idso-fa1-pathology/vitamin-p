{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e3c4d4c-616d-4489-82b8-620f5ff1add2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Working directory: /rsrch9/home/plm/idso_fa1_pathology/codes/yshokrollahi/vitamin-p-latest\n"
     ]
    }
   ],
   "source": [
    "# ALWAYS RUN THIS FIRST!\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "NOTEBOOK_DIR = Path(\"/rsrch9/home/plm/idso_fa1_pathology/codes/yshokrollahi/vitamin-p-latest\")\n",
    "os.chdir(NOTEBOOK_DIR)\n",
    "sys.path.insert(0, str(NOTEBOOK_DIR))\n",
    "\n",
    "print(f\"‚úÖ Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fabad766-f558-4487-a266-aa1760093422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üî¨ TNBC Dataset ‚Üí Zarr with Train/Val/Test Split\n",
      "======================================================================\n",
      "\n",
      "üìä Found 11 slides: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "\n",
      "üìÇ Split Configuration:\n",
      "   Training:   Slides [1, 2, 3, 4, 5, 6, 7] -> tnbc_train/\n",
      "   Validation: Slides [8, 9] -> tnbc_val/\n",
      "   Testing:    Slides [10, 11] -> tnbc_test/\n",
      "\n",
      "   Patch size: 512x512\n",
      "   Output: /rsrch9/home/plm/idso_fa1_pathology/TIER2/yasin-vitaminp/tnbc/zarr_data\n",
      "\n",
      "üìÇ Processing Slide_01 (7 images) -> tnbc_train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Slide_01: 7 patches, 156 nuclei instances\n",
      "\n",
      "üìÇ Processing Slide_02 (3 images) -> tnbc_train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Slide_02: 3 patches, 97 nuclei instances\n",
      "\n",
      "üìÇ Processing Slide_03 (5 images) -> tnbc_train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Slide_03: 5 patches, 103 nuclei instances\n",
      "\n",
      "üìÇ Processing Slide_04 (8 images) -> tnbc_train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Slide_04: 8 patches, 187 nuclei instances\n",
      "\n",
      "üìÇ Processing Slide_05 (4 images) -> tnbc_train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Slide_05: 4 patches, 150 nuclei instances\n",
      "\n",
      "üìÇ Processing Slide_06 (3 images) -> tnbc_train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Slide_06: 3 patches, 97 nuclei instances\n",
      "\n",
      "üìÇ Processing Slide_07 (3 images) -> tnbc_train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Slide_07: 3 patches, 298 nuclei instances\n",
      "\n",
      "üìÇ Processing Slide_08 (4 images) -> tnbc_val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Slide_08: 4 patches, 133 nuclei instances\n",
      "\n",
      "üìÇ Processing Slide_09 (6 images) -> tnbc_val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Slide_09: 6 patches, 78 nuclei instances\n",
      "\n",
      "üìÇ Processing Slide_10 (4 images) -> tnbc_test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Slide_10: 4 patches, 191 nuclei instances\n",
      "\n",
      "üìÇ Processing Slide_11 (3 images) -> tnbc_test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Slide_11: 3 patches, 140 nuclei instances\n",
      "\n",
      "======================================================================\n",
      "‚úÖ PROCESSING COMPLETE\n",
      "======================================================================\n",
      "Total slides processed: 11\n",
      "Total patches created: 50\n",
      "Total nuclei instances: 1630\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìä Per-Split Statistics:\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "TNBC_TRAIN:\n",
      "   Slides: [1, 2, 3, 4, 5, 6, 7]\n",
      "   Total patches: 33\n",
      "   Total nuclei: 1088\n",
      "   Avg nuclei/patch: 33.0\n",
      "\n",
      "TNBC_VAL:\n",
      "   Slides: [8, 9]\n",
      "   Total patches: 10\n",
      "   Total nuclei: 211\n",
      "   Avg nuclei/patch: 21.1\n",
      "\n",
      "TNBC_TEST:\n",
      "   Slides: [10, 11]\n",
      "   Total patches: 7\n",
      "   Total nuclei: 331\n",
      "   Avg nuclei/patch: 47.3\n",
      "\n",
      "======================================================================\n",
      "Output directory: /rsrch9/home/plm/idso_fa1_pathology/TIER2/yasin-vitaminp/tnbc/zarr_data\n",
      "======================================================================\n",
      "\n",
      "üìä Output Structure:\n",
      "   tnbc_train/\n",
      "      ‚îî‚îÄ‚îÄ Slide_01/\n",
      "      ‚îî‚îÄ‚îÄ Slide_02/\n",
      "      ‚îî‚îÄ‚îÄ Slide_03/\n",
      "      ‚îî‚îÄ‚îÄ Slide_04/\n",
      "      ‚îî‚îÄ‚îÄ Slide_05/\n",
      "      ‚îî‚îÄ‚îÄ Slide_06/\n",
      "      ‚îî‚îÄ‚îÄ Slide_07/\n",
      "   tnbc_val/\n",
      "      ‚îî‚îÄ‚îÄ Slide_08/\n",
      "      ‚îî‚îÄ‚îÄ Slide_09/\n",
      "   tnbc_test/\n",
      "      ‚îî‚îÄ‚îÄ Slide_10/\n",
      "      ‚îî‚îÄ‚îÄ Slide_11/\n",
      "\n",
      "üìÑ Split info saved to: /rsrch9/home/plm/idso_fa1_pathology/TIER2/yasin-vitaminp/tnbc/zarr_data/split_info.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import zarr\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from tqdm import tqdm\n",
    "import numcodecs\n",
    "from scipy import ndimage\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "BASE_PATH = Path(\"/rsrch9/home/plm/idso_fa1_pathology/TIER1/yasin-vitaminp/public-datasets/TNBC\")\n",
    "OUTPUT_BASE = Path(\"/rsrch9/home/plm/idso_fa1_pathology/TIER2/yasin-vitaminp/tnbc/zarr_data\")\n",
    "\n",
    "# Split configuration\n",
    "TRAIN_SLIDES = [1, 2, 3, 4, 5, 6, 7]  # 7 patients for training\n",
    "VAL_SLIDES = [8, 9]                    # 2 patients for validation\n",
    "TEST_SLIDES = [10, 11]                 # 2 patients for testing\n",
    "\n",
    "PATCH_SIZE = 512\n",
    "NUM_WORKERS = 16\n",
    "cv2.setNumThreads(0)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 1. Convert Binary Mask to Instance Mask\n",
    "# ---------------------------------------------------------------------\n",
    "def binary_to_instance_mask(binary_mask):\n",
    "    \"\"\"\n",
    "    Convert binary mask (0=background, 255=nuclei) to instance mask.\n",
    "    Uses connected components to assign unique ID to each nucleus.\n",
    "    \"\"\"\n",
    "    # Ensure binary format\n",
    "    binary = (binary_mask > 127).astype(np.uint8)\n",
    "    \n",
    "    # Label connected components (each nucleus gets unique ID)\n",
    "    instance_mask, num_instances = ndimage.label(binary)\n",
    "    \n",
    "    return instance_mask.astype(np.int32)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2. Padding Logic\n",
    "# ---------------------------------------------------------------------\n",
    "def pad_to_512_multiple(img):\n",
    "    \"\"\"Pad image/mask to be evenly divisible by 512\"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    target_h = max(int(np.ceil(h / PATCH_SIZE) * PATCH_SIZE), PATCH_SIZE)\n",
    "    target_w = max(int(np.ceil(w / PATCH_SIZE) * PATCH_SIZE), PATCH_SIZE)\n",
    "    \n",
    "    pad_h, pad_w = target_h - h, target_w - w\n",
    "    if pad_h == 0 and pad_w == 0:\n",
    "        return img\n",
    "    \n",
    "    # Handle both 2D (mask) and 3D (image) arrays\n",
    "    if img.ndim == 3:\n",
    "        padding = ((0, pad_h), (0, pad_w), (0, 0))\n",
    "    else:\n",
    "        padding = ((0, pad_h), (0, pad_w))\n",
    "    \n",
    "    return np.pad(img, padding, mode='constant', constant_values=0)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 3. Worker Function - Process Single Image Pair\n",
    "# ---------------------------------------------------------------------\n",
    "def process_image_pair(args):\n",
    "    \"\"\"\n",
    "    Process one image+mask pair:\n",
    "    1. Load image and GT mask\n",
    "    2. Convert binary mask to instance mask\n",
    "    3. Pad to 512 multiples\n",
    "    4. Extract 512x512 patches\n",
    "    5. Return patches (will be aggregated per slide later)\n",
    "    \"\"\"\n",
    "    img_path, gt_path, patch_name = args\n",
    "    \n",
    "    try:\n",
    "        # --- A. Load Image ---\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            print(f\"‚ö†Ô∏è  Cannot read image: {img_path}\")\n",
    "            return None\n",
    "        \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        h_img, w_img = img.shape[:2]\n",
    "        \n",
    "        # --- B. Load GT Mask ---\n",
    "        gt_mask = cv2.imread(str(gt_path), cv2.IMREAD_GRAYSCALE)\n",
    "        if gt_mask is None:\n",
    "            print(f\"‚ö†Ô∏è  Cannot read GT mask: {gt_path}\")\n",
    "            return None\n",
    "        \n",
    "        # --- C. Convert Binary to Instance Mask ---\n",
    "        instance_mask = binary_to_instance_mask(gt_mask)\n",
    "        \n",
    "        # --- D. Pad to 512 Multiples ---\n",
    "        img_padded = pad_to_512_multiple(img)\n",
    "        mask_padded = pad_to_512_multiple(instance_mask)\n",
    "        h_pad, w_pad = img_padded.shape[:2]\n",
    "        \n",
    "        # --- E. Extract 512x512 Patches ---\n",
    "        img_stack, mask_stack, metadata_list = [], [], []\n",
    "        \n",
    "        for y in range(0, h_pad, PATCH_SIZE):\n",
    "            for x in range(0, w_pad, PATCH_SIZE):\n",
    "                crop_img = img_padded[y:y+PATCH_SIZE, x:x+PATCH_SIZE]\n",
    "                crop_mask = mask_padded[y:y+PATCH_SIZE, x:x+PATCH_SIZE]\n",
    "                \n",
    "                # Ensure full 512x512 patch\n",
    "                if crop_img.shape[0] == PATCH_SIZE and crop_img.shape[1] == PATCH_SIZE:\n",
    "                    img_stack.append(crop_img)\n",
    "                    mask_stack.append(crop_mask)\n",
    "                    metadata_list.append({\n",
    "                        'original_file': patch_name,\n",
    "                        'x': x,\n",
    "                        'y': y,\n",
    "                        'original_height': h_img,\n",
    "                        'original_width': w_img\n",
    "                    })\n",
    "        \n",
    "        if not img_stack:\n",
    "            print(f\"‚ö†Ô∏è  No patches extracted for {patch_name}\")\n",
    "            return None\n",
    "        \n",
    "        return {\n",
    "            'patch_name': patch_name,\n",
    "            'images': np.stack(img_stack, axis=0),\n",
    "            'masks': np.stack(mask_stack, axis=0),\n",
    "            'metadata': metadata_list\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing {patch_name}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 4. Process Single Slide and Determine Split\n",
    "# ---------------------------------------------------------------------\n",
    "def process_slide(slide_num):\n",
    "    \"\"\"\n",
    "    Process all images for a single slide (e.g., Slide_01 with GT_01).\n",
    "    Aggregates all patches from that slide into single zarr arrays.\n",
    "    Determines which split (train/val/test) this slide belongs to.\n",
    "    \"\"\"\n",
    "    slide_name = f\"Slide_{slide_num:02d}\"\n",
    "    gt_name = f\"GT_{slide_num:02d}\"\n",
    "    \n",
    "    slide_dir = BASE_PATH / slide_name\n",
    "    gt_dir = BASE_PATH / gt_name\n",
    "    \n",
    "    if not slide_dir.exists() or not gt_dir.exists():\n",
    "        print(f\"‚ö†Ô∏è  Skipping {slide_name}: directory not found\")\n",
    "        return 0, 0\n",
    "    \n",
    "    # Determine which split this slide belongs to\n",
    "    if slide_num in TRAIN_SLIDES:\n",
    "        split_name = \"tnbc_train\"\n",
    "    elif slide_num in VAL_SLIDES:\n",
    "        split_name = \"tnbc_val\"\n",
    "    elif slide_num in TEST_SLIDES:\n",
    "        split_name = \"tnbc_test\"\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Slide {slide_num} not assigned to any split!\")\n",
    "        return 0, 0\n",
    "    \n",
    "    # Find all image files in the slide\n",
    "    img_files = sorted(slide_dir.glob(\"*.png\"))\n",
    "    \n",
    "    if not img_files:\n",
    "        print(f\"‚ö†Ô∏è  No images found in {slide_name}\")\n",
    "        return 0, 0\n",
    "    \n",
    "    print(f\"\\nüìÇ Processing {slide_name} ({len(img_files)} images) -> {split_name}\")\n",
    "    \n",
    "    # Build task list for this slide\n",
    "    tasks = []\n",
    "    for img_path in img_files:\n",
    "        patch_name = img_path.name  # e.g., \"01_1.png\"\n",
    "        gt_path = gt_dir / patch_name\n",
    "        \n",
    "        if gt_path.exists():\n",
    "            tasks.append((img_path, gt_path, patch_name))\n",
    "        else:\n",
    "            print(f\"   ‚ö†Ô∏è  No GT mask for {patch_name}\")\n",
    "    \n",
    "    if not tasks:\n",
    "        return 0, 0\n",
    "    \n",
    "    # Process all image pairs for this slide\n",
    "    results = []\n",
    "    for task in tqdm(tasks, desc=f\"  {slide_name}\", leave=False):\n",
    "        result = process_image_pair(task)\n",
    "        if result is not None:\n",
    "            results.append(result)\n",
    "    \n",
    "    if not results:\n",
    "        print(f\"‚ö†Ô∏è  No valid results for {slide_name}\")\n",
    "        return 0, 0\n",
    "    \n",
    "    # --- Aggregate All Patches for This Slide ---\n",
    "    all_images = []\n",
    "    all_masks = []\n",
    "    all_metadata = []\n",
    "    \n",
    "    for result in results:\n",
    "        all_images.append(result['images'])\n",
    "        all_masks.append(result['masks'])\n",
    "        all_metadata.extend(result['metadata'])\n",
    "    \n",
    "    # Concatenate all patches\n",
    "    final_images = np.concatenate(all_images, axis=0)\n",
    "    final_masks = np.concatenate(all_masks, axis=0)\n",
    "    \n",
    "    # --- Save to Zarr in appropriate split directory ---\n",
    "    split_dir = OUTPUT_BASE / split_name\n",
    "    slide_out_path = split_dir / slide_name\n",
    "    os.makedirs(slide_out_path, exist_ok=True)\n",
    "    compressor = numcodecs.Blosc(cname='zstd', clevel=3)\n",
    "    \n",
    "    # Save images\n",
    "    z_img = zarr.open_array(\n",
    "        str(slide_out_path / 'images.zarr'),\n",
    "        mode='w',\n",
    "        shape=final_images.shape,\n",
    "        chunks=(1, 512, 512, 3),\n",
    "        dtype='uint8',\n",
    "        compressor=compressor\n",
    "    )\n",
    "    z_img[:] = final_images\n",
    "    \n",
    "    # Save instance masks\n",
    "    z_mask = zarr.open_array(\n",
    "        str(slide_out_path / 'nuclei_masks.zarr'),\n",
    "        mode='w',\n",
    "        shape=final_masks.shape,\n",
    "        chunks=(1, 512, 512),\n",
    "        dtype='int32',\n",
    "        compressor=compressor\n",
    "    )\n",
    "    z_mask[:] = final_masks\n",
    "    \n",
    "    # Save metadata\n",
    "    pd.DataFrame(all_metadata).to_csv(\n",
    "        slide_out_path / 'metadata.csv',\n",
    "        index=False\n",
    "    )\n",
    "    \n",
    "    # Get instance stats\n",
    "    unique_instances = np.unique(final_masks)\n",
    "    num_instances = len(unique_instances[unique_instances > 0])\n",
    "    \n",
    "    print(f\"   ‚úÖ {slide_name}: {len(final_images)} patches, {num_instances} nuclei instances\")\n",
    "    \n",
    "    return len(final_images), num_instances\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 5. Main Processing Pipeline\n",
    "# ---------------------------------------------------------------------\n",
    "def main():\n",
    "    print(\"=\" * 70)\n",
    "    print(\"üî¨ TNBC Dataset ‚Üí Zarr with Train/Val/Test Split\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Find all available slides\n",
    "    slide_dirs = sorted(BASE_PATH.glob(\"Slide_*\"))\n",
    "    slide_numbers = [int(d.name.split('_')[1]) for d in slide_dirs]\n",
    "    \n",
    "    print(f\"\\nüìä Found {len(slide_numbers)} slides: {slide_numbers}\")\n",
    "    print(f\"\\nüìÇ Split Configuration:\")\n",
    "    print(f\"   Training:   Slides {TRAIN_SLIDES} -> tnbc_train/\")\n",
    "    print(f\"   Validation: Slides {VAL_SLIDES} -> tnbc_val/\")\n",
    "    print(f\"   Testing:    Slides {TEST_SLIDES} -> tnbc_test/\")\n",
    "    print(f\"\\n   Patch size: {PATCH_SIZE}x{PATCH_SIZE}\")\n",
    "    print(f\"   Output: {OUTPUT_BASE}\")\n",
    "    \n",
    "    # Create output directories\n",
    "    OUTPUT_BASE.mkdir(parents=True, exist_ok=True)\n",
    "    for split_name in ['tnbc_train', 'tnbc_val', 'tnbc_test']:\n",
    "        (OUTPUT_BASE / split_name).mkdir(exist_ok=True)\n",
    "    \n",
    "    # Process each slide sequentially\n",
    "    total_patches = 0\n",
    "    total_instances = 0\n",
    "    split_stats = {'tnbc_train': {'patches': 0, 'nuclei': 0, 'slides': []},\n",
    "                   'tnbc_val': {'patches': 0, 'nuclei': 0, 'slides': []},\n",
    "                   'tnbc_test': {'patches': 0, 'nuclei': 0, 'slides': []}}\n",
    "    \n",
    "    for slide_num in slide_numbers:\n",
    "        num_patches, num_instances = process_slide(slide_num)\n",
    "        total_patches += num_patches\n",
    "        total_instances += num_instances\n",
    "        \n",
    "        # Track per-split stats\n",
    "        if slide_num in TRAIN_SLIDES:\n",
    "            split_stats['tnbc_train']['patches'] += num_patches\n",
    "            split_stats['tnbc_train']['nuclei'] += num_instances\n",
    "            split_stats['tnbc_train']['slides'].append(slide_num)\n",
    "        elif slide_num in VAL_SLIDES:\n",
    "            split_stats['tnbc_val']['patches'] += num_patches\n",
    "            split_stats['tnbc_val']['nuclei'] += num_instances\n",
    "            split_stats['tnbc_val']['slides'].append(slide_num)\n",
    "        elif slide_num in TEST_SLIDES:\n",
    "            split_stats['tnbc_test']['patches'] += num_patches\n",
    "            split_stats['tnbc_test']['nuclei'] += num_instances\n",
    "            split_stats['tnbc_test']['slides'].append(slide_num)\n",
    "    \n",
    "    # --- Summary Statistics ---\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"‚úÖ PROCESSING COMPLETE\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Total slides processed: {len(slide_numbers)}\")\n",
    "    print(f\"Total patches created: {total_patches}\")\n",
    "    print(f\"Total nuclei instances: {total_instances}\")\n",
    "    \n",
    "    print(\"\\n\" + \"‚îÄ\" * 70)\n",
    "    print(\"üìä Per-Split Statistics:\")\n",
    "    print(\"‚îÄ\" * 70)\n",
    "    for split_name in ['tnbc_train', 'tnbc_val', 'tnbc_test']:\n",
    "        stats = split_stats[split_name]\n",
    "        print(f\"\\n{split_name.upper()}:\")\n",
    "        print(f\"   Slides: {stats['slides']}\")\n",
    "        print(f\"   Total patches: {stats['patches']}\")\n",
    "        print(f\"   Total nuclei: {stats['nuclei']}\")\n",
    "        if stats['patches'] > 0:\n",
    "            print(f\"   Avg nuclei/patch: {stats['nuclei']/stats['patches']:.1f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"Output directory: {OUTPUT_BASE}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # --- Print Directory Structure ---\n",
    "    print(\"\\nüìä Output Structure:\")\n",
    "    for split_name in ['tnbc_train', 'tnbc_val', 'tnbc_test']:\n",
    "        split_dir = OUTPUT_BASE / split_name\n",
    "        if split_dir.exists():\n",
    "            slides = sorted([d.name for d in split_dir.iterdir() if d.is_dir()])\n",
    "            print(f\"   {split_name}/\")\n",
    "            for slide in slides:\n",
    "                print(f\"      ‚îî‚îÄ‚îÄ {slide}/\")\n",
    "    \n",
    "    # Create split info file\n",
    "    create_split_info_file(split_stats)\n",
    "\n",
    "def create_split_info_file(split_stats):\n",
    "    \"\"\"Create a text file documenting the split.\"\"\"\n",
    "    info_file = OUTPUT_BASE / \"split_info.txt\"\n",
    "    \n",
    "    with open(info_file, 'w') as f:\n",
    "        f.write(\"TNBC Dataset Split Information\\n\")\n",
    "        f.write(\"=\" * 70 + \"\\n\\n\")\n",
    "        f.write(\"Directory Structure:\\n\")\n",
    "        f.write(f\"  tnbc_train/   - Slides {TRAIN_SLIDES}\\n\")\n",
    "        f.write(f\"  tnbc_val/     - Slides {VAL_SLIDES}\\n\")\n",
    "        f.write(f\"  tnbc_test/    - Slides {TEST_SLIDES}\\n\\n\")\n",
    "        f.write(\"Split Strategy: Patient-level split to prevent data leakage\\n\")\n",
    "        f.write(\"Total: 11 patients -> 7 train / 2 val / 2 test\\n\\n\")\n",
    "        \n",
    "        f.write(\"Statistics:\\n\")\n",
    "        f.write(\"-\" * 70 + \"\\n\")\n",
    "        for split_name in ['tnbc_train', 'tnbc_val', 'tnbc_test']:\n",
    "            stats = split_stats[split_name]\n",
    "            f.write(f\"\\n{split_name.upper()}:\\n\")\n",
    "            f.write(f\"  Slides: {stats['slides']}\\n\")\n",
    "            f.write(f\"  Total patches: {stats['patches']}\\n\")\n",
    "            f.write(f\"  Total nuclei: {stats['nuclei']}\\n\")\n",
    "            if stats['patches'] > 0:\n",
    "                f.write(f\"  Avg nuclei/patch: {stats['nuclei']/stats['patches']:.1f}\\n\")\n",
    "    \n",
    "    print(f\"\\nüìÑ Split info saved to: {info_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bff70e4-28b2-4e07-b223-2dacb3f8f8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üîç DATA INTEGRITY CHECK\n",
      "======================================================================\n",
      "\n",
      "‚úÖ All checks passed! Dataset looks good.\n",
      "\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üìä TNBC DATASET SUMMARY\n",
      "======================================================================\n",
      "‚ö†Ô∏è  No slides found\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üëÄ INSPECTING TNBC ZARR DATA AT: /rsrch9/home/plm/idso_fa1_pathology/TIER2/yasin-vitaminp/tnbc/zarr_data\n",
      "======================================================================\n",
      "\n",
      "‚ö†Ô∏è  No slides found in /rsrch9/home/plm/idso_fa1_pathology/TIER2/yasin-vitaminp/tnbc/zarr_data\n"
     ]
    }
   ],
   "source": [
    "import zarr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "ZARR_DATA_ROOT = Path(\"/rsrch9/home/plm/idso_fa1_pathology/TIER2/yasin-vitaminp/tnbc/zarr_data\")\n",
    "\n",
    "def colorize_instances(mask):\n",
    "    \"\"\"\n",
    "    Creates a random RGB color map for an instance mask.\n",
    "    Background (0) is always Black.\n",
    "    Each unique instance ID gets a unique color.\n",
    "    \"\"\"\n",
    "    max_id = int(mask.max())\n",
    "    if max_id == 0:\n",
    "        return np.zeros((*mask.shape, 3), dtype=np.uint8)\n",
    "    \n",
    "    # Create a random color for every possible ID\n",
    "    # Using a fixed seed so colors are consistent for the same mask, \n",
    "    # but random across IDs.\n",
    "    np.random.seed(42) \n",
    "    colors = np.random.randint(50, 255, size=(max_id + 1, 3), dtype=np.uint8)\n",
    "    \n",
    "    # Force background to black\n",
    "    colors[0] = [0, 0, 0]\n",
    "    \n",
    "    # Map the IDs to colors\n",
    "    colored_mask = colors[mask]\n",
    "    return colored_mask\n",
    "\n",
    "def get_instance_stats(mask):\n",
    "    \"\"\"Get statistics about instances in the mask\"\"\"\n",
    "    unique_ids = np.unique(mask)\n",
    "    num_instances = len(unique_ids[unique_ids > 0])  # Exclude background\n",
    "    \n",
    "    instance_sizes = []\n",
    "    for inst_id in unique_ids:\n",
    "        if inst_id > 0:\n",
    "            size = np.sum(mask == inst_id)\n",
    "            instance_sizes.append(size)\n",
    "    \n",
    "    return {\n",
    "        'num_instances': num_instances,\n",
    "        'min_size': min(instance_sizes) if instance_sizes else 0,\n",
    "        'max_size': max(instance_sizes) if instance_sizes else 0,\n",
    "        'avg_size': np.mean(instance_sizes) if instance_sizes else 0\n",
    "    }\n",
    "\n",
    "def visualize_dataset(root_path, samples_per_category=5):\n",
    "    \"\"\"\n",
    "    Visualize random samples from the TNBC zarr dataset.\n",
    "    Works with Slide_XX directories.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(f\"üëÄ INSPECTING TNBC ZARR DATA AT: {root_path}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    if not root_path.exists():\n",
    "        print(f\"\\n‚ùå Path not found: {root_path}\")\n",
    "        return\n",
    "    \n",
    "    # Get all slide directories\n",
    "    slides = sorted([d for d in root_path.iterdir() if d.is_dir() and d.name.startswith('Slide_')])\n",
    "    \n",
    "    if not slides:\n",
    "        print(f\"\\n‚ö†Ô∏è  No slides found in {root_path}\")\n",
    "        return\n",
    "    \n",
    "    # Randomly select slides\n",
    "    chosen = random.sample(slides, min(len(slides), samples_per_category))\n",
    "    \n",
    "    print(f\"\\n{'‚îÄ' * 70}\")\n",
    "    print(f\"üìÇ TNBC DATASET\")\n",
    "    print(f\"   Total slides: {len(slides)}\")\n",
    "    print(f\"   Showing: {len(chosen)} random slides\")\n",
    "    print(f\"{'‚îÄ' * 70}\")\n",
    "    \n",
    "    for slide_idx, slide_path in enumerate(chosen, 1):\n",
    "        slide_name = slide_path.name\n",
    "        \n",
    "        try:\n",
    "            # Open zarr arrays\n",
    "            z_img = zarr.open(str(slide_path / \"images.zarr\"), mode='r')\n",
    "            z_msk = zarr.open(str(slide_path / \"nuclei_masks.zarr\"), mode='r')\n",
    "            \n",
    "            # Get metadata if available\n",
    "            metadata_path = slide_path / \"metadata.csv\"\n",
    "            if metadata_path.exists():\n",
    "                import pandas as pd\n",
    "                metadata = pd.read_csv(metadata_path)\n",
    "            else:\n",
    "                metadata = None\n",
    "            \n",
    "            # Pick a random patch from this slide\n",
    "            num_patches = z_img.shape[0]\n",
    "            idx = random.randint(0, num_patches - 1)\n",
    "            \n",
    "            img_patch = z_img[idx]\n",
    "            mask_patch = z_msk[idx]\n",
    "            \n",
    "            # Get instance statistics\n",
    "            stats = get_instance_stats(mask_patch)\n",
    "            \n",
    "            # Print info\n",
    "            print(f\"\\n   [{slide_idx}/{len(chosen)}] {slide_name}\")\n",
    "            print(f\"        Total patches: {num_patches}\")\n",
    "            print(f\"        Selected patch: #{idx}\")\n",
    "            print(f\"        Nuclei in patch: {stats['num_instances']}\")\n",
    "            if stats['num_instances'] > 0:\n",
    "                print(f\"        Size range: {stats['min_size']}-{stats['max_size']} pixels (avg: {stats['avg_size']:.0f})\")\n",
    "            \n",
    "            if metadata is not None:\n",
    "                patch_meta = metadata.iloc[idx]\n",
    "                print(f\"        Original file: {patch_meta['original_file']}\")\n",
    "                print(f\"        Position: x={patch_meta['x']}, y={patch_meta['y']}\")\n",
    "                print(f\"        Original size: {patch_meta['original_width']}x{patch_meta['original_height']}\")\n",
    "            \n",
    "            # --- PLOTTING ---\n",
    "            fig, ax = plt.subplots(1, 3, figsize=(18, 6))\n",
    "            fig.suptitle(\n",
    "                f\"{slide_name} | Patch #{idx} | {stats['num_instances']} nuclei\",\n",
    "                fontsize=14,\n",
    "                fontweight='bold'\n",
    "            )\n",
    "            \n",
    "            # 1. Original Image\n",
    "            ax[0].imshow(img_patch)\n",
    "            ax[0].set_title(\"Original Image (H&E)\", fontsize=12)\n",
    "            ax[0].axis('off')\n",
    "            \n",
    "            # 2. Instance Mask (Random Colors)\n",
    "            colored_mask = colorize_instances(mask_patch)\n",
    "            ax[1].imshow(colored_mask)\n",
    "            ax[1].set_title(\n",
    "                f\"Instance Mask\\n({stats['num_instances']} nuclei, IDs: 1-{mask_patch.max()})\",\n",
    "                fontsize=12\n",
    "            )\n",
    "            ax[1].axis('off')\n",
    "            \n",
    "            # 3. Overlay\n",
    "            # Create overlay with transparency\n",
    "            overlay_img = img_patch.copy().astype(float)\n",
    "            \n",
    "            # Create alpha channel based on mask\n",
    "            alpha = np.where(mask_patch > 0, 0.5, 0.0)  # 50% transparency for nuclei\n",
    "            \n",
    "            # Blend the colored mask with the original image\n",
    "            for c in range(3):\n",
    "                overlay_img[:, :, c] = (\n",
    "                    img_patch[:, :, c] * (1 - alpha) + \n",
    "                    colored_mask[:, :, c] * alpha\n",
    "                )\n",
    "            \n",
    "            overlay_img = overlay_img.astype(np.uint8)\n",
    "            \n",
    "            ax[2].imshow(overlay_img)\n",
    "            ax[2].set_title(\"Overlay (Image + Instances)\", fontsize=12)\n",
    "            ax[2].axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            print(f\"        ‚úÖ Visualization complete\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n        ‚ùå Error reading {slide_name}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"‚úÖ Dataset inspection complete!\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "def print_dataset_summary(root_path):\n",
    "    \"\"\"Print summary statistics for the entire TNBC dataset\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"üìä TNBC DATASET SUMMARY\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    if not root_path.exists():\n",
    "        print(f\"‚ùå Path not found: {root_path}\")\n",
    "        return\n",
    "    \n",
    "    slides = sorted([d for d in root_path.iterdir() if d.is_dir() and d.name.startswith('Slide_')])\n",
    "    \n",
    "    if not slides:\n",
    "        print(\"‚ö†Ô∏è  No slides found\")\n",
    "        return\n",
    "    \n",
    "    total_patches = 0\n",
    "    total_nuclei = 0\n",
    "    slide_info = []\n",
    "    \n",
    "    for slide_path in slides:\n",
    "        try:\n",
    "            z_msk = zarr.open(str(slide_path / \"nuclei_masks.zarr\"), mode='r')\n",
    "            num_patches = z_msk.shape[0]\n",
    "            total_patches += num_patches\n",
    "            \n",
    "            # Count nuclei in all patches\n",
    "            slide_nuclei = 0\n",
    "            for patch_idx in range(z_msk.shape[0]):\n",
    "                mask = z_msk[patch_idx]\n",
    "                unique_ids = np.unique(mask)\n",
    "                slide_nuclei += len(unique_ids[unique_ids > 0])\n",
    "            \n",
    "            total_nuclei += slide_nuclei\n",
    "            slide_info.append({\n",
    "                'name': slide_path.name,\n",
    "                'patches': num_patches,\n",
    "                'nuclei': slide_nuclei\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Error processing {slide_path.name}: {e}\")\n",
    "    \n",
    "    print(f\"\\nTotal slides: {len(slides)}\")\n",
    "    print(f\"Total patches: {total_patches}\")\n",
    "    print(f\"Total nuclei: {total_nuclei}\")\n",
    "    if total_patches > 0:\n",
    "        print(f\"Avg nuclei/patch: {total_nuclei/total_patches:.1f}\")\n",
    "    \n",
    "    print(f\"\\n{'‚îÄ' * 70}\")\n",
    "    print(\"Per-slide breakdown:\")\n",
    "    print(f\"{'‚îÄ' * 70}\")\n",
    "    for info in slide_info:\n",
    "        avg_per_patch = info['nuclei'] / info['patches'] if info['patches'] > 0 else 0\n",
    "        print(f\"   {info['name']}: {info['patches']} patches, {info['nuclei']} nuclei (avg: {avg_per_patch:.1f}/patch)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "\n",
    "def verify_data_integrity(root_path):\n",
    "    \"\"\"Check for common issues in the dataset\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"üîç DATA INTEGRITY CHECK\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    if not root_path.exists():\n",
    "        print(f\"‚ùå Path not found: {root_path}\")\n",
    "        return\n",
    "    \n",
    "    slides = sorted([d for d in root_path.iterdir() if d.is_dir() and d.name.startswith('Slide_')])\n",
    "    \n",
    "    issues = []\n",
    "    \n",
    "    for slide_path in slides:\n",
    "        slide_name = slide_path.name\n",
    "        \n",
    "        # Check for required files\n",
    "        if not (slide_path / \"images.zarr\").exists():\n",
    "            issues.append(f\"{slide_name}: Missing images.zarr\")\n",
    "        if not (slide_path / \"nuclei_masks.zarr\").exists():\n",
    "            issues.append(f\"{slide_name}: Missing nuclei_masks.zarr\")\n",
    "        if not (slide_path / \"metadata.csv\").exists():\n",
    "            issues.append(f\"{slide_name}: Missing metadata.csv\")\n",
    "        \n",
    "        try:\n",
    "            z_img = zarr.open(str(slide_path / \"images.zarr\"), mode='r')\n",
    "            z_msk = zarr.open(str(slide_path / \"nuclei_masks.zarr\"), mode='r')\n",
    "            \n",
    "            # Check shape consistency\n",
    "            if z_img.shape[0] != z_msk.shape[0]:\n",
    "                issues.append(f\"{slide_name}: Image/mask count mismatch ({z_img.shape[0]} vs {z_msk.shape[0]})\")\n",
    "            \n",
    "            # Check patch dimensions\n",
    "            if z_img.shape[1:3] != (512, 512):\n",
    "                issues.append(f\"{slide_name}: Incorrect image patch size {z_img.shape[1:3]}\")\n",
    "            if z_msk.shape[1:3] != (512, 512):\n",
    "                issues.append(f\"{slide_name}: Incorrect mask patch size {z_msk.shape[1:3]}\")\n",
    "            \n",
    "            # Sample check: verify at least one patch has nuclei\n",
    "            has_nuclei = False\n",
    "            for idx in range(min(10, z_msk.shape[0])):  # Check first 10 patches\n",
    "                if z_msk[idx].max() > 0:\n",
    "                    has_nuclei = True\n",
    "                    break\n",
    "            \n",
    "            if not has_nuclei:\n",
    "                issues.append(f\"{slide_name}: Warning - No nuclei found in first 10 patches\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            issues.append(f\"{slide_name}: Error reading zarr - {e}\")\n",
    "    \n",
    "    if issues:\n",
    "        print(\"\\n‚ö†Ô∏è  Issues found:\")\n",
    "        for issue in issues:\n",
    "            print(f\"   ‚Ä¢ {issue}\")\n",
    "    else:\n",
    "        print(\"\\n‚úÖ All checks passed! Dataset looks good.\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if ZARR_DATA_ROOT.exists():\n",
    "        # First verify data integrity\n",
    "        verify_data_integrity(ZARR_DATA_ROOT)\n",
    "        \n",
    "        # Print overall summary\n",
    "        print_dataset_summary(ZARR_DATA_ROOT)\n",
    "        \n",
    "        # Then visualize random samples\n",
    "        print(\"\\n\")\n",
    "        visualize_dataset(ZARR_DATA_ROOT, samples_per_category=10)\n",
    "    else:\n",
    "        print(f\"‚ùå Path not found: {ZARR_DATA_ROOT}\")\n",
    "        print(\"   Please check your ZARR_DATA_ROOT configuration.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e52b433-acd8-4dfd-b2cb-fa895a97bd84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yshokrollahi (py3.11.0rc1)",
   "language": "python",
   "name": "yshokrollahi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
