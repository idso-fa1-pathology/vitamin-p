{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d1439b0-b265-428f-bf0b-7871d864736c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m parentdir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(parentdir)\n\u001b[1;32m     20\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, parentdir)\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbase_ml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_experiment\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseExperiment\n\u001b[1;32m     24\u001b[0m BaseExperiment\u001b[38;5;241m.\u001b[39mseed_run(\u001b[38;5;241m1232\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n",
      "File \u001b[0;32m/rsrch5/home/plm/yshokrollahi/CellViT/base_ml/base_experiment.py:23\u001b[0m\n\u001b[1;32m     20\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, parentdir)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# CellViT Inference Method for Patch-Wise Inference on a test set\n",
    "# Without merging WSI\n",
    "#\n",
    "# Aim is to calculate metrics as defined for the PanNuke dataset\n",
    "#\n",
    "# @ Fabian HÃ¶rst, fabian.hoerst@uk-essen.de\n",
    "# Institute for Artifical Intelligence in Medicine,\n",
    "# University Medicine Essen\n",
    "\n",
    "import argparse\n",
    "import inspect\n",
    "import os\n",
    "import sys\n",
    "\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0, parentdir)\n",
    "parentdir = os.path.dirname(parentdir)\n",
    "sys.path.insert(0, parentdir)\n",
    "\n",
    "from base_ml.base_experiment import BaseExperiment\n",
    "\n",
    "BaseExperiment.seed_run(1232)\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Union\n",
    "\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "import yaml\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "from skimage.color import rgba2rgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tabulate import tabulate\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics.functional import dice\n",
    "from torchmetrics.functional.classification import binary_jaccard_index\n",
    "from torchvision import transforms\n",
    "\n",
    "from cell_segmentation.datasets.dataset_coordinator import select_dataset\n",
    "from models.segmentation.cell_segmentation.cellvit import DataclassHVStorage\n",
    "from cell_segmentation.utils.metrics import (\n",
    "    cell_detection_scores,\n",
    "    cell_type_detection_scores,\n",
    "    get_fast_pq,\n",
    "    remap_label,\n",
    "    binarize,\n",
    ")\n",
    "from cell_segmentation.utils.post_proc_cellvit import calculate_instances\n",
    "from cell_segmentation.utils.tools import cropping_center, pair_coordinates\n",
    "from models.segmentation.cell_segmentation.cellvit import (\n",
    "    CellViT,\n",
    "    CellViT256,\n",
    "    CellViTSAM,\n",
    ")\n",
    "from models.segmentation.cell_segmentation.cellvit_shared import (\n",
    "    CellViT256Shared,\n",
    "    CellViTSAMShared,\n",
    "    CellViTShared,\n",
    ")\n",
    "from utils.logger import Logger\n",
    "\n",
    "\n",
    "class InferenceCellViT:\n",
    "    def __init__(\n",
    "        self,\n",
    "        run_dir: Union[Path, str],\n",
    "        gpu: int,\n",
    "        magnification: int = 40,\n",
    "        checkpoint_name: str = \"model_best.pth\",\n",
    "    ) -> None:\n",
    "        \"\"\"Inference for HoverNet\n",
    "\n",
    "        Args:\n",
    "            run_dir (Union[Path, str]): logging directory with checkpoints and configs\n",
    "            gpu (int): CUDA GPU device to use for inference\n",
    "            magnification (int, optional): Dataset magnification. Defaults to 40.\n",
    "            checkpoint_name (str, optional): Select name of the model to load. Defaults to model_best.pth\n",
    "        \"\"\"\n",
    "        self.run_dir = Path(run_dir)\n",
    "        self.device = f\"cuda:{gpu}\"\n",
    "        self.run_conf: dict = None\n",
    "        self.logger: Logger = None\n",
    "        self.magnification = magnification\n",
    "        self.checkpoint_name = checkpoint_name\n",
    "\n",
    "        self.__load_run_conf()\n",
    "\n",
    "        self.__load_dataset_setup(dataset_path=self.run_conf[\"data\"][\"dataset_path\"])\n",
    "        self.__instantiate_logger()\n",
    "        self.__check_eval_model()\n",
    "        self.__setup_amp()\n",
    "\n",
    "        self.logger.info(f\"Loaded run: {run_dir}\")\n",
    "        self.num_classes = self.run_conf[\"data\"][\"num_nuclei_classes\"]\n",
    "\n",
    "    def __load_run_conf(self) -> None:\n",
    "        \"\"\"Load the config.yaml file with the run setup\n",
    "\n",
    "        Be careful with loading and usage, since original None values in the run configuration are not stored when dumped to yaml file.\n",
    "        If you want to check if a key is not defined, first check if the key does exists in the dict.\n",
    "        \"\"\"\n",
    "        with open((self.run_dir / \"config.yaml\").resolve(), \"r\") as run_config_file:\n",
    "            yaml_config = yaml.safe_load(run_config_file)\n",
    "            self.run_conf = dict(yaml_config)\n",
    "\n",
    "    def __load_dataset_setup(self, dataset_path: Union[Path, str]) -> None:\n",
    "        \"\"\"Load the configuration of the cell segmentation dataset.\n",
    "\n",
    "        The dataset must have a dataset_config.yaml file in their dataset path with the following entries:\n",
    "            * tissue_types: describing the present tissue types with corresponding integer\n",
    "            * nuclei_types: describing the present nuclei types with corresponding integer\n",
    "\n",
    "        Args:\n",
    "            dataset_path (Union[Path, str]): Path to dataset folder\n",
    "        \"\"\"\n",
    "        dataset_config_path = Path(dataset_path) / \"dataset_config.yaml\"\n",
    "        with open(dataset_config_path, \"r\") as dataset_config_file:\n",
    "            yaml_config = yaml.safe_load(dataset_config_file)\n",
    "            self.dataset_config = dict(yaml_config)\n",
    "\n",
    "    def __instantiate_logger(self) -> None:\n",
    "        \"\"\"Instantiate logger\n",
    "\n",
    "        Logger is using no formatters. Logs are stored in the run directory under the filename: inference.log\n",
    "        \"\"\"\n",
    "        logger = Logger(\n",
    "            level=self.run_conf[\"logging\"][\"level\"].upper(),\n",
    "            log_dir=Path(self.run_dir).resolve(),\n",
    "            comment=\"inference\",\n",
    "            use_timestamp=False,\n",
    "            formatter=\"%(message)s\",\n",
    "        )\n",
    "        self.logger = logger.create_logger()\n",
    "\n",
    "    def __check_eval_model(self) -> None:\n",
    "        \"\"\"Check if there is a best model pytorch file\"\"\"\n",
    "        assert (self.run_dir / \"checkpoints\" / self.checkpoint_name).is_file()\n",
    "\n",
    "    def __setup_amp(self) -> None:\n",
    "        \"\"\"Setup automated mixed precision (amp) for inference.\"\"\"\n",
    "        self.mixed_precision = self.run_conf[\"training\"].get(\"mixed_precision\", False)\n",
    "\n",
    "    def get_model(\n",
    "        self, model_type: str\n",
    "    ) -> Union[\n",
    "        CellViT,\n",
    "        CellViTShared,\n",
    "        CellViT256,\n",
    "        CellViT256Shared,\n",
    "        CellViTSAM,\n",
    "        CellViTSAMShared,\n",
    "    ]:\n",
    "        \"\"\"Return the trained model for inference\n",
    "\n",
    "        Args:\n",
    "            model_type (str): Name of the model. Must either be one of:\n",
    "                CellViT, CellViTShared, CellViT256, CellViT256Shared, CellViTSAM, CellViTSAMShared\n",
    "\n",
    "        Returns:\n",
    "            Union[CellViT, CellViTShared, CellViT256, CellViT256Shared, CellViTSAM, CellViTSAMShared]: Model\n",
    "        \"\"\"\n",
    "        implemented_models = [\n",
    "            \"CellViT\",\n",
    "            \"CellViTShared\",\n",
    "            \"CellViT256\",\n",
    "            \"CellViT256Shared\",\n",
    "            \"CellViTSAM\",\n",
    "            \"CellViTSAMShared\",\n",
    "        ]\n",
    "        if model_type not in implemented_models:\n",
    "            raise NotImplementedError(\n",
    "                f\"Unknown model type. Please select one of {implemented_models}\"\n",
    "            )\n",
    "        if model_type in [\"CellViT\", \"CellViTShared\"]:\n",
    "            if model_type == \"CellViT\":\n",
    "                model_class = CellViT\n",
    "            elif model_type == \"CellViTShared\":\n",
    "                model_class = CellViTShared\n",
    "            model = model_class(\n",
    "                num_nuclei_classes=self.run_conf[\"data\"][\"num_nuclei_classes\"],\n",
    "                num_tissue_classes=self.run_conf[\"data\"][\"num_tissue_classes\"],\n",
    "                embed_dim=self.run_conf[\"model\"][\"embed_dim\"],\n",
    "                input_channels=self.run_conf[\"model\"].get(\"input_channels\", 3),\n",
    "                depth=self.run_conf[\"model\"][\"depth\"],\n",
    "                num_heads=self.run_conf[\"model\"][\"num_heads\"],\n",
    "                extract_layers=self.run_conf[\"model\"][\"extract_layers\"],\n",
    "                regression_loss=self.run_conf[\"model\"].get(\"regression_loss\", False),\n",
    "            )\n",
    "\n",
    "        elif model_type in [\"CellViT256\", \"CellViT256Shared\"]:\n",
    "            if model_type == \"CellViT256\":\n",
    "                model_class = CellViT256\n",
    "            elif model_type == \"CellViT256Shared\":\n",
    "                model_class = CellViT256Shared\n",
    "            model = model_class(\n",
    "                model256_path=None,\n",
    "                num_nuclei_classes=self.run_conf[\"data\"][\"num_nuclei_classes\"],\n",
    "                num_tissue_classes=self.run_conf[\"data\"][\"num_tissue_classes\"],\n",
    "                regression_loss=self.run_conf[\"model\"].get(\"regression_loss\", False),\n",
    "            )\n",
    "        elif model_type in [\"CellViTSAM\", \"CellViTSAMShared\"]:\n",
    "            if model_type == \"CellViTSAM\":\n",
    "                model_class = CellViTSAM\n",
    "            elif model_type == \"CellViTSAMShared\":\n",
    "                model_class = CellViTSAMShared\n",
    "            model = model_class(\n",
    "                model_path=None,\n",
    "                num_nuclei_classes=self.run_conf[\"data\"][\"num_nuclei_classes\"],\n",
    "                num_tissue_classes=self.run_conf[\"data\"][\"num_tissue_classes\"],\n",
    "                vit_structure=self.run_conf[\"model\"][\"backbone\"],\n",
    "                regression_loss=self.run_conf[\"model\"].get(\"regression_loss\", False),\n",
    "            )\n",
    "        return model\n",
    "\n",
    "    def setup_patch_inference(\n",
    "        self, test_folds: List[int] = None\n",
    "    ) -> tuple[\n",
    "        Union[\n",
    "            CellViT,\n",
    "            CellViTShared,\n",
    "            CellViT256,\n",
    "            CellViT256Shared,\n",
    "            CellViTSAM,\n",
    "            CellViTSAMShared,\n",
    "        ],\n",
    "        DataLoader,\n",
    "        dict,\n",
    "    ]:\n",
    "        \"\"\"Setup patch inference by defining a patch-wise datalaoder and loading the model checkpoint\n",
    "\n",
    "        Args:\n",
    "            test_folds (List[int], optional): Test fold to use. Otherwise defined folds from config.yaml (in run_dir) are loaded. Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            tuple[Union[CellViT, CellViTShared, CellViT256, CellViT256Shared, CellViTSAM, CellViTSAMShared], DataLoader, dict]:\n",
    "                Union[CellViT, CellViTShared, CellViT256, CellViT256Shared, CellViTSAM, CellViTSAMShared]: Best model loaded form checkpoint\n",
    "                DataLoader: Inference DataLoader\n",
    "                dict: Dataset configuration. Keys are:\n",
    "                    * \"tissue_types\": describing the present tissue types with corresponding integer\n",
    "                    * \"nuclei_types\": describing the present nuclei types with corresponding integer\n",
    "\n",
    "        \"\"\"\n",
    "        # get model for inference\n",
    "        checkpoint = torch.load(\n",
    "            self.run_dir / \"checkpoints\" / self.checkpoint_name, map_location=\"cpu\"\n",
    "        )\n",
    "        model = self.get_model(model_type=checkpoint[\"arch\"])\n",
    "        self.logger.info(\n",
    "            f\"Loading best model from {str(self.run_dir / 'checkpoints' / self.checkpoint_name)}\"\n",
    "        )\n",
    "        self.logger.info(model.load_state_dict(checkpoint[\"model_state_dict\"]))\n",
    "\n",
    "        # get dataset\n",
    "        if test_folds is None:\n",
    "            if \"test_folds\" in self.run_conf[\"data\"]:\n",
    "                if self.run_conf[\"data\"][\"test_folds\"] is None:\n",
    "                    self.logger.info(\n",
    "                        \"There was no test set provided. We now use the validation dataset for testing\"\n",
    "                    )\n",
    "                    self.run_conf[\"data\"][\"test_folds\"] = self.run_conf[\"data\"][\n",
    "                        \"val_folds\"\n",
    "                    ]\n",
    "            else:\n",
    "                self.logger.info(\n",
    "                    \"There was no test set provided. We now use the validation dataset for testing\"\n",
    "                )\n",
    "                self.run_conf[\"data\"][\"test_folds\"] = self.run_conf[\"data\"][\"val_folds\"]\n",
    "        else:\n",
    "            self.run_conf[\"data\"][\"test_folds\"] = self.run_conf[\"data\"][\"val_folds\"]\n",
    "        self.logger.info(\n",
    "            f\"Performing Inference on test set: {self.run_conf['data']['test_folds']}\"\n",
    "        )\n",
    "\n",
    "        transform_settings = self.run_conf[\"transformations\"]\n",
    "        if \"normalize\" in transform_settings:\n",
    "            mean = transform_settings[\"normalize\"].get(\"mean\", (0.5, 0.5, 0.5))\n",
    "            std = transform_settings[\"normalize\"].get(\"std\", (0.5, 0.5, 0.5))\n",
    "        else:\n",
    "            mean = (0.5, 0.5, 0.5)\n",
    "            std = (0.5, 0.5, 0.5)\n",
    "        transforms = A.Compose([A.Normalize(mean=mean, std=std)])\n",
    "\n",
    "        inference_dataset = select_dataset(\n",
    "            dataset_name=self.run_conf[\"data\"][\"dataset\"],\n",
    "            split=\"test\",\n",
    "            dataset_config=self.run_conf[\"data\"],\n",
    "            transforms=transforms,\n",
    "        )\n",
    "\n",
    "        inference_dataloader = DataLoader(\n",
    "            inference_dataset,\n",
    "            batch_size=128,\n",
    "            num_workers=12,\n",
    "            pin_memory=False,\n",
    "            shuffle=False,\n",
    "        )\n",
    "\n",
    "        return model, inference_dataloader, self.dataset_config\n",
    "\n",
    "    def run_patch_inference(\n",
    "        self,\n",
    "        model: Union[\n",
    "            CellViT,\n",
    "            CellViTShared,\n",
    "            CellViT256,\n",
    "            CellViT256Shared,\n",
    "            CellViTSAM,\n",
    "            CellViTSAMShared,\n",
    "        ],\n",
    "        inference_dataloader: DataLoader,\n",
    "        dataset_config: dict,\n",
    "        generate_plots: bool = False,\n",
    "    ) -> None:\n",
    "        \"\"\"Run Patch inference with given setup\n",
    "\n",
    "        Args:\n",
    "            model (Union[CellViT, CellViTShared, CellViT256, CellViT256Shared, CellViTSAM, CellViTSAMShared]): Model to use for inference\n",
    "            inference_dataloader (DataLoader): Inference Dataloader. Must return a batch with the following structure:\n",
    "                * Images (torch.Tensor)\n",
    "                * Masks (dict)\n",
    "                * Tissue types as str\n",
    "                * Image name as str\n",
    "            dataset_config (dict): Dataset configuration. Required keys are:\n",
    "                    * \"tissue_types\": describing the present tissue types with corresponding integer\n",
    "                    * \"nuclei_types\": describing the present nuclei types with corresponding integer\n",
    "            generate_plots (bool, optional): If inference plots should be generated. Defaults to False.\n",
    "        \"\"\"\n",
    "        # put model in eval mode\n",
    "        model.to(device=self.device)\n",
    "        model.eval()\n",
    "\n",
    "        # setup score tracker\n",
    "        image_names = []  # image names as str\n",
    "        binary_dice_scores = []  # binary dice scores per image\n",
    "        binary_jaccard_scores = []  # binary jaccard scores per image\n",
    "        pq_scores = []  # pq-scores per image\n",
    "        dq_scores = []  # dq-scores per image\n",
    "        sq_scores = []  # sq-scores per image\n",
    "        cell_type_pq_scores = []  # pq-scores per cell type and image\n",
    "        cell_type_dq_scores = []  # dq-scores per cell type and image\n",
    "        cell_type_sq_scores = []  # sq-scores per cell type and image\n",
    "        tissue_pred = []  # tissue predictions for each image\n",
    "        tissue_gt = []  # ground truth tissue image class\n",
    "        tissue_types_inf = []  # string repr of ground truth tissue image class\n",
    "\n",
    "        paired_all_global = []  # unique matched index pair\n",
    "        unpaired_true_all_global = (\n",
    "            []\n",
    "        )  # the index must exist in `true_inst_type_all` and unique\n",
    "        unpaired_pred_all_global = (\n",
    "            []\n",
    "        )  # the index must exist in `pred_inst_type_all` and unique\n",
    "        true_inst_type_all_global = []  # each index is 1 independent data point\n",
    "        pred_inst_type_all_global = []  # each index is 1 independent data point\n",
    "\n",
    "        # for detections scores\n",
    "        true_idx_offset = 0\n",
    "        pred_idx_offset = 0\n",
    "\n",
    "        inference_loop = tqdm.tqdm(\n",
    "            enumerate(inference_dataloader), total=len(inference_dataloader)\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch in inference_loop:\n",
    "                batch_metrics = self.inference_step(\n",
    "                    model, batch, generate_plots=generate_plots\n",
    "                )\n",
    "                # unpack batch_metrics\n",
    "                image_names = image_names + batch_metrics[\"image_names\"]\n",
    "\n",
    "                # dice scores\n",
    "                binary_dice_scores = (\n",
    "                    binary_dice_scores + batch_metrics[\"binary_dice_scores\"]\n",
    "                )\n",
    "                binary_jaccard_scores = (\n",
    "                    binary_jaccard_scores + batch_metrics[\"binary_jaccard_scores\"]\n",
    "                )\n",
    "\n",
    "                # pq scores\n",
    "                pq_scores = pq_scores + batch_metrics[\"pq_scores\"]\n",
    "                dq_scores = dq_scores + batch_metrics[\"dq_scores\"]\n",
    "                sq_scores = sq_scores + batch_metrics[\"sq_scores\"]\n",
    "                tissue_types_inf = tissue_types_inf + batch_metrics[\"tissue_types\"]\n",
    "                cell_type_pq_scores = (\n",
    "                    cell_type_pq_scores + batch_metrics[\"cell_type_pq_scores\"]\n",
    "                )\n",
    "                cell_type_dq_scores = (\n",
    "                    cell_type_dq_scores + batch_metrics[\"cell_type_dq_scores\"]\n",
    "                )\n",
    "                cell_type_sq_scores = (\n",
    "                    cell_type_sq_scores + batch_metrics[\"cell_type_sq_scores\"]\n",
    "                )\n",
    "                tissue_pred.append(batch_metrics[\"tissue_pred\"])\n",
    "                tissue_gt.append(batch_metrics[\"tissue_gt\"])\n",
    "\n",
    "                # detection scores\n",
    "                true_idx_offset = (\n",
    "                    true_idx_offset + true_inst_type_all_global[-1].shape[0]\n",
    "                    if batch_idx != 0\n",
    "                    else 0\n",
    "                )\n",
    "                pred_idx_offset = (\n",
    "                    pred_idx_offset + pred_inst_type_all_global[-1].shape[0]\n",
    "                    if batch_idx != 0\n",
    "                    else 0\n",
    "                )\n",
    "                true_inst_type_all_global.append(batch_metrics[\"true_inst_type_all\"])\n",
    "                pred_inst_type_all_global.append(batch_metrics[\"pred_inst_type_all\"])\n",
    "                # increment the pairing index statistic\n",
    "                batch_metrics[\"paired_all\"][:, 0] += true_idx_offset\n",
    "                batch_metrics[\"paired_all\"][:, 1] += pred_idx_offset\n",
    "                paired_all_global.append(batch_metrics[\"paired_all\"])\n",
    "\n",
    "                batch_metrics[\"unpaired_true_all\"] += true_idx_offset\n",
    "                batch_metrics[\"unpaired_pred_all\"] += pred_idx_offset\n",
    "                unpaired_true_all_global.append(batch_metrics[\"unpaired_true_all\"])\n",
    "                unpaired_pred_all_global.append(batch_metrics[\"unpaired_pred_all\"])\n",
    "\n",
    "        # assemble batches to datasets (global)\n",
    "        tissue_types_inf = [t.lower() for t in tissue_types_inf]\n",
    "\n",
    "        paired_all = np.concatenate(paired_all_global, axis=0)\n",
    "        unpaired_true_all = np.concatenate(unpaired_true_all_global, axis=0)\n",
    "        unpaired_pred_all = np.concatenate(unpaired_pred_all_global, axis=0)\n",
    "        true_inst_type_all = np.concatenate(true_inst_type_all_global, axis=0)\n",
    "        pred_inst_type_all = np.concatenate(pred_inst_type_all_global, axis=0)\n",
    "        paired_true_type = true_inst_type_all[paired_all[:, 0]]\n",
    "        paired_pred_type = pred_inst_type_all[paired_all[:, 1]]\n",
    "        unpaired_true_type = true_inst_type_all[unpaired_true_all]\n",
    "        unpaired_pred_type = pred_inst_type_all[unpaired_pred_all]\n",
    "\n",
    "        binary_dice_scores = np.array(binary_dice_scores)\n",
    "        binary_jaccard_scores = np.array(binary_jaccard_scores)\n",
    "        pq_scores = np.array(pq_scores)\n",
    "        dq_scores = np.array(dq_scores)\n",
    "        sq_scores = np.array(sq_scores)\n",
    "\n",
    "        tissue_detection_accuracy = accuracy_score(\n",
    "            y_true=np.concatenate(tissue_gt), y_pred=np.concatenate(tissue_pred)\n",
    "        )\n",
    "        f1_d, prec_d, rec_d = cell_detection_scores(\n",
    "            paired_true=paired_true_type,\n",
    "            paired_pred=paired_pred_type,\n",
    "            unpaired_true=unpaired_true_type,\n",
    "            unpaired_pred=unpaired_pred_type,\n",
    "        )\n",
    "        dataset_metrics = {\n",
    "            \"Binary-Cell-Dice-Mean\": float(np.nanmean(binary_dice_scores)),\n",
    "            \"Binary-Cell-Jacard-Mean\": float(np.nanmean(binary_jaccard_scores)),\n",
    "            \"Tissue-Multiclass-Accuracy\": tissue_detection_accuracy,\n",
    "            \"bPQ\": float(np.nanmean(pq_scores)),\n",
    "            \"bDQ\": float(np.nanmean(dq_scores)),\n",
    "            \"bSQ\": float(np.nanmean(sq_scores)),\n",
    "            \"mPQ\": float(np.nanmean([np.nanmean(pq) for pq in cell_type_pq_scores])),\n",
    "            \"mDQ\": float(np.nanmean([np.nanmean(dq) for dq in cell_type_dq_scores])),\n",
    "            \"mSQ\": float(np.nanmean([np.nanmean(sq) for sq in cell_type_sq_scores])),\n",
    "            \"f1_detection\": float(f1_d),\n",
    "            \"precision_detection\": float(prec_d),\n",
    "            \"recall_detection\": float(rec_d),\n",
    "        }\n",
    "\n",
    "        # calculate tissue metrics\n",
    "        tissue_types = dataset_config[\"tissue_types\"]\n",
    "        tissue_metrics = {}\n",
    "        for tissue in tissue_types.keys():\n",
    "            tissue = tissue.lower()\n",
    "            tissue_ids = np.where(np.asarray(tissue_types_inf) == tissue)\n",
    "            tissue_metrics[f\"{tissue}\"] = {}\n",
    "            tissue_metrics[f\"{tissue}\"][\"Dice\"] = float(\n",
    "                np.nanmean(binary_dice_scores[tissue_ids])\n",
    "            )\n",
    "            tissue_metrics[f\"{tissue}\"][\"Jaccard\"] = float(\n",
    "                np.nanmean(binary_jaccard_scores[tissue_ids])\n",
    "            )\n",
    "            tissue_metrics[f\"{tissue}\"][\"mPQ\"] = float(\n",
    "                np.nanmean(\n",
    "                    [np.nanmean(pq) for pq in np.array(cell_type_pq_scores)[tissue_ids]]\n",
    "                )\n",
    "            )\n",
    "            tissue_metrics[f\"{tissue}\"][\"bPQ\"] = float(\n",
    "                np.nanmean(pq_scores[tissue_ids])\n",
    "            )\n",
    "\n",
    "        # calculate nuclei metrics\n",
    "        nuclei_types = dataset_config[\"nuclei_types\"]\n",
    "        nuclei_metrics_d = {}\n",
    "        nuclei_metrics_pq = {}\n",
    "        nuclei_metrics_dq = {}\n",
    "        nuclei_metrics_sq = {}\n",
    "        for nuc_name, nuc_type in nuclei_types.items():\n",
    "            if nuc_name.lower() == \"background\":\n",
    "                continue\n",
    "            nuclei_metrics_pq[nuc_name] = np.nanmean(\n",
    "                [pq[nuc_type] for pq in cell_type_pq_scores]\n",
    "            )\n",
    "            nuclei_metrics_dq[nuc_name] = np.nanmean(\n",
    "                [dq[nuc_type] for dq in cell_type_dq_scores]\n",
    "            )\n",
    "            nuclei_metrics_sq[nuc_name] = np.nanmean(\n",
    "                [sq[nuc_type] for sq in cell_type_sq_scores]\n",
    "            )\n",
    "            f1_cell, prec_cell, rec_cell = cell_type_detection_scores(\n",
    "                paired_true_type,\n",
    "                paired_pred_type,\n",
    "                unpaired_true_type,\n",
    "                unpaired_pred_type,\n",
    "                nuc_type,\n",
    "            )\n",
    "            nuclei_metrics_d[nuc_name] = {\n",
    "                \"f1_cell\": f1_cell,\n",
    "                \"prec_cell\": prec_cell,\n",
    "                \"rec_cell\": rec_cell,\n",
    "            }\n",
    "\n",
    "        # print final results\n",
    "        # binary\n",
    "        self.logger.info(f\"{20*'*'} Binary Dataset metrics {20*'*'}\")\n",
    "        [self.logger.info(f\"{f'{k}:': <25} {v}\") for k, v in dataset_metrics.items()]\n",
    "        # tissue -> the PQ values are bPQ values -> what about mBQ?\n",
    "        self.logger.info(f\"{20*'*'} Tissue metrics {20*'*'}\")\n",
    "        flattened_tissue = []\n",
    "        for key in tissue_metrics:\n",
    "            flattened_tissue.append(\n",
    "                [\n",
    "                    key,\n",
    "                    tissue_metrics[key][\"Dice\"],\n",
    "                    tissue_metrics[key][\"Jaccard\"],\n",
    "                    tissue_metrics[key][\"mPQ\"],\n",
    "                    tissue_metrics[key][\"bPQ\"],\n",
    "                ]\n",
    "            )\n",
    "        self.logger.info(\n",
    "            tabulate(\n",
    "                flattened_tissue, headers=[\"Tissue\", \"Dice\", \"Jaccard\", \"mPQ\", \"bPQ\"]\n",
    "            )\n",
    "        )\n",
    "        # nuclei types\n",
    "        self.logger.info(f\"{20*'*'} Nuclei Type Metrics {20*'*'}\")\n",
    "        flattened_nuclei_type = []\n",
    "        for key in nuclei_metrics_pq:\n",
    "            flattened_nuclei_type.append(\n",
    "                [\n",
    "                    key,\n",
    "                    nuclei_metrics_dq[key],\n",
    "                    nuclei_metrics_sq[key],\n",
    "                    nuclei_metrics_pq[key],\n",
    "                ]\n",
    "            )\n",
    "        self.logger.info(\n",
    "            tabulate(flattened_nuclei_type, headers=[\"Nuclei Type\", \"DQ\", \"SQ\", \"PQ\"])\n",
    "        )\n",
    "        # nuclei detection metrics\n",
    "        self.logger.info(f\"{20*'*'} Nuclei Detection Metrics {20*'*'}\")\n",
    "        flattened_detection = []\n",
    "        for key in nuclei_metrics_d:\n",
    "            flattened_detection.append(\n",
    "                [\n",
    "                    key,\n",
    "                    nuclei_metrics_d[key][\"prec_cell\"],\n",
    "                    nuclei_metrics_d[key][\"rec_cell\"],\n",
    "                    nuclei_metrics_d[key][\"f1_cell\"],\n",
    "                ]\n",
    "            )\n",
    "        self.logger.info(\n",
    "            tabulate(\n",
    "                flattened_detection,\n",
    "                headers=[\"Nuclei Type\", \"Precision\", \"Recall\", \"F1\"],\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # save all folds\n",
    "        image_metrics = {}\n",
    "        for idx, image_name in enumerate(image_names):\n",
    "            image_metrics[image_name] = {\n",
    "                \"Dice\": float(binary_dice_scores[idx]),\n",
    "                \"Jaccard\": float(binary_jaccard_scores[idx]),\n",
    "                \"bPQ\": float(pq_scores[idx]),\n",
    "            }\n",
    "        all_metrics = {\n",
    "            \"dataset\": dataset_metrics,\n",
    "            \"tissue_metrics\": tissue_metrics,\n",
    "            \"image_metrics\": image_metrics,\n",
    "            \"nuclei_metrics_pq\": nuclei_metrics_pq,\n",
    "            \"nuclei_metrics_d\": nuclei_metrics_d,\n",
    "        }\n",
    "\n",
    "        # saving\n",
    "        with open(str(self.run_dir / \"inference_results.json\"), \"w\") as outfile:\n",
    "            json.dump(all_metrics, outfile, indent=2)\n",
    "\n",
    "    def inference_step(\n",
    "        self,\n",
    "        model: Union[\n",
    "            CellViT,\n",
    "            CellViTShared,\n",
    "            CellViT256,\n",
    "            CellViT256Shared,\n",
    "            CellViTSAM,\n",
    "            CellViTSAMShared,\n",
    "        ],\n",
    "        batch: tuple,\n",
    "        generate_plots: bool = False,\n",
    "    ) -> None:\n",
    "        \"\"\"Inference step for a patch-wise batch\n",
    "\n",
    "        Args:\n",
    "            model (CellViT): Model to use for inference\n",
    "            batch (tuple): Batch with the following structure:\n",
    "                * Images (torch.Tensor)\n",
    "                * Masks (dict)\n",
    "                * Tissue types as str\n",
    "                * Image name as str\n",
    "            generate_plots (bool, optional):  If inference plots should be generated. Defaults to False.\n",
    "        \"\"\"\n",
    "        # unpack batch, for shape compare train_step method\n",
    "        imgs = batch[0].to(self.device)\n",
    "        masks = batch[1]\n",
    "        tissue_types = list(batch[2])\n",
    "        image_names = list(batch[3])\n",
    "\n",
    "        model.zero_grad()\n",
    "        if self.mixed_precision:\n",
    "            with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "                predictions = model.forward(imgs)\n",
    "        else:\n",
    "            predictions = model.forward(imgs)\n",
    "        predictions = self.unpack_predictions(predictions=predictions, model=model)\n",
    "        gt = self.unpack_masks(masks=masks, tissue_types=tissue_types, model=model)\n",
    "\n",
    "        # scores\n",
    "        batch_metrics, scores = self.calculate_step_metric(predictions, gt, image_names)\n",
    "        batch_metrics[\"tissue_types\"] = tissue_types\n",
    "        if generate_plots:\n",
    "            self.plot_results(\n",
    "                imgs=imgs,\n",
    "                predictions=predictions,\n",
    "                ground_truth=gt,\n",
    "                img_names=image_names,\n",
    "                num_nuclei_classes=self.num_classes,\n",
    "                outdir=Path(self.run_dir / \"inference_predictions\"),\n",
    "                scores=scores,\n",
    "            )\n",
    "\n",
    "        return batch_metrics\n",
    "\n",
    "    def unpack_predictions(\n",
    "        self, predictions: dict, model: CellViT\n",
    "    ) -> DataclassHVStorage:\n",
    "        \"\"\"Unpack the given predictions. Main focus lays on reshaping and postprocessing predictions, e.g. separating instances\n",
    "\n",
    "        Args:\n",
    "            predictions (dict): Dictionary with the following keys:\n",
    "                * tissue_types: Logit tissue prediction output. Shape: (batch_size, num_tissue_classes)\n",
    "                * nuclei_binary_map: Logit output for binary nuclei prediction branch. Shape: (batch_size, H, W, 2)\n",
    "                * hv_map: Logit output for hv-prediction. Shape: (batch_size, H, W, 2)\n",
    "                * nuclei_type_map: Logit output for nuclei instance-prediction. Shape: (batch_size, num_nuclei_classes, H, W)\n",
    "            model (CellViT): Current model\n",
    "\n",
    "        Returns:\n",
    "            DataclassHVStorage: Processed network output\n",
    "\n",
    "        \"\"\"\n",
    "        predictions[\"tissue_types\"] = predictions[\"tissue_types\"].to(self.device)\n",
    "        predictions[\"nuclei_binary_map\"] = F.softmax(\n",
    "            predictions[\"nuclei_binary_map\"], dim=1\n",
    "        )  # shape: (batch_size, 2, H, W)\n",
    "        predictions[\"nuclei_type_map\"] = F.softmax(\n",
    "            predictions[\"nuclei_type_map\"], dim=1\n",
    "        )  # shape: (batch_size, num_nuclei_classes, H, W)\n",
    "        (\n",
    "            predictions[\"instance_map\"],\n",
    "            predictions[\"instance_types\"],\n",
    "        ) = model.calculate_instance_map(\n",
    "            predictions, magnification=self.magnification\n",
    "        )  # shape: (batch_size, H', W')\n",
    "        predictions[\"instance_types_nuclei\"] = model.generate_instance_nuclei_map(\n",
    "            predictions[\"instance_map\"], predictions[\"instance_types\"]\n",
    "        ).to(\n",
    "            self.device\n",
    "        )  # shape: (batch_size, num_nuclei_classes, H, W)\n",
    "        predictions = DataclassHVStorage(\n",
    "            nuclei_binary_map=predictions[\"nuclei_binary_map\"],\n",
    "            hv_map=predictions[\"hv_map\"],\n",
    "            nuclei_type_map=predictions[\"nuclei_type_map\"],\n",
    "            tissue_types=predictions[\"tissue_types\"],\n",
    "            instance_map=predictions[\"instance_map\"],\n",
    "            instance_types=predictions[\"instance_types\"],\n",
    "            instance_types_nuclei=predictions[\"instance_types_nuclei\"],\n",
    "            batch_size=predictions[\"tissue_types\"].shape[0],\n",
    "        )\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def unpack_masks(\n",
    "        self, masks: dict, tissue_types: list, model: CellViT\n",
    "    ) -> DataclassHVStorage:\n",
    "        # get ground truth values, perform one hot encoding for segmentation maps\n",
    "        gt_nuclei_binary_map_onehot = (\n",
    "            F.one_hot(masks[\"nuclei_binary_map\"], num_classes=2)\n",
    "        ).type(\n",
    "            torch.float32\n",
    "        )  # background, nuclei\n",
    "        nuclei_type_maps = torch.squeeze(masks[\"nuclei_type_map\"]).type(torch.int64)\n",
    "        gt_nuclei_type_maps_onehot = F.one_hot(\n",
    "            nuclei_type_maps, num_classes=self.num_classes\n",
    "        ).type(\n",
    "            torch.float32\n",
    "        )  # background + nuclei types\n",
    "\n",
    "        # assemble ground truth dictionary\n",
    "        gt = {\n",
    "            \"nuclei_type_map\": gt_nuclei_type_maps_onehot.permute(0, 3, 1, 2).to(\n",
    "                self.device\n",
    "            ),  # shape: (batch_size, H, W, num_nuclei_classes)\n",
    "            \"nuclei_binary_map\": gt_nuclei_binary_map_onehot.permute(0, 3, 1, 2).to(\n",
    "                self.device\n",
    "            ),  # shape: (batch_size, H, W, 2)\n",
    "            \"hv_map\": masks[\"hv_map\"].to(self.device),  # shape: (batch_size, H, W, 2)\n",
    "            \"instance_map\": masks[\"instance_map\"].to(\n",
    "                self.device\n",
    "            ),  # shape: (batch_size, H, W) -> each instance has one integer\n",
    "            \"instance_types_nuclei\": (\n",
    "                gt_nuclei_type_maps_onehot * masks[\"instance_map\"][..., None]\n",
    "            )\n",
    "            .permute(0, 3, 1, 2)\n",
    "            .to(\n",
    "                self.device\n",
    "            ),  # shape: (batch_size, num_nuclei_classes, H, W) -> instance has one integer, for each nuclei class\n",
    "            \"tissue_types\": torch.Tensor(\n",
    "                [self.dataset_config[\"tissue_types\"][t] for t in tissue_types]\n",
    "            )\n",
    "            .type(torch.LongTensor)\n",
    "            .to(self.device),  # shape: batch_size\n",
    "        }\n",
    "        gt[\"instance_types\"] = calculate_instances(\n",
    "            gt[\"nuclei_type_map\"], gt[\"instance_map\"]\n",
    "        )\n",
    "        gt = DataclassHVStorage(**gt, batch_size=gt[\"tissue_types\"].shape[0])\n",
    "        return gt\n",
    "\n",
    "    def calculate_step_metric(\n",
    "        self,\n",
    "        predictions: DataclassHVStorage,\n",
    "        gt: DataclassHVStorage,\n",
    "        image_names: list[str],\n",
    "    ) -> Tuple[dict, list]:\n",
    "        \"\"\"Calculate the metrics for the validation step\n",
    "\n",
    "        Args:\n",
    "            predictions (DataclassHVStorage): Processed network output\n",
    "            gt (DataclassHVStorage): Ground truth values\n",
    "            image_names (list(str)): List with image names\n",
    "\n",
    "        Returns:\n",
    "            Tuple[dict, list]:\n",
    "                * dict: Dictionary with metrics. Structure not fixed yet\n",
    "                * list with cell_dice, cell_jaccard and pq for each image\n",
    "        \"\"\"\n",
    "        predictions = predictions.get_dict()\n",
    "        gt = gt.get_dict()\n",
    "\n",
    "        # preparation and device movement\n",
    "        predictions[\"tissue_types_classes\"] = F.softmax(\n",
    "            predictions[\"tissue_types\"], dim=-1\n",
    "        )\n",
    "        pred_tissue = (\n",
    "            torch.argmax(predictions[\"tissue_types_classes\"], dim=-1)\n",
    "            .detach()\n",
    "            .cpu()\n",
    "            .numpy()\n",
    "            .astype(np.uint8)\n",
    "        )\n",
    "        predictions[\"instance_map\"] = predictions[\"instance_map\"].detach().cpu()\n",
    "        predictions[\"instance_types_nuclei\"] = (\n",
    "            predictions[\"instance_types_nuclei\"].detach().cpu().numpy().astype(\"int32\")\n",
    "        )\n",
    "        instance_maps_gt = gt[\"instance_map\"].detach().cpu()\n",
    "        gt[\"tissue_types\"] = gt[\"tissue_types\"].detach().cpu().numpy().astype(np.uint8)\n",
    "        gt[\"nuclei_binary_map\"] = torch.argmax(gt[\"nuclei_binary_map\"], dim=1).type(\n",
    "            torch.uint8\n",
    "        )\n",
    "        gt[\"instance_types_nuclei\"] = (\n",
    "            gt[\"instance_types_nuclei\"].detach().cpu().numpy().astype(\"int32\")\n",
    "        )\n",
    "\n",
    "        # segmentation scores\n",
    "        binary_dice_scores = []  # binary dice scores per image\n",
    "        binary_jaccard_scores = []  # binary jaccard scores per image\n",
    "        pq_scores = []  # pq-scores per image\n",
    "        dq_scores = []  # dq-scores per image\n",
    "        sq_scores = []  # sq_scores per image\n",
    "        cell_type_pq_scores = []  # pq-scores per cell type and image\n",
    "        cell_type_dq_scores = []  # dq-scores per cell type and image\n",
    "        cell_type_sq_scores = []  # sq-scores per cell type and image\n",
    "        scores = []  # all scores in one list\n",
    "\n",
    "        # detection scores\n",
    "        paired_all = []  # unique matched index pair\n",
    "        unpaired_true_all = (\n",
    "            []\n",
    "        )  # the index must exist in `true_inst_type_all` and unique\n",
    "        unpaired_pred_all = (\n",
    "            []\n",
    "        )  # the index must exist in `pred_inst_type_all` and unique\n",
    "        true_inst_type_all = []  # each index is 1 independent data point\n",
    "        pred_inst_type_all = []  # each index is 1 independent data point\n",
    "\n",
    "        # for detections scores\n",
    "        true_idx_offset = 0\n",
    "        pred_idx_offset = 0\n",
    "\n",
    "        for i in range(len(pred_tissue)):\n",
    "            # binary dice score: Score for cell detection per image, without background\n",
    "            pred_binary_map = torch.argmax(predictions[\"nuclei_binary_map\"][i], dim=0)\n",
    "            target_binary_map = gt[\"nuclei_binary_map\"][i]\n",
    "            cell_dice = (\n",
    "                dice(preds=pred_binary_map, target=target_binary_map, ignore_index=0)\n",
    "                .detach()\n",
    "                .cpu()\n",
    "            )\n",
    "            binary_dice_scores.append(float(cell_dice))\n",
    "\n",
    "            # binary aji\n",
    "            cell_jaccard = (\n",
    "                binary_jaccard_index(\n",
    "                    preds=pred_binary_map,\n",
    "                    target=target_binary_map,\n",
    "                )\n",
    "                .detach()\n",
    "                .cpu()\n",
    "            )\n",
    "            binary_jaccard_scores.append(float(cell_jaccard))\n",
    "\n",
    "            # pq values\n",
    "            if len(np.unique(instance_maps_gt[i])) == 1:\n",
    "                dq, sq, pq = np.nan, np.nan, np.nan\n",
    "            else:\n",
    "                remapped_instance_pred = binarize(\n",
    "                    predictions[\"instance_types_nuclei\"][i][1:].transpose(1, 2, 0)\n",
    "                )\n",
    "                remapped_gt = remap_label(instance_maps_gt[i])\n",
    "                [dq, sq, pq], _ = get_fast_pq(\n",
    "                    true=remapped_gt, pred=remapped_instance_pred\n",
    "                )\n",
    "            pq_scores.append(pq)\n",
    "            dq_scores.append(dq)\n",
    "            sq_scores.append(sq)\n",
    "            scores.append(\n",
    "                [\n",
    "                    cell_dice.detach().cpu().numpy(),\n",
    "                    cell_jaccard.detach().cpu().numpy(),\n",
    "                    pq,\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            # pq values per class (with class 0 beeing background -> should be skipped in the future)\n",
    "            nuclei_type_pq = []\n",
    "            nuclei_type_dq = []\n",
    "            nuclei_type_sq = []\n",
    "            for j in range(0, self.num_classes):\n",
    "                pred_nuclei_instance_class = remap_label(\n",
    "                    predictions[\"instance_types_nuclei\"][i][j, ...]\n",
    "                )\n",
    "                target_nuclei_instance_class = remap_label(\n",
    "                    gt[\"instance_types_nuclei\"][i][j, ...]\n",
    "                )\n",
    "\n",
    "                # if ground truth is empty, skip from calculation\n",
    "                if len(np.unique(target_nuclei_instance_class)) == 1:\n",
    "                    pq_tmp = np.nan\n",
    "                    dq_tmp = np.nan\n",
    "                    sq_tmp = np.nan\n",
    "                else:\n",
    "                    [dq_tmp, sq_tmp, pq_tmp], _ = get_fast_pq(\n",
    "                        pred_nuclei_instance_class,\n",
    "                        target_nuclei_instance_class,\n",
    "                        match_iou=0.5,\n",
    "                    )\n",
    "                nuclei_type_pq.append(pq_tmp)\n",
    "                nuclei_type_dq.append(dq_tmp)\n",
    "                nuclei_type_sq.append(sq_tmp)\n",
    "\n",
    "            # detection scores\n",
    "            true_centroids = np.array(\n",
    "                [v[\"centroid\"] for k, v in gt[\"instance_types\"][i].items()]\n",
    "            )\n",
    "            true_instance_type = np.array(\n",
    "                [v[\"type\"] for k, v in gt[\"instance_types\"][i].items()]\n",
    "            )\n",
    "            pred_centroids = np.array(\n",
    "                [v[\"centroid\"] for k, v in predictions[\"instance_types\"][i].items()]\n",
    "            )\n",
    "            pred_instance_type = np.array(\n",
    "                [v[\"type\"] for k, v in predictions[\"instance_types\"][i].items()]\n",
    "            )\n",
    "\n",
    "            if true_centroids.shape[0] == 0:\n",
    "                true_centroids = np.array([[0, 0]])\n",
    "                true_instance_type = np.array([0])\n",
    "            if pred_centroids.shape[0] == 0:\n",
    "                pred_centroids = np.array([[0, 0]])\n",
    "                pred_instance_type = np.array([0])\n",
    "            if self.magnification == 40:\n",
    "                pairing_radius = 12\n",
    "            else:\n",
    "                pairing_radius = 6\n",
    "            paired, unpaired_true, unpaired_pred = pair_coordinates(\n",
    "                true_centroids, pred_centroids, pairing_radius\n",
    "            )\n",
    "            true_idx_offset = (\n",
    "                true_idx_offset + true_inst_type_all[-1].shape[0] if i != 0 else 0\n",
    "            )\n",
    "            pred_idx_offset = (\n",
    "                pred_idx_offset + pred_inst_type_all[-1].shape[0] if i != 0 else 0\n",
    "            )\n",
    "            true_inst_type_all.append(true_instance_type)\n",
    "            pred_inst_type_all.append(pred_instance_type)\n",
    "\n",
    "            # increment the pairing index statistic\n",
    "            if paired.shape[0] != 0:  # ! sanity\n",
    "                paired[:, 0] += true_idx_offset\n",
    "                paired[:, 1] += pred_idx_offset\n",
    "                paired_all.append(paired)\n",
    "\n",
    "            unpaired_true += true_idx_offset\n",
    "            unpaired_pred += pred_idx_offset\n",
    "            unpaired_true_all.append(unpaired_true)\n",
    "            unpaired_pred_all.append(unpaired_pred)\n",
    "\n",
    "            cell_type_pq_scores.append(nuclei_type_pq)\n",
    "            cell_type_dq_scores.append(nuclei_type_dq)\n",
    "            cell_type_sq_scores.append(nuclei_type_sq)\n",
    "\n",
    "        paired_all = np.concatenate(paired_all, axis=0)\n",
    "        unpaired_true_all = np.concatenate(unpaired_true_all, axis=0)\n",
    "        unpaired_pred_all = np.concatenate(unpaired_pred_all, axis=0)\n",
    "        true_inst_type_all = np.concatenate(true_inst_type_all, axis=0)\n",
    "        pred_inst_type_all = np.concatenate(pred_inst_type_all, axis=0)\n",
    "\n",
    "        batch_metrics = {\n",
    "            \"image_names\": image_names,\n",
    "            \"binary_dice_scores\": binary_dice_scores,\n",
    "            \"binary_jaccard_scores\": binary_jaccard_scores,\n",
    "            \"pq_scores\": pq_scores,\n",
    "            \"dq_scores\": dq_scores,\n",
    "            \"sq_scores\": sq_scores,\n",
    "            \"cell_type_pq_scores\": cell_type_pq_scores,\n",
    "            \"cell_type_dq_scores\": cell_type_dq_scores,\n",
    "            \"cell_type_sq_scores\": cell_type_sq_scores,\n",
    "            \"tissue_pred\": pred_tissue,\n",
    "            \"tissue_gt\": gt[\"tissue_types\"],\n",
    "            \"paired_all\": paired_all,\n",
    "            \"unpaired_true_all\": unpaired_true_all,\n",
    "            \"unpaired_pred_all\": unpaired_pred_all,\n",
    "            \"true_inst_type_all\": true_inst_type_all,\n",
    "            \"pred_inst_type_all\": pred_inst_type_all,\n",
    "        }\n",
    "\n",
    "        return batch_metrics, scores\n",
    "\n",
    "    def plot_results(\n",
    "        self,\n",
    "        imgs: Union[torch.Tensor, np.ndarray],\n",
    "        predictions: dict,\n",
    "        ground_truth: dict,\n",
    "        img_names: List,\n",
    "        num_nuclei_classes: int,\n",
    "        outdir: Union[Path, str],\n",
    "        scores: List[List[float]] = None,\n",
    "    ) -> None:\n",
    "        # TODO: Adapt Docstring and function, currently not working with our shape\n",
    "        \"\"\"Generate example plot with image, binary_pred, hv-map and instance map from prediction and ground-truth\n",
    "\n",
    "        Args:\n",
    "            imgs (Union[torch.Tensor, np.ndarray]): Images to process, a random number (num_images) is selected from this stack\n",
    "                Shape: (batch_size, 3, H', W')\n",
    "            predictions (dict): Predictions of models. Keys:\n",
    "                \"nuclei_type_map\": Shape: (batch_size, H', W', num_nuclei)\n",
    "                \"nuclei_binary_map\": Shape: (batch_size, H', W', 2)\n",
    "                \"hv_map\": Shape: (batch_size, H', W', 2)\n",
    "                \"instance_map\": Shape: (batch_size, H', W')\n",
    "            ground_truth (dict): Ground truth values. Keys:\n",
    "                \"nuclei_type_map\": Shape: (batch_size, H', W', num_nuclei)\n",
    "                \"nuclei_binary_map\": Shape: (batch_size, H', W', 2)\n",
    "                \"hv_map\": Shape: (batch_size, H', W', 2)\n",
    "                \"instance_map\": Shape: (batch_size, H', W')\n",
    "            img_names (List): Names of images as list\n",
    "            num_nuclei_classes (int): Number of total nuclei classes including background\n",
    "            outdir (Union[Path, str]): Output directory where images should be stored\n",
    "            scores (List[List[float]], optional): List with scores for each image.\n",
    "                Each list entry is a list with 3 scores: Dice, Jaccard and bPQ for the image.\n",
    "                Defaults to None.\n",
    "        \"\"\"\n",
    "        outdir = Path(outdir)\n",
    "        outdir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "        h = ground_truth[\"hv_map\"].shape[1]\n",
    "        w = ground_truth[\"hv_map\"].shape[2]\n",
    "\n",
    "        # convert to rgb and crop to selection\n",
    "        sample_images = (\n",
    "            imgs.permute(0, 2, 3, 1).contiguous().cpu().numpy()\n",
    "        )  # convert to rgb\n",
    "        sample_images = cropping_center(sample_images, (h, w), True)\n",
    "\n",
    "        pred_sample_binary_map = (\n",
    "            predictions[\"nuclei_binary_map\"][:, :, :, 1].detach().cpu().numpy()\n",
    "        )\n",
    "        pred_sample_hv_map = predictions[\"hv_map\"].detach().cpu().numpy()\n",
    "        pred_sample_instance_maps = predictions[\"instance_map\"].detach().cpu().numpy()\n",
    "        pred_sample_type_maps = (\n",
    "            torch.argmax(predictions[\"nuclei_type_map\"], dim=-1).detach().cpu().numpy()\n",
    "        )\n",
    "\n",
    "        # get ground truth labels\n",
    "        # gt_sample_binary_map = (\n",
    "        #     torch.argmax(ground_truth[\"nuclei_binary_map\"], dim=-1).detach().cpu()\n",
    "        # )\n",
    "        gt_sample_binary_map = ground_truth[\"nuclei_binary_map\"].detach().cpu().numpy()\n",
    "        gt_sample_hv_map = ground_truth[\"hv_map\"].detach().cpu().numpy()\n",
    "        gt_sample_instance_map = ground_truth[\"instance_map\"].detach().cpu().numpy()\n",
    "        gt_sample_type_map = (\n",
    "            torch.argmax(ground_truth[\"nuclei_type_map\"], dim=-1).detach().cpu().numpy()\n",
    "        )\n",
    "\n",
    "        # create colormaps\n",
    "        hv_cmap = plt.get_cmap(\"jet\")\n",
    "        binary_cmap = plt.get_cmap(\"jet\")\n",
    "        instance_map = plt.get_cmap(\"viridis\")\n",
    "        cell_colors = [\"#ffffff\", \"#ff0000\", \"#00ff00\", \"#1e00ff\", \"#feff00\", \"#ffbf00\"]\n",
    "\n",
    "        # invert the normalization of the sample images\n",
    "        transform_settings = self.run_conf[\"transformations\"]\n",
    "        if \"normalize\" in transform_settings:\n",
    "            mean = transform_settings[\"normalize\"].get(\"mean\", (0.5, 0.5, 0.5))\n",
    "            std = transform_settings[\"normalize\"].get(\"std\", (0.5, 0.5, 0.5))\n",
    "        else:\n",
    "            mean = (0.5, 0.5, 0.5)\n",
    "            std = (0.5, 0.5, 0.5)\n",
    "        inv_normalize = transforms.Normalize(\n",
    "            mean=[-0.5 / mean[0], -0.5 / mean[1], -0.5 / mean[2]],\n",
    "            std=[1 / std[0], 1 / std[1], 1 / std[2]],\n",
    "        )\n",
    "        inv_samples = inv_normalize(torch.tensor(sample_images).permute(0, 3, 1, 2))\n",
    "        sample_images = inv_samples.permute(0, 2, 3, 1).detach().cpu().numpy()\n",
    "\n",
    "        for i in range(len(img_names)):\n",
    "            fig, axs = plt.subplots(figsize=(6, 2), dpi=300)\n",
    "            placeholder = np.zeros((2 * h, 7 * w, 3))\n",
    "            # orig image\n",
    "            placeholder[:h, :w, :3] = sample_images[i]\n",
    "            placeholder[h : 2 * h, :w, :3] = sample_images[i]\n",
    "            # binary prediction\n",
    "            placeholder[:h, w : 2 * w, :3] = rgba2rgb(\n",
    "                binary_cmap(gt_sample_binary_map[i] * 255)\n",
    "            )\n",
    "            placeholder[h : 2 * h, w : 2 * w, :3] = rgba2rgb(\n",
    "                binary_cmap(pred_sample_binary_map[i])\n",
    "            )  # *255?\n",
    "            # hv maps\n",
    "            placeholder[:h, 2 * w : 3 * w, :3] = rgba2rgb(\n",
    "                hv_cmap((gt_sample_hv_map[i, :, :, 0] + 1) / 2)\n",
    "            )\n",
    "            placeholder[h : 2 * h, 2 * w : 3 * w, :3] = rgba2rgb(\n",
    "                hv_cmap((pred_sample_hv_map[i, :, :, 0] + 1) / 2)\n",
    "            )\n",
    "            placeholder[:h, 3 * w : 4 * w, :3] = rgba2rgb(\n",
    "                hv_cmap((gt_sample_hv_map[i, :, :, 1] + 1) / 2)\n",
    "            )\n",
    "            placeholder[h : 2 * h, 3 * w : 4 * w, :3] = rgba2rgb(\n",
    "                hv_cmap((pred_sample_hv_map[i, :, :, 1] + 1) / 2)\n",
    "            )\n",
    "            # instance_predictions\n",
    "            placeholder[:h, 4 * w : 5 * w, :3] = rgba2rgb(\n",
    "                instance_map(\n",
    "                    (gt_sample_instance_map[i] - np.min(gt_sample_instance_map[i]))\n",
    "                    / (\n",
    "                        np.max(gt_sample_instance_map[i])\n",
    "                        - np.min(gt_sample_instance_map[i] + 1e-10)\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "            placeholder[h : 2 * h, 4 * w : 5 * w, :3] = rgba2rgb(\n",
    "                instance_map(\n",
    "                    (\n",
    "                        pred_sample_instance_maps[i]\n",
    "                        - np.min(pred_sample_instance_maps[i])\n",
    "                    )\n",
    "                    / (\n",
    "                        np.max(pred_sample_instance_maps[i])\n",
    "                        - np.min(pred_sample_instance_maps[i] + 1e-10)\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "            # type_predictions\n",
    "            placeholder[:h, 5 * w : 6 * w, :3] = rgba2rgb(\n",
    "                binary_cmap(gt_sample_type_map[i] / num_nuclei_classes)\n",
    "            )\n",
    "            placeholder[h : 2 * h, 5 * w : 6 * w, :3] = rgba2rgb(\n",
    "                binary_cmap(pred_sample_type_maps[i] / num_nuclei_classes)\n",
    "            )\n",
    "\n",
    "            # contours\n",
    "            # gt\n",
    "            gt_contours_polygon = [\n",
    "                v[\"contour\"] for v in ground_truth[\"instance_types\"][i].values()\n",
    "            ]\n",
    "            gt_contours_polygon = [\n",
    "                list(zip(poly[:, 0], poly[:, 1])) for poly in gt_contours_polygon\n",
    "            ]\n",
    "            gt_contour_colors_polygon = [\n",
    "                cell_colors[v[\"type\"]]\n",
    "                for v in ground_truth[\"instance_types\"][i].values()\n",
    "            ]\n",
    "            gt_cell_image = Image.fromarray(\n",
    "                (sample_images[i] * 255).astype(np.uint8)\n",
    "            ).convert(\"RGB\")\n",
    "            gt_drawing = ImageDraw.Draw(gt_cell_image)\n",
    "            add_patch = lambda poly, color: gt_drawing.polygon(\n",
    "                poly, outline=color, width=2\n",
    "            )\n",
    "            [\n",
    "                add_patch(poly, c)\n",
    "                for poly, c in zip(gt_contours_polygon, gt_contour_colors_polygon)\n",
    "            ]\n",
    "            gt_cell_image.save(outdir / f\"raw_gt_{img_names[i]}\")\n",
    "            placeholder[:h, 6 * w : 7 * w, :3] = np.asarray(gt_cell_image) / 255\n",
    "            # pred\n",
    "            pred_contours_polygon = [\n",
    "                v[\"contour\"] for v in predictions[\"instance_types\"][i].values()\n",
    "            ]\n",
    "            pred_contours_polygon = [\n",
    "                list(zip(poly[:, 0], poly[:, 1])) for poly in pred_contours_polygon\n",
    "            ]\n",
    "            pred_contour_colors_polygon = [\n",
    "                cell_colors[v[\"type\"]]\n",
    "                for v in predictions[\"instance_types\"][i].values()\n",
    "            ]\n",
    "            pred_cell_image = Image.fromarray(\n",
    "                (sample_images[i] * 255).astype(np.uint8)\n",
    "            ).convert(\"RGB\")\n",
    "            pred_drawing = ImageDraw.Draw(pred_cell_image)\n",
    "            add_patch = lambda poly, color: pred_drawing.polygon(\n",
    "                poly, outline=color, width=2\n",
    "            )\n",
    "            [\n",
    "                add_patch(poly, c)\n",
    "                for poly, c in zip(pred_contours_polygon, pred_contour_colors_polygon)\n",
    "            ]\n",
    "            pred_cell_image.save(outdir / f\"raw_pred_{img_names[i]}\")\n",
    "            placeholder[h : 2 * h, 6 * w : 7 * w, :3] = (\n",
    "                np.asarray(pred_cell_image) / 255\n",
    "            )\n",
    "\n",
    "            # plotting\n",
    "            axs.imshow(placeholder)\n",
    "            axs.set_xticks(np.arange(w / 2, 7 * w, w))\n",
    "            axs.set_xticklabels(\n",
    "                [\n",
    "                    \"Image\",\n",
    "                    \"Binary-Cells\",\n",
    "                    \"HV-Map-0\",\n",
    "                    \"HV-Map-1\",\n",
    "                    \"Instances\",\n",
    "                    \"Nuclei-Pred\",\n",
    "                    \"Countours\",\n",
    "                ],\n",
    "                fontsize=6,\n",
    "            )\n",
    "            axs.xaxis.tick_top()\n",
    "\n",
    "            axs.set_yticks(np.arange(h / 2, 2 * h, h))\n",
    "            axs.set_yticklabels([\"GT\", \"Pred.\"], fontsize=6)\n",
    "            axs.tick_params(axis=\"both\", which=\"both\", length=0)\n",
    "            grid_x = np.arange(w, 6 * w, w)\n",
    "            grid_y = np.arange(h, 2 * h, h)\n",
    "\n",
    "            for x_seg in grid_x:\n",
    "                axs.axvline(x_seg, color=\"black\")\n",
    "            for y_seg in grid_y:\n",
    "                axs.axhline(y_seg, color=\"black\")\n",
    "\n",
    "            if scores is not None:\n",
    "                axs.text(\n",
    "                    20,\n",
    "                    1.85 * h,\n",
    "                    f\"Dice: {str(np.round(scores[i][0], 2))}\\nJac.: {str(np.round(scores[i][1], 2))}\\nbPQ: {str(np.round(scores[i][2], 2))}\",\n",
    "                    bbox={\"facecolor\": \"white\", \"pad\": 2, \"alpha\": 0.5},\n",
    "                    fontsize=4,\n",
    "                )\n",
    "            fig.suptitle(f\"Patch Predictions for {img_names[i]}\")\n",
    "            fig.tight_layout()\n",
    "            fig.savefig(outdir / f\"pred_{img_names[i]}\")\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "# CLI\n",
    "class InferenceCellViTParser:\n",
    "    def __init__(self) -> None:\n",
    "        parser = argparse.ArgumentParser(\n",
    "            formatter_class=argparse.ArgumentDefaultsHelpFormatter,\n",
    "            description=\"Perform CellViT inference for given run-directory with model checkpoints and logs\",\n",
    "        )\n",
    "\n",
    "        parser.add_argument(\n",
    "            \"--run_dir\",\n",
    "            type=str,\n",
    "            help=\"Logging directory of a training run.\",\n",
    "            required=True,\n",
    "        )\n",
    "        parser.add_argument(\n",
    "            \"--checkpoint_name\",\n",
    "            type=str,\n",
    "            help=\"Name of the checkpoint.  Either select 'best_checkpoint.pth',\"\n",
    "            \"'latest_checkpoint.pth' or one of the intermediate checkpoint names,\"\n",
    "            \"e.g., 'checkpoint_100.pth'\",\n",
    "            default=\"model_best.pth\",\n",
    "        )\n",
    "        parser.add_argument(\n",
    "            \"--gpu\", type=int, help=\"Cuda-GPU ID for inference\", default=5\n",
    "        )\n",
    "        parser.add_argument(\n",
    "            \"--magnification\",\n",
    "            type=int,\n",
    "            help=\"Dataset Magnification. Either 20 or 40. Default: 40\",\n",
    "            choices=[20, 40],\n",
    "            default=40,\n",
    "        )\n",
    "        parser.add_argument(\n",
    "            \"--plots\",\n",
    "            action=\"store_true\",\n",
    "            help=\"Generate inference plots in run_dir\",\n",
    "        )\n",
    "\n",
    "        self.parser = parser\n",
    "\n",
    "    def parse_arguments(self) -> dict:\n",
    "        opt = self.parser.parse_args()\n",
    "        return vars(opt)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    configuration_parser = InferenceCellViTParser()\n",
    "    configuration = configuration_parser.parse_arguments()\n",
    "    print(configuration)\n",
    "    inf = InferenceCellViT(\n",
    "        run_dir=configuration[\"run_dir\"],\n",
    "        checkpoint_name=configuration[\"checkpoint_name\"],\n",
    "        gpu=configuration[\"gpu\"],\n",
    "        magnification=configuration[\"magnification\"],\n",
    "    )\n",
    "    model, dataloader, conf = inf.setup_patch_inference()\n",
    "\n",
    "    inf.run_patch_inference(\n",
    "        model, dataloader, conf, generate_plots=configuration[\"plots\"]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77123b94-a5fc-428b-a896-096d1a768cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2220379-66ce-4489-a004-fa870c228424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (23.3.1)\n",
      "Collecting pip\n",
      "  Downloading pip-24.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Downloading pip-24.2-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "Successfully installed pip-24.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1963b2e1-17bb-48e1-9bc0-be0db4385c4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
