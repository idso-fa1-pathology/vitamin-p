{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "683c7ed8-4422-4770-aaa2-6dd7da37e7f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: zarr<3 in ./.local/lib/python3.11/site-packages (2.18.7)\n",
      "Requirement already satisfied: asciitree in ./.local/lib/python3.11/site-packages (from zarr<3) (0.3.3)\n",
      "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from zarr<3) (1.26.2)\n",
      "Requirement already satisfied: fasteners in ./.local/lib/python3.11/site-packages (from zarr<3) (0.20)\n",
      "Requirement already satisfied: numcodecs!=0.14.0,!=0.14.1,<0.16,>=0.10.0 in ./.local/lib/python3.11/site-packages (from zarr<3) (0.15.1)\n",
      "Requirement already satisfied: deprecated in ./.local/lib/python3.11/site-packages (from numcodecs!=0.14.0,!=0.14.1,<0.16,>=0.10.0->zarr<3) (1.3.1)\n",
      "Requirement already satisfied: wrapt<3,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated->numcodecs!=0.14.0,!=0.14.1,<0.16,>=0.10.0->zarr<3) (1.14.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: timm in ./.local/lib/python3.11/site-packages (1.0.24)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from timm) (2.1.2)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm) (0.16.2)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm) (6.0.1)\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.20.2)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2023.12.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.64.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.8.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (23.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->timm) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->timm) (12.3.101)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (1.26.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (10.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->timm) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->timm) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install 'zarr<3'\n",
    "!pip install timm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3aea9fb2-5fc5-4964-9d01-950bafa8c6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Working directory: /rsrch9/home/plm/idso_fa1_pathology/codes/yshokrollahi/vitamin-p-latest\n"
     ]
    }
   ],
   "source": [
    "# ALWAYS RUN THIS FIRST!\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "NOTEBOOK_DIR = Path(\"/rsrch9/home/plm/idso_fa1_pathology/codes/yshokrollahi/vitamin-p-latest\")\n",
    "os.chdir(NOTEBOOK_DIR)\n",
    "sys.path.insert(0, str(NOTEBOOK_DIR))\n",
    "\n",
    "print(f\"âœ… Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9306d8e4-becf-4251-aa11-69871841ba16",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a980a20-2ac1-460b-b9e5-e07db852b2eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CRC DATASET CONFIGURATION\n",
      "================================================================================\n",
      "Config File: configs/config_fold2.yaml\n",
      "Zarr Base: /rsrch9/home/plm/idso_fa1_pathology/TIER2/yasin-vitaminp/ORION-CRC/zarr_data\n",
      "Cache: Disabled\n",
      "Strategy: memory\n",
      "\n",
      "ðŸ“Š Data Splits:\n",
      "  Train: 33 samples\n",
      "  Val: 9 samples\n",
      "  Test: 8 samples\n",
      "\n",
      "ðŸ”„ DataLoader:\n",
      "  Batch Size: 4\n",
      "  Num Workers: 0\n",
      "  Pin Memory: True\n",
      "\n",
      "ðŸŽ¨ Augmentation:\n",
      "  Training: True\n",
      "  Probability: 0.0\n",
      "\n",
      "ðŸŽ¯ HV Maps:\n",
      "  Generate: True\n",
      "  Method: pannuke\n",
      "  HE Nuclei: True\n",
      "  HE Cells: True\n",
      "  MIF Nuclei: True\n",
      "  MIF Cells: True\n",
      "\n",
      "ðŸ” Filtering:\n",
      "  Min Instances: 0\n",
      "  Filter Empty: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "CREATING DATALOADERS\n",
      "================================================================================\n",
      "Strategy: memory\n",
      "Use Cache: False\n",
      "Batch Size: 4\n",
      "Num Workers: 0\n",
      "\n",
      "Train split: 27 CRC + 6 Xenium samples\n",
      "Val split: 7 CRC + 2 Xenium samples\n",
      "Test split: 7 CRC + 1 Xenium samples\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š Building patch index for 33 samples...\n",
      "  âœ… CRC01 (CRC): 36 patches\n",
      "  âœ… CRC02 (CRC): 75 patches\n",
      "  âœ… CRC03 (CRC): 43 patches\n",
      "  âœ… CRC04 (CRC): 118 patches\n",
      "  âœ… CRC05 (CRC): 696 patches\n",
      "  âœ… CRC06 (CRC): 147 patches\n",
      "  âœ… CRC07 (CRC): 130 patches\n",
      "  âœ… CRC14 (CRC): 18 patches\n",
      "  âœ… CRC15 (CRC): 18 patches\n",
      "  âœ… CRC16 (CRC): 142 patches\n",
      "  âœ… CRC17 (CRC): 76 patches\n",
      "  âœ… CRC18 (CRC): 80 patches\n",
      "  âœ… CRC19 (CRC): 29 patches\n",
      "  âœ… CRC20 (CRC): 35 patches\n",
      "  âœ… CRC28 (CRC): 92 patches\n",
      "  âœ… CRC29 (CRC): 53 patches\n",
      "  âœ… CRC30 (CRC): 71 patches\n",
      "  âœ… CRC31 (CRC): 149 patches\n",
      "  âœ… CRC32 (CRC): 123 patches\n",
      "  âœ… CRC33_01 (CRC): 25 patches\n",
      "  âœ… CRC33_02 (CRC): 52 patches\n",
      "  âœ… CRC34 (CRC): 119 patches\n",
      "  âœ… CRC35 (CRC): 54 patches\n",
      "  âœ… CRC36 (CRC): 30 patches\n",
      "  âœ… CRC37 (CRC): 63 patches\n",
      "  âœ… CRC38 (CRC): 99 patches\n",
      "  âœ… CRC39 (CRC): 62 patches\n",
      "  âœ… breast (Xenium): 145 patches\n",
      "  âœ… cervical (Xenium): 54 patches\n",
      "  âœ… pancreasV1 (Xenium): 78 patches\n",
      "  âœ… prostate (Xenium): 1011 patches\n",
      "  âœ… skin (Xenium): 205 patches\n",
      "  âœ… lung (Xenium): 66 patches\n",
      "Training Dataset: 33 samples, 4194 patches\n",
      "ðŸ“Š Building patch index for 9 samples...\n",
      "  âœ… CRC08 (CRC): 115 patches\n",
      "  âœ… CRC09 (CRC): 57 patches\n",
      "  âœ… CRC10 (CRC): 27 patches\n",
      "  âœ… CRC11 (CRC): 13 patches\n",
      "  âœ… CRC12 (CRC): 69 patches\n",
      "  âœ… CRC13 (CRC): 38 patches\n",
      "  âœ… CRC40 (CRC): 68 patches\n",
      "  âœ… lungV1 (Xenium): 203 patches\n",
      "  âœ… lymph_node (Xenium): 53 patches\n",
      "Validation/Test Dataset: 9 samples, 643 patches\n",
      "ðŸ“Š Building patch index for 8 samples...\n",
      "  âœ… CRC21 (CRC): 20 patches\n",
      "  âœ… CRC22 (CRC): 65 patches\n",
      "  âœ… CRC23 (CRC): 51 patches\n",
      "  âœ… CRC24 (CRC): 84 patches\n",
      "  âœ… CRC25 (CRC): 24 patches\n",
      "  âœ… CRC26 (CRC): 42 patches\n",
      "  âœ… CRC27 (CRC): 29 patches\n",
      "  âœ… ovarian (Xenium): 94 patches\n",
      "Validation/Test Dataset: 8 samples, 409 patches\n",
      "âœ… Dataloaders created:\n",
      "   Train: 4194 patches (1048 batches)\n",
      "   Val: 643 patches (161 batches)\n",
      "   Test: 409 patches (103 batches)\n",
      "\n",
      "âœ… Ready to use!\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Import and create dataloaders\n",
    "from dataset import Config, create_dataloaders\n",
    "\n",
    "# Just use the correct relative path from your working directory\n",
    "config = Config(\"configs/config_fold2.yaml\")  # Note: \"configs\" not \"config\"\n",
    "config.print_config()\n",
    "\n",
    "train_loader, val_loader, test_loader = create_dataloaders(config)\n",
    "print(\"\\nâœ… Ready to use!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef9dd79-26c6-4bfa-83e1-0a3ebb4bd515",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faba78bc-05f0-42d3-b2d1-b98eddcc82f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building H&E encoder with DINOv2-base\n",
      "Building MIF encoder with DINOv2-base\n",
      "Building shared encoder with DINOv2-base\n",
      "âœ“ VitaminPDual initialized with base backbone\n",
      "  Embed dim: 768 | Decoder dims: [768, 384, 192, 96]\n",
      "================================================================================\n",
      "Training VitaminPDual-BASE\n",
      "Epochs: 250 | LR: 0.0001\n",
      "Augmentations: True\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                    | 0/1048 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 25\u001b[0m\n\u001b[1;32m     10\u001b[0m trainer \u001b[38;5;241m=\u001b[39m VitaminPTrainer(\n\u001b[1;32m     11\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     12\u001b[0m     train_loader\u001b[38;5;241m=\u001b[39mtrain_loader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     checkpoint_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoints\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Cell 5: Train\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m250\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_augmentations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/rsrch9/home/plm/idso_fa1_pathology/codes/yshokrollahi/vitamin-p-latest/vitaminp/trainer.py:929\u001b[0m, in \u001b[0;36mVitaminPTrainer.train\u001b[0;34m(self, epochs, use_augmentations)\u001b[0m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m80\u001b[39m)\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m    928\u001b[0m     \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[0;32m--> 929\u001b[0m     train_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_augmentations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_augmentations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    931\u001b[0m     \u001b[38;5;66;03m# Validate\u001b[39;00m\n\u001b[1;32m    932\u001b[0m     val_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate()\n",
      "File \u001b[0;32m/rsrch9/home/plm/idso_fa1_pathology/codes/yshokrollahi/vitamin-p-latest/vitaminp/trainer.py:680\u001b[0m, in \u001b[0;36mVitaminPTrainer.train_epoch\u001b[0;34m(self, use_augmentations)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Route to appropriate training function based on model type\"\"\"\u001b[39;00m\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDual\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSyn\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 680\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch_dual\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_augmentations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFlex\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_epoch_flex(use_augmentations)\n",
      "File \u001b[0;32m/rsrch9/home/plm/idso_fa1_pathology/codes/yshokrollahi/vitamin-p-latest/vitaminp/trainer.py:163\u001b[0m, in \u001b[0;36mVitaminPTrainer.train_epoch_dual\u001b[0;34m(self, use_augmentations)\u001b[0m\n\u001b[1;32m    149\u001b[0m metrics \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhe_nuclei_dice\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmif_cell_hv_std\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    159\u001b[0m }\n\u001b[1;32m    161\u001b[0m pbar \u001b[38;5;241m=\u001b[39m tqdm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;124m'\u001b[39m, ncols\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m140\u001b[39m)\n\u001b[0;32m--> 163\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpbar\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhe_img\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhe_image\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmif_img\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmif_image\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/rsrch9/home/plm/idso_fa1_pathology/codes/yshokrollahi/vitamin-p-latest/dataset/dataset.py:170\u001b[0m, in \u001b[0;36mCRCZarrDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    160\u001b[0m     he_cell_hv \u001b[38;5;241m=\u001b[39m batch_generate_hv_maps(\n\u001b[1;32m    161\u001b[0m         he_cell_mask[np\u001b[38;5;241m.\u001b[39mnewaxis, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m],\n\u001b[1;32m    162\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mhv_method\n\u001b[1;32m    163\u001b[0m     )[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    165\u001b[0m     mif_nuclei_hv \u001b[38;5;241m=\u001b[39m batch_generate_hv_maps(\n\u001b[1;32m    166\u001b[0m         mif_nuclei_mask[np\u001b[38;5;241m.\u001b[39mnewaxis, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m],\n\u001b[1;32m    167\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mhv_method\n\u001b[1;32m    168\u001b[0m     )[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 170\u001b[0m     mif_cell_hv \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_generate_hv_maps\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmif_cell_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnewaxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhv_method\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;66;03m# Create dummy HV maps\u001b[39;00m\n\u001b[1;32m    176\u001b[0m     h, w \u001b[38;5;241m=\u001b[39m he_img\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[0;32m/rsrch9/home/plm/idso_fa1_pathology/codes/yshokrollahi/vitamin-p-latest/dataset/hv_generator.py:208\u001b[0m, in \u001b[0;36mbatch_generate_hv_maps\u001b[0;34m(masks_batch, method)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;66;03m# Generate for each mask in batch\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch_size):\n\u001b[0;32m--> 208\u001b[0m     hv_maps[i] \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmasks_batch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hv_maps\n",
      "File \u001b[0;32m/rsrch9/home/plm/idso_fa1_pathology/codes/yshokrollahi/vitamin-p-latest/dataset/hv_generator.py:58\u001b[0m, in \u001b[0;36mgenerate_hv_map_pannuke\u001b[0;34m(inst_map)\u001b[0m\n\u001b[1;32m     55\u001b[0m y_map \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((h, w), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Get list of instance IDs (excluding background=0)\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m inst_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43morig_inst_map\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inst_list:\n\u001b[1;32m     60\u001b[0m     inst_list\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/lib/arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[1;32m    272\u001b[0m ar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(ar)\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43m_unique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mequal_nan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[1;32m    278\u001b[0m \u001b[38;5;66;03m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/lib/arraysetops.py:336\u001b[0m, in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[1;32m    334\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar[perm]\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 336\u001b[0m     \u001b[43mar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    337\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar\n\u001b[1;32m    338\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(aux\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mbool_)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Cell 1: Import\n",
    "from vitaminp import VitaminPDual, VitaminPTrainer\n",
    "import torch\n",
    "\n",
    "# Cell 3: Initialize model\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = VitaminPDual(model_size='base', dropout_rate=0.3, freeze_backbone=False)\n",
    "\n",
    "# Cell 4: Initialize trainer\n",
    "trainer = VitaminPTrainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    lr=1e-4,\n",
    "    weight_decay=1e-4,\n",
    "    fold=2,\n",
    "    use_wandb=False,\n",
    "    project_name=\"vitamin-p-channel_shuffling\",\n",
    "    run_name=\"VitaminPDual-base_fold2\",\n",
    "    checkpoint_dir=\"checkpoints\"\n",
    ")\n",
    "\n",
    "# Cell 5: Train\n",
    "trainer.train(epochs=250, use_augmentations=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f22c40-eceb-4c1a-b6fb-0161bd4a2c7b",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba2ab93e-e1a6-42fc-b9e3-00698142f255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "                           LOADING DUAL ENCODER MODEL                           \n",
      "================================================================================\n",
      "Model: VitaminPDual-BASE\n",
      "Checkpoint: checkpoints/vitamin_p_dual_base_fold2_best.pth\n",
      "--------------------------------------------------------------------------------\n",
      "Building H&E encoder with DINOv2-base\n",
      "Building MIF encoder with DINOv2-base\n",
      "Building shared encoder with DINOv2-base\n",
      "âœ“ VitaminPDual initialized with base backbone\n",
      "  Embed dim: 768 | Decoder dims: [768, 384, 192, 96]\n",
      "âœ“ Model loaded successfully\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "SAMPLE IDENTIFICATION\n",
      "================================================================================\n",
      "Batch Index: 74 / 103\n",
      "Sample Index in Batch: 3 / 4\n",
      "Global Sample Index: 299\n",
      "================================================================================\n",
      "\n",
      "Running predictions...\n",
      "âœ“ Predictions complete\n",
      "\n",
      "Post-processing H&E predictions...\n",
      "  Processing H&E nuclei instances...\n",
      "  âœ“ Detected 144 H&E nuclei instances\n",
      "  Processing H&E cell instances...\n",
      "  âœ“ Detected 181 H&E cell instances\n",
      "\n",
      "Post-processing MIF predictions...\n",
      "  Processing MIF nuclei instances...\n",
      "  âœ“ Detected 187 MIF nuclei instances\n",
      "  Processing MIF cell instances...\n",
      "  âœ“ Detected 176 MIF cell instances\n",
      "\n",
      "================================================================================\n",
      "STATISTICS SUMMARY\n",
      "================================================================================\n",
      "H&E  NUCLEI: 144 instances | HV MAE: 0.0823\n",
      "H&E  CELLS:  181 instances | HV MAE: 0.0833\n",
      "MIF  NUCLEI: 187 instances | HV MAE: 0.0826\n",
      "MIF  CELLS:  176 instances | HV MAE: 0.0835\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SINGLE SAMPLE VISUALIZATION - DUAL ENCODER MODEL\n",
    "# ============================================================================\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from vitaminp import VitaminPDual, SimplePreprocessing\n",
    "from postprocessing import process_model_outputs\n",
    "import random\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL CONFIGURATION\n",
    "# ============================================================================\n",
    "MODEL_SIZE = 'base'\n",
    "DUAL_MODEL_PATH = 'checkpoints/vitamin_p_dual_base_fold2_best.pth'  # Update with your actual path\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD MODEL\n",
    "# ============================================================================\n",
    "print(\"=\"*80)\n",
    "print(f\"{'LOADING DUAL ENCODER MODEL':^80}\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Model: VitaminPDual-{MODEL_SIZE.upper()}\")\n",
    "print(f\"Checkpoint: {DUAL_MODEL_PATH}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_dual = VitaminPDual(model_size=MODEL_SIZE, dropout_rate=0.3, freeze_backbone=False)\n",
    "checkpoint_dual = torch.load(DUAL_MODEL_PATH, map_location=device)\n",
    "model_dual.load_state_dict(checkpoint_dual)\n",
    "model_dual.eval()\n",
    "model_dual = model_dual.to(device)\n",
    "print(f\"âœ“ Model loaded successfully\")\n",
    "print(f\"Device: {device}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# PREPROCESSING\n",
    "# ============================================================================\n",
    "preprocessor = SimplePreprocessing()\n",
    "\n",
    "# ============================================================================\n",
    "# GET A RANDOM SAMPLE\n",
    "# ============================================================================\n",
    "batch_idx = random.randint(0, len(test_loader) - 1)\n",
    "for i, batch in enumerate(test_loader):\n",
    "    if i == batch_idx:\n",
    "        break\n",
    "\n",
    "idx = random.randint(0, batch['he_image'].shape[0] - 1)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"SAMPLE IDENTIFICATION\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Batch Index: {batch_idx} / {len(test_loader)}\")\n",
    "print(f\"Sample Index in Batch: {idx} / {batch['he_image'].shape[0]}\")\n",
    "global_idx = batch_idx * batch['he_image'].shape[0] + idx\n",
    "print(f\"Global Sample Index: {global_idx}\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# ============================================================================\n",
    "# PREPARE INPUTS\n",
    "# ============================================================================\n",
    "he_img = batch['he_image'][idx].to(device)\n",
    "mif_img = batch['mif_image'][idx].to(device)\n",
    "\n",
    "# Ground truth HV maps\n",
    "he_nuclei_hv_gt = batch['he_nuclei_hv'][idx].cpu().numpy()\n",
    "he_cell_hv_gt = batch['he_cell_hv'][idx].cpu().numpy()\n",
    "mif_nuclei_hv_gt = batch['mif_nuclei_hv'][idx].cpu().numpy()\n",
    "mif_cell_hv_gt = batch['mif_cell_hv'][idx].cpu().numpy()\n",
    "\n",
    "# Prepare inputs for model\n",
    "he_input = he_img.unsqueeze(0)\n",
    "mif_input = mif_img.unsqueeze(0)\n",
    "he_input = preprocessor.percentile_normalize(he_input)\n",
    "mif_input = preprocessor.percentile_normalize(mif_input)\n",
    "\n",
    "# ============================================================================\n",
    "# PREDICT WITH DUAL ENCODER MODEL\n",
    "# ============================================================================\n",
    "print(f\"\\nRunning predictions...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs_dual = model_dual(he_input, mif_input)\n",
    "    \n",
    "    # H&E predictions\n",
    "    n_hv_pred_he = outputs_dual['he_nuclei_hv'][0].cpu().numpy()\n",
    "    c_hv_pred_he = outputs_dual['he_cell_hv'][0].cpu().numpy()\n",
    "    n_mask_pred_he = (outputs_dual['he_nuclei_seg'][0, 0] > 0.5).float().cpu().numpy()\n",
    "    c_mask_pred_he = (outputs_dual['he_cell_seg'][0, 0] > 0.5).float().cpu().numpy()\n",
    "    \n",
    "    # MIF predictions\n",
    "    n_hv_pred_mif = outputs_dual['mif_nuclei_hv'][0].cpu().numpy()\n",
    "    c_hv_pred_mif = outputs_dual['mif_cell_hv'][0].cpu().numpy()\n",
    "    n_mask_pred_mif = (outputs_dual['mif_nuclei_seg'][0, 0] > 0.5).float().cpu().numpy()\n",
    "    c_mask_pred_mif = (outputs_dual['mif_cell_seg'][0, 0] > 0.5).float().cpu().numpy()\n",
    "\n",
    "print(\"âœ“ Predictions complete\")\n",
    "\n",
    "# ============================================================================\n",
    "# PREPARE IMAGES FOR VISUALIZATION\n",
    "# ============================================================================\n",
    "img_he = he_img.cpu().permute(1, 2, 0).numpy()\n",
    "img_he = np.clip(img_he, 0, 1)\n",
    "\n",
    "img_mif = mif_img.cpu().permute(1, 2, 0).numpy()\n",
    "img_mif = np.clip(img_mif, 0, 1)\n",
    "\n",
    "# Convert MIF to RGB for visualization\n",
    "if img_mif.shape[2] == 2:\n",
    "    img_mif_rgb = np.zeros((img_mif.shape[0], img_mif.shape[1], 3), dtype=img_mif.dtype)\n",
    "    img_mif_rgb[:, :, 0] = img_mif[:, :, 0]  # Red channel\n",
    "    img_mif_rgb[:, :, 1] = img_mif[:, :, 1]  # Green channel\n",
    "    img_mif_rgb = np.clip(img_mif_rgb * 1.5, 0, 1)  # Brighten\n",
    "    img_mif = img_mif_rgb\n",
    "\n",
    "# Create HV magnitude maps\n",
    "# Ground truth\n",
    "n_hv_gt_he_mag = np.sqrt(he_nuclei_hv_gt[0]**2 + he_nuclei_hv_gt[1]**2)\n",
    "c_hv_gt_he_mag = np.sqrt(he_cell_hv_gt[0]**2 + he_cell_hv_gt[1]**2)\n",
    "n_hv_gt_mif_mag = np.sqrt(mif_nuclei_hv_gt[0]**2 + mif_nuclei_hv_gt[1]**2)\n",
    "c_hv_gt_mif_mag = np.sqrt(mif_cell_hv_gt[0]**2 + mif_cell_hv_gt[1]**2)\n",
    "\n",
    "# Predictions\n",
    "n_hv_pred_he_mag = np.sqrt(n_hv_pred_he[0]**2 + n_hv_pred_he[1]**2)\n",
    "c_hv_pred_he_mag = np.sqrt(c_hv_pred_he[0]**2 + c_hv_pred_he[1]**2)\n",
    "n_hv_pred_mif_mag = np.sqrt(n_hv_pred_mif[0]**2 + n_hv_pred_mif[1]**2)\n",
    "c_hv_pred_mif_mag = np.sqrt(c_hv_pred_mif[0]**2 + c_hv_pred_mif[1]**2)\n",
    "\n",
    "# ============================================================================\n",
    "# POST-PROCESSING TO GET INSTANCES\n",
    "# ============================================================================\n",
    "print(\"\\nPost-processing H&E predictions...\")\n",
    "print(\"  Processing H&E nuclei instances...\")\n",
    "nuclei_inst_he, nuclei_info_he, num_nuclei_he = process_model_outputs(\n",
    "    seg_pred=n_mask_pred_he,\n",
    "    h_map=n_hv_pred_he[0],\n",
    "    v_map=n_hv_pred_he[1],\n",
    "    magnification=40\n",
    ")\n",
    "print(f\"  âœ“ Detected {num_nuclei_he} H&E nuclei instances\")\n",
    "\n",
    "print(\"  Processing H&E cell instances...\")\n",
    "cell_inst_he, cell_info_he, num_cells_he = process_model_outputs(\n",
    "    seg_pred=c_mask_pred_he,\n",
    "    h_map=c_hv_pred_he[0],\n",
    "    v_map=c_hv_pred_he[1],\n",
    "    magnification=40\n",
    ")\n",
    "print(f\"  âœ“ Detected {num_cells_he} H&E cell instances\")\n",
    "\n",
    "print(\"\\nPost-processing MIF predictions...\")\n",
    "print(\"  Processing MIF nuclei instances...\")\n",
    "nuclei_inst_mif, nuclei_info_mif, num_nuclei_mif = process_model_outputs(\n",
    "    seg_pred=n_mask_pred_mif,\n",
    "    h_map=n_hv_pred_mif[0],\n",
    "    v_map=n_hv_pred_mif[1],\n",
    "    magnification=40\n",
    ")\n",
    "print(f\"  âœ“ Detected {num_nuclei_mif} MIF nuclei instances\")\n",
    "\n",
    "print(\"  Processing MIF cell instances...\")\n",
    "cell_inst_mif, cell_info_mif, num_cells_mif = process_model_outputs(\n",
    "    seg_pred=c_mask_pred_mif,\n",
    "    h_map=c_hv_pred_mif[0],\n",
    "    v_map=c_hv_pred_mif[1],\n",
    "    magnification=40\n",
    ")\n",
    "print(f\"  âœ“ Detected {num_cells_mif} MIF cell instances\")\n",
    "\n",
    "# ============================================================================\n",
    "# DRAW CONTOURS FUNCTION\n",
    "# ============================================================================\n",
    "def draw_contours_simple(image, inst_info_dict, color=(0, 255, 0), thickness=2):\n",
    "    \"\"\"Draw instance contours on image\"\"\"\n",
    "    if image.max() <= 1.0:\n",
    "        image = (image * 255).astype(np.uint8)\n",
    "    else:\n",
    "        image = image.astype(np.uint8)\n",
    "    \n",
    "    if len(image.shape) == 2:\n",
    "        output = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "    elif image.shape[2] == 3:\n",
    "        output = image.copy()\n",
    "    \n",
    "    for inst_id, inst_data in inst_info_dict.items():\n",
    "        contour = inst_data['contour']\n",
    "        if contour.shape[0] >= 3:\n",
    "            cv2.drawContours(output, [contour], -1, color, thickness)\n",
    "        \n",
    "        centroid = inst_data['centroid'].astype(int)\n",
    "        cv2.circle(output, tuple(centroid), 3, (255, 255, 0), -1)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Draw contours\n",
    "img_he_uint8 = (img_he * 255).astype(np.uint8) if img_he.max() <= 1.0 else img_he.astype(np.uint8)\n",
    "img_mif_uint8 = (img_mif * 255).astype(np.uint8) if img_mif.max() <= 1.0 else img_mif.astype(np.uint8)\n",
    "\n",
    "# H&E contours (BLUE for nuclei, GREEN for cells)\n",
    "nuclei_contours_he = draw_contours_simple(img_he_uint8.copy(), nuclei_info_he, color=(0, 100, 255), thickness=2)\n",
    "cell_contours_he = draw_contours_simple(img_he_uint8.copy(), cell_info_he, color=(0, 255, 0), thickness=2)\n",
    "\n",
    "# MIF contours (BLUE for nuclei, GREEN for cells)\n",
    "nuclei_contours_mif = draw_contours_simple(img_mif_uint8.copy(), nuclei_info_mif, color=(0, 100, 255), thickness=2)\n",
    "cell_contours_mif = draw_contours_simple(img_mif_uint8.copy(), cell_info_mif, color=(0, 255, 0), thickness=2)\n",
    "\n",
    "# ============================================================================\n",
    "# VISUALIZATION - NUCLEI (H&E vs MIF)\n",
    "# ============================================================================\n",
    "fig, axes = plt.subplots(2, 4, figsize=(24, 12))\n",
    "\n",
    "# ROW 1: H&E NUCLEI\n",
    "axes[0, 0].imshow(img_he)\n",
    "axes[0, 0].set_title('H&E Input Image', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "im1 = axes[0, 1].imshow(n_hv_gt_he_mag, cmap='viridis', vmin=0, vmax=1.5)\n",
    "axes[0, 1].set_title(f'H&E Nuclei HV GT\\nMean: {n_hv_gt_he_mag.mean():.3f}', fontsize=11)\n",
    "axes[0, 1].axis('off')\n",
    "plt.colorbar(im1, ax=axes[0, 1], fraction=0.046)\n",
    "\n",
    "im2 = axes[0, 2].imshow(n_hv_pred_he_mag, cmap='viridis', vmin=0, vmax=1.5)\n",
    "axes[0, 2].set_title(f'H&E Nuclei HV Pred\\nMean: {n_hv_pred_he_mag.mean():.3f}', fontsize=11)\n",
    "axes[0, 2].axis('off')\n",
    "plt.colorbar(im2, ax=axes[0, 2], fraction=0.046)\n",
    "\n",
    "axes[0, 3].imshow(nuclei_contours_he)\n",
    "axes[0, 3].set_title(f'H&E Nuclei Boundaries (BLUE)\\n({num_nuclei_he} instances)', fontsize=11, fontweight='bold')\n",
    "axes[0, 3].axis('off')\n",
    "\n",
    "# ROW 2: MIF NUCLEI\n",
    "axes[1, 0].imshow(img_mif)\n",
    "axes[1, 0].set_title('MIF Input Image (Brightened)', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "im3 = axes[1, 1].imshow(n_hv_gt_mif_mag, cmap='viridis', vmin=0, vmax=1.5)\n",
    "axes[1, 1].set_title(f'MIF Nuclei HV GT\\nMean: {n_hv_gt_mif_mag.mean():.3f}', fontsize=11)\n",
    "axes[1, 1].axis('off')\n",
    "plt.colorbar(im3, ax=axes[1, 1], fraction=0.046)\n",
    "\n",
    "im4 = axes[1, 2].imshow(n_hv_pred_mif_mag, cmap='viridis', vmin=0, vmax=1.5)\n",
    "axes[1, 2].set_title(f'MIF Nuclei HV Pred\\nMean: {n_hv_pred_mif_mag.mean():.3f}', fontsize=11)\n",
    "axes[1, 2].axis('off')\n",
    "plt.colorbar(im4, ax=axes[1, 2], fraction=0.046)\n",
    "\n",
    "axes[1, 3].imshow(nuclei_contours_mif)\n",
    "axes[1, 3].set_title(f'MIF Nuclei Boundaries (BLUE)\\n({num_nuclei_mif} instances)', fontsize=11, fontweight='bold')\n",
    "axes[1, 3].axis('off')\n",
    "\n",
    "plt.suptitle(f'NUCLEI SEGMENTATION - VitaminPDual-{MODEL_SIZE.upper()} | Batch {batch_idx}, Sample {idx}', \n",
    "             fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# VISUALIZATION - CELLS (H&E vs MIF)\n",
    "# ============================================================================\n",
    "fig2, axes2 = plt.subplots(2, 4, figsize=(24, 12))\n",
    "\n",
    "# ROW 1: H&E CELLS\n",
    "axes2[0, 0].imshow(img_he)\n",
    "axes2[0, 0].set_title('H&E Input Image', fontsize=12, fontweight='bold')\n",
    "axes2[0, 0].axis('off')\n",
    "\n",
    "im5 = axes2[0, 1].imshow(c_hv_gt_he_mag, cmap='viridis', vmin=0, vmax=1.5)\n",
    "axes2[0, 1].set_title(f'H&E Cell HV GT\\nMean: {c_hv_gt_he_mag.mean():.3f}', fontsize=11)\n",
    "axes2[0, 1].axis('off')\n",
    "plt.colorbar(im5, ax=axes2[0, 1], fraction=0.046)\n",
    "\n",
    "im6 = axes2[0, 2].imshow(c_hv_pred_he_mag, cmap='viridis', vmin=0, vmax=1.5)\n",
    "axes2[0, 2].set_title(f'H&E Cell HV Pred\\nMean: {c_hv_pred_he_mag.mean():.3f}', fontsize=11)\n",
    "axes2[0, 2].axis('off')\n",
    "plt.colorbar(im6, ax=axes2[0, 2], fraction=0.046)\n",
    "\n",
    "axes2[0, 3].imshow(cell_contours_he)\n",
    "axes2[0, 3].set_title(f'H&E Cell Boundaries (GREEN)\\n({num_cells_he} instances)', fontsize=11, fontweight='bold')\n",
    "axes2[0, 3].axis('off')\n",
    "\n",
    "# ROW 2: MIF CELLS\n",
    "axes2[1, 0].imshow(img_mif)\n",
    "axes2[1, 0].set_title('MIF Input Image (Brightened)', fontsize=12, fontweight='bold')\n",
    "axes2[1, 0].axis('off')\n",
    "\n",
    "im7 = axes2[1, 1].imshow(c_hv_gt_mif_mag, cmap='viridis', vmin=0, vmax=1.5)\n",
    "axes2[1, 1].set_title(f'MIF Cell HV GT\\nMean: {c_hv_gt_mif_mag.mean():.3f}', fontsize=11)\n",
    "axes2[1, 1].axis('off')\n",
    "plt.colorbar(im7, ax=axes2[1, 1], fraction=0.046)\n",
    "\n",
    "im8 = axes2[1, 2].imshow(c_hv_pred_mif_mag, cmap='viridis', vmin=0, vmax=1.5)\n",
    "axes2[1, 2].set_title(f'MIF Cell HV Pred\\nMean: {c_hv_pred_mif_mag.mean():.3f}', fontsize=11)\n",
    "axes2[1, 2].axis('off')\n",
    "plt.colorbar(im8, ax=axes2[1, 2], fraction=0.046)\n",
    "\n",
    "axes2[1, 3].imshow(cell_contours_mif)\n",
    "axes2[1, 3].set_title(f'MIF Cell Boundaries (GREEN)\\n({num_cells_mif} instances)', fontsize=11, fontweight='bold')\n",
    "axes2[1, 3].axis('off')\n",
    "\n",
    "plt.suptitle(f'CELL SEGMENTATION - VitaminPDual-{MODEL_SIZE.upper()} | Batch {batch_idx}, Sample {idx}', \n",
    "             fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# STATISTICS SUMMARY\n",
    "# ============================================================================\n",
    "nuclei_error_he = np.abs(n_hv_pred_he_mag - n_hv_gt_he_mag)\n",
    "cell_error_he = np.abs(c_hv_pred_he_mag - c_hv_gt_he_mag)\n",
    "nuclei_error_mif = np.abs(n_hv_pred_mif_mag - n_hv_gt_mif_mag)\n",
    "cell_error_mif = np.abs(c_hv_pred_mif_mag - c_hv_gt_mif_mag)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"STATISTICS SUMMARY\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"H&E  NUCLEI: {num_nuclei_he} instances | HV MAE: {nuclei_error_he.mean():.4f}\")\n",
    "print(f\"H&E  CELLS:  {num_cells_he} instances | HV MAE: {cell_error_he.mean():.4f}\")\n",
    "print(f\"MIF  NUCLEI: {num_nuclei_mif} instances | HV MAE: {nuclei_error_mif.mean():.4f}\")\n",
    "print(f\"MIF  CELLS:  {num_cells_mif} instances | HV MAE: {cell_error_mif.mean():.4f}\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4759be50-e8c8-45f8-8a86-44fd1fe1ec42",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b9e3064-09e7-41d4-b22d-58d4a12e0bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "ðŸ“¦ Loading trained dual model...\n",
      "Building H&E encoder with DINOv2-base\n",
      "Building MIF encoder with DINOv2-base\n",
      "Building shared encoder with DINOv2-base\n",
      "âœ“ VitaminPDual initialized with base backbone\n",
      "  Embed dim: 768 | Decoder dims: [768, 384, 192, 96]\n",
      "âœ… Loaded checkpoint: checkpoints/vitamin_p_dual_base_fold2_best.pth\n",
      "âœ… Model: VitaminPDual-Base\n",
      "\n",
      "ðŸ§ª Evaluating on test set...\n",
      "Processed 10/103 batches...\n",
      "Processed 20/103 batches...\n",
      "Processed 30/103 batches...\n",
      "Processed 40/103 batches...\n",
      "Processed 50/103 batches...\n",
      "Processed 60/103 batches...\n",
      "Processed 70/103 batches...\n",
      "Processed 80/103 batches...\n",
      "Processed 90/103 batches...\n",
      "Processed 100/103 batches...\n",
      "Processed 110/103 batches...\n",
      "Processed 120/103 batches...\n",
      "Processed 130/103 batches...\n",
      "Processed 140/103 batches...\n",
      "Processed 150/103 batches...\n",
      "Processed 160/103 batches...\n",
      "Processed 170/103 batches...\n",
      "Processed 180/103 batches...\n",
      "Processed 190/103 batches...\n",
      "Processed 200/103 batches...\n",
      "Processed 210/103 batches...\n",
      "Processed 220/103 batches...\n",
      "Processed 230/103 batches...\n",
      "Processed 240/103 batches...\n",
      "Processed 250/103 batches...\n",
      "Processed 260/103 batches...\n",
      "Processed 270/103 batches...\n",
      "Processed 280/103 batches...\n",
      "Processed 290/103 batches...\n",
      "Processed 300/103 batches...\n",
      "Processed 310/103 batches...\n",
      "Processed 320/103 batches...\n",
      "Processed 330/103 batches...\n",
      "Processed 340/103 batches...\n",
      "Processed 350/103 batches...\n",
      "Processed 360/103 batches...\n",
      "Processed 370/103 batches...\n",
      "Processed 380/103 batches...\n",
      "Processed 390/103 batches...\n",
      "Processed 400/103 batches...\n",
      "Processed 410/103 batches...\n",
      "Processed 420/103 batches...\n",
      "Processed 430/103 batches...\n",
      "Processed 440/103 batches...\n",
      "Processed 450/103 batches...\n",
      "Processed 460/103 batches...\n",
      "Processed 470/103 batches...\n",
      "Processed 480/103 batches...\n",
      "Processed 490/103 batches...\n",
      "Processed 500/103 batches...\n",
      "Processed 510/103 batches...\n",
      "Processed 520/103 batches...\n",
      "Processed 530/103 batches...\n",
      "Processed 540/103 batches...\n",
      "Processed 550/103 batches...\n",
      "Processed 560/103 batches...\n",
      "Processed 570/103 batches...\n",
      "Processed 580/103 batches...\n",
      "Processed 590/103 batches...\n",
      "Processed 600/103 batches...\n",
      "Processed 610/103 batches...\n",
      "Processed 620/103 batches...\n",
      "Processed 630/103 batches...\n",
      "Processed 640/103 batches...\n",
      "Processed 650/103 batches...\n",
      "Processed 660/103 batches...\n",
      "Processed 670/103 batches...\n",
      "Processed 680/103 batches...\n",
      "Processed 690/103 batches...\n",
      "Processed 700/103 batches...\n",
      "Processed 710/103 batches...\n",
      "Processed 720/103 batches...\n",
      "Processed 730/103 batches...\n",
      "Processed 740/103 batches...\n",
      "Processed 750/103 batches...\n",
      "Processed 760/103 batches...\n",
      "Processed 770/103 batches...\n",
      "Processed 780/103 batches...\n",
      "Processed 790/103 batches...\n",
      "Processed 800/103 batches...\n",
      "Processed 810/103 batches...\n",
      "Processed 820/103 batches...\n",
      "Processed 830/103 batches...\n",
      "Processed 840/103 batches...\n",
      "Processed 850/103 batches...\n",
      "Processed 860/103 batches...\n",
      "Processed 870/103 batches...\n",
      "Processed 880/103 batches...\n",
      "Processed 890/103 batches...\n",
      "Processed 900/103 batches...\n",
      "Processed 910/103 batches...\n",
      "Processed 920/103 batches...\n",
      "Processed 930/103 batches...\n",
      "Processed 940/103 batches...\n",
      "Processed 950/103 batches...\n",
      "Processed 960/103 batches...\n",
      "Processed 970/103 batches...\n",
      "Processed 980/103 batches...\n",
      "Processed 990/103 batches...\n",
      "Processed 1000/103 batches...\n",
      "Processed 1010/103 batches...\n",
      "Processed 1020/103 batches...\n",
      "Processed 1030/103 batches...\n",
      "Processed 1040/103 batches...\n",
      "\n",
      "================================================================================\n",
      "ðŸ“Š DUAL MODEL TEST SET RESULTS\n",
      "================================================================================\n",
      "\n",
      "ðŸ”¬ H&E Performance:\n",
      "  Nuclei Dice: 0.9003 Â± 0.0193\n",
      "  Nuclei IoU:  0.8192 Â± 0.0318\n",
      "  Cell Dice:   0.9479 Â± 0.0120\n",
      "  Cell IoU:    0.9012 Â± 0.0215\n",
      "\n",
      "ðŸ§¬ MIF Performance:\n",
      "  Nuclei Dice: 0.6379 Â± 0.0490\n",
      "  Nuclei IoU:  0.4702 Â± 0.0529\n",
      "  Cell Dice:   0.9489 Â± 0.0121\n",
      "  Cell IoU:    0.9030 Â± 0.0218\n",
      "\n",
      "================================================================================\n",
      "ðŸ“ˆ SUMMARY:\n",
      "================================================================================\n",
      "Total batches processed: 103\n",
      "Total samples: 1048\n",
      "\n",
      "Average H&E Dice:  0.9241\n",
      "Average MIF Dice:  0.7934\n",
      "Overall Dice:      0.8587\n",
      "================================================================================\n",
      "\n",
      "ðŸ” Single batch detailed view (first sample):\n",
      "\n",
      "H&E (first sample):\n",
      "  Nuclei - Dice: 0.8484, IoU: 0.7367\n",
      "  Cell   - Dice: 0.8552, IoU: 0.7470\n",
      "\n",
      "MIF (first sample):\n",
      "  Nuclei - Dice: 0.6453, IoU: 0.4764\n",
      "  Cell   - Dice: 0.8583, IoU: 0.7517\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from metrics import (\n",
    "    dice_coefficient, \n",
    "    iou_score, \n",
    "    panoptic_quality,\n",
    "    aggregated_jaccard_index,\n",
    "    compute_batch_metrics,\n",
    "    print_metrics\n",
    ")\n",
    "import numpy as np\n",
    "from vitaminp import VitaminPDual, SimplePreprocessing\n",
    "from postprocessing import process_model_outputs\n",
    "\n",
    "# Define device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ========== LOAD TRAINED DUAL MODEL ==========\n",
    "print(\"\\nðŸ“¦ Loading trained dual model...\")\n",
    "\n",
    "model = VitaminPDual(model_size='base', dropout_rate=0.3, freeze_backbone=False).to(device)\n",
    "checkpoint_path = \"checkpoints/vitamin_p_dual_base_fold2_best.pth\"  # Update with your actual path\n",
    "model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "\n",
    "print(f\"âœ… Loaded checkpoint: {checkpoint_path}\")\n",
    "print(f\"âœ… Model: VitaminPDual-Base\")\n",
    "\n",
    "# ========== PREPROCESSING ==========\n",
    "preprocessor = SimplePreprocessing()\n",
    "\n",
    "# ========== EVALUATE ON TEST DATA ==========\n",
    "print(\"\\nðŸ§ª Evaluating on test set...\")\n",
    "model.eval()\n",
    "\n",
    "all_metrics = {\n",
    "    # H&E metrics\n",
    "    'he_nuclei_dice': [], 'he_nuclei_iou': [],\n",
    "    'he_cell_dice': [], 'he_cell_iou': [],\n",
    "    # MIF metrics\n",
    "    'mif_nuclei_dice': [], 'mif_nuclei_iou': [],\n",
    "    'mif_cell_dice': [], 'mif_cell_iou': []\n",
    "}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        \n",
    "        # ===== Prepare inputs =====\n",
    "        he_img = batch['he_image'].to(device)\n",
    "        mif_img = batch['mif_image'].to(device)\n",
    "        \n",
    "        # Normalize\n",
    "        he_img = preprocessor.percentile_normalize(he_img)\n",
    "        mif_img = preprocessor.percentile_normalize(mif_img)\n",
    "        \n",
    "        # Ground truth masks\n",
    "        he_nuclei_mask_gt = batch['he_nuclei_mask'].float().unsqueeze(1).to(device)\n",
    "        he_cell_mask_gt = batch['he_cell_mask'].float().unsqueeze(1).to(device)\n",
    "        mif_nuclei_mask_gt = batch['mif_nuclei_mask'].float().unsqueeze(1).to(device)\n",
    "        mif_cell_mask_gt = batch['mif_cell_mask'].float().unsqueeze(1).to(device)\n",
    "        \n",
    "        # ===== Forward pass (Dual Model) =====\n",
    "        outputs = model(he_img, mif_img)\n",
    "        \n",
    "        # ===== H&E Predictions =====\n",
    "        pred_nuclei_he = (outputs['he_nuclei_seg'] > 0.5).float()\n",
    "        pred_cell_he = (outputs['he_cell_seg'] > 0.5).float()\n",
    "        \n",
    "        # Compute H&E metrics\n",
    "        he_nuclei_dice = dice_coefficient(pred_nuclei_he, he_nuclei_mask_gt)\n",
    "        he_nuclei_iou = iou_score(pred_nuclei_he, he_nuclei_mask_gt)\n",
    "        he_cell_dice = dice_coefficient(pred_cell_he, he_cell_mask_gt)\n",
    "        he_cell_iou = iou_score(pred_cell_he, he_cell_mask_gt)\n",
    "        \n",
    "        all_metrics['he_nuclei_dice'].append(he_nuclei_dice)\n",
    "        all_metrics['he_nuclei_iou'].append(he_nuclei_iou)\n",
    "        all_metrics['he_cell_dice'].append(he_cell_dice)\n",
    "        all_metrics['he_cell_iou'].append(he_cell_iou)\n",
    "        \n",
    "        # ===== MIF Predictions =====\n",
    "        pred_nuclei_mif = (outputs['mif_nuclei_seg'] > 0.5).float()\n",
    "        pred_cell_mif = (outputs['mif_cell_seg'] > 0.5).float()\n",
    "        \n",
    "        # Compute MIF metrics\n",
    "        mif_nuclei_dice = dice_coefficient(pred_nuclei_mif, mif_nuclei_mask_gt)\n",
    "        mif_nuclei_iou = iou_score(pred_nuclei_mif, mif_nuclei_mask_gt)\n",
    "        mif_cell_dice = dice_coefficient(pred_cell_mif, mif_cell_mask_gt)\n",
    "        mif_cell_iou = iou_score(pred_cell_mif, mif_cell_mask_gt)\n",
    "        \n",
    "        all_metrics['mif_nuclei_dice'].append(mif_nuclei_dice)\n",
    "        all_metrics['mif_nuclei_iou'].append(mif_nuclei_iou)\n",
    "        all_metrics['mif_cell_dice'].append(mif_cell_dice)\n",
    "        all_metrics['mif_cell_iou'].append(mif_cell_iou)\n",
    "        \n",
    "        # Print progress every 10 batches\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f\"Processed {batch_idx + 1}/{len(test_loader)} batches...\")\n",
    "\n",
    "# ========== AGGREGATE RESULTS ==========\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸ“Š DUAL MODEL TEST SET RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nðŸ”¬ H&E Performance:\")\n",
    "he_nuclei_dice_mean = sum(all_metrics['he_nuclei_dice'])/len(all_metrics['he_nuclei_dice'])\n",
    "he_nuclei_dice_std = torch.tensor(all_metrics['he_nuclei_dice']).std()\n",
    "he_nuclei_iou_mean = sum(all_metrics['he_nuclei_iou'])/len(all_metrics['he_nuclei_iou'])\n",
    "he_nuclei_iou_std = torch.tensor(all_metrics['he_nuclei_iou']).std()\n",
    "he_cell_dice_mean = sum(all_metrics['he_cell_dice'])/len(all_metrics['he_cell_dice'])\n",
    "he_cell_dice_std = torch.tensor(all_metrics['he_cell_dice']).std()\n",
    "he_cell_iou_mean = sum(all_metrics['he_cell_iou'])/len(all_metrics['he_cell_iou'])\n",
    "he_cell_iou_std = torch.tensor(all_metrics['he_cell_iou']).std()\n",
    "\n",
    "print(f\"  Nuclei Dice: {he_nuclei_dice_mean:.4f} Â± {he_nuclei_dice_std:.4f}\")\n",
    "print(f\"  Nuclei IoU:  {he_nuclei_iou_mean:.4f} Â± {he_nuclei_iou_std:.4f}\")\n",
    "print(f\"  Cell Dice:   {he_cell_dice_mean:.4f} Â± {he_cell_dice_std:.4f}\")\n",
    "print(f\"  Cell IoU:    {he_cell_iou_mean:.4f} Â± {he_cell_iou_std:.4f}\")\n",
    "\n",
    "print(\"\\nðŸ§¬ MIF Performance:\")\n",
    "mif_nuclei_dice_mean = sum(all_metrics['mif_nuclei_dice'])/len(all_metrics['mif_nuclei_dice'])\n",
    "mif_nuclei_dice_std = torch.tensor(all_metrics['mif_nuclei_dice']).std()\n",
    "mif_nuclei_iou_mean = sum(all_metrics['mif_nuclei_iou'])/len(all_metrics['mif_nuclei_iou'])\n",
    "mif_nuclei_iou_std = torch.tensor(all_metrics['mif_nuclei_iou']).std()\n",
    "mif_cell_dice_mean = sum(all_metrics['mif_cell_dice'])/len(all_metrics['mif_cell_dice'])\n",
    "mif_cell_dice_std = torch.tensor(all_metrics['mif_cell_dice']).std()\n",
    "mif_cell_iou_mean = sum(all_metrics['mif_cell_iou'])/len(all_metrics['mif_cell_iou'])\n",
    "mif_cell_iou_std = torch.tensor(all_metrics['mif_cell_iou']).std()\n",
    "\n",
    "print(f\"  Nuclei Dice: {mif_nuclei_dice_mean:.4f} Â± {mif_nuclei_dice_std:.4f}\")\n",
    "print(f\"  Nuclei IoU:  {mif_nuclei_iou_mean:.4f} Â± {mif_nuclei_iou_std:.4f}\")\n",
    "print(f\"  Cell Dice:   {mif_cell_dice_mean:.4f} Â± {mif_cell_dice_std:.4f}\")\n",
    "print(f\"  Cell IoU:    {mif_cell_iou_mean:.4f} Â± {mif_cell_iou_std:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸ“ˆ SUMMARY:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total batches processed: {len(test_loader)}\")\n",
    "print(f\"Total samples: {len(all_metrics['he_nuclei_dice'])}\")\n",
    "\n",
    "# Overall averages\n",
    "he_avg = (he_nuclei_dice_mean + he_cell_dice_mean) / 2\n",
    "mif_avg = (mif_nuclei_dice_mean + mif_cell_dice_mean) / 2\n",
    "overall_avg = (he_avg + mif_avg) / 2\n",
    "\n",
    "print(f\"\\nAverage H&E Dice:  {he_avg:.4f}\")\n",
    "print(f\"Average MIF Dice:  {mif_avg:.4f}\")\n",
    "print(f\"Overall Dice:      {overall_avg:.4f}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ========== SINGLE BATCH DETAILED VIEW ==========\n",
    "print(\"\\nðŸ” Single batch detailed view (first sample):\")\n",
    "with torch.no_grad():\n",
    "    batch = next(iter(test_loader))\n",
    "    \n",
    "    he_img = batch['he_image'].to(device)\n",
    "    mif_img = batch['mif_image'].to(device)\n",
    "    he_img = preprocessor.percentile_normalize(he_img)\n",
    "    mif_img = preprocessor.percentile_normalize(mif_img)\n",
    "    \n",
    "    outputs = model(he_img, mif_img)\n",
    "    \n",
    "    # H&E sample\n",
    "    pred_nuclei_he = outputs['he_nuclei_seg'][0].cpu()\n",
    "    gt_nuclei_he = batch['he_nuclei_mask'][0].unsqueeze(0).cpu()\n",
    "    \n",
    "    pred_cell_he = outputs['he_cell_seg'][0].cpu()\n",
    "    gt_cell_he = batch['he_cell_mask'][0].unsqueeze(0).cpu()\n",
    "    \n",
    "    # MIF sample\n",
    "    pred_nuclei_mif = outputs['mif_nuclei_seg'][0].cpu()\n",
    "    gt_nuclei_mif = batch['mif_nuclei_mask'][0].unsqueeze(0).cpu()\n",
    "    \n",
    "    pred_cell_mif = outputs['mif_cell_seg'][0].cpu()\n",
    "    gt_cell_mif = batch['mif_cell_mask'][0].unsqueeze(0).cpu()\n",
    "    \n",
    "    # Compute metrics\n",
    "    he_n_dice = dice_coefficient(pred_nuclei_he, gt_nuclei_he)\n",
    "    he_n_iou = iou_score(pred_nuclei_he, gt_nuclei_he)\n",
    "    he_c_dice = dice_coefficient(pred_cell_he, gt_cell_he)\n",
    "    he_c_iou = iou_score(pred_cell_he, gt_cell_he)\n",
    "    \n",
    "    mif_n_dice = dice_coefficient(pred_nuclei_mif, gt_nuclei_mif)\n",
    "    mif_n_iou = iou_score(pred_nuclei_mif, gt_nuclei_mif)\n",
    "    mif_c_dice = dice_coefficient(pred_cell_mif, gt_cell_mif)\n",
    "    mif_c_iou = iou_score(pred_cell_mif, gt_cell_mif)\n",
    "    \n",
    "    print(f\"\\nH&E (first sample):\")\n",
    "    print(f\"  Nuclei - Dice: {he_n_dice:.4f}, IoU: {he_n_iou:.4f}\")\n",
    "    print(f\"  Cell   - Dice: {he_c_dice:.4f}, IoU: {he_c_iou:.4f}\")\n",
    "    \n",
    "    print(f\"\\nMIF (first sample):\")\n",
    "    print(f\"  Nuclei - Dice: {mif_n_dice:.4f}, IoU: {mif_n_iou:.4f}\")\n",
    "    print(f\"  Cell   - Dice: {mif_c_dice:.4f}, IoU: {mif_c_iou:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d20100-1504-4b24-a363-289bc8ac37e2",
   "metadata": {},
   "source": [
    "## Figure 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7709fe5a-df34-4fd7-b686-c4f91f9f3c8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yshokrollahi (py3.11.0rc1)",
   "language": "python",
   "name": "yshokrollahi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
