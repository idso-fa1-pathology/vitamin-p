{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5225c1-9d0d-46e0-b609-dcbee397061e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.models import vit_b_16, ViT_B_16_Weights\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Data Loading and Preprocessing\n",
    "def load_all_folds(base_path):\n",
    "    folds = [\"Fold 1\", \"Fold 2\", \"Fold 3\"]\n",
    "    all_images, all_masks, all_types = [], [], []\n",
    "    \n",
    "    for fold in folds:\n",
    "        fold_path = os.path.join(base_path, fold)\n",
    "        images = np.load(os.path.join(fold_path, \"images\", f\"fold{fold[-1]}\", \"images.npy\"))\n",
    "        masks = np.load(os.path.join(fold_path, \"masks\", f\"fold{fold[-1]}\", \"masks.npy\"))\n",
    "        types = np.load(os.path.join(fold_path, \"images\", f\"fold{fold[-1]}\", \"types.npy\"))\n",
    "        \n",
    "        all_images.append(images)\n",
    "        all_masks.append(masks)\n",
    "        all_types.append(types)\n",
    "    \n",
    "    return all_images, all_masks, all_types\n",
    "\n",
    "base_path = \"/rsrch5/home/plm/yshokrollahi/vitamin-p/vitamin-p/data/raw/H&E\"\n",
    "all_images, all_masks, all_types = load_all_folds(base_path)\n",
    "\n",
    "def create_train_val_test_split(all_images, all_masks, all_types):\n",
    "    splits = []\n",
    "    \n",
    "    for test_fold in range(3):\n",
    "        train_val_folds = [i for i in range(3) if i != test_fold]\n",
    "        \n",
    "        train_val_images = np.concatenate([all_images[i] for i in train_val_folds])\n",
    "        train_val_masks = np.concatenate([all_masks[i] for i in train_val_folds])\n",
    "        train_val_types = np.concatenate([all_types[i] for i in train_val_folds])\n",
    "        \n",
    "        num_samples = len(train_val_images)\n",
    "        num_val = num_samples // 10\n",
    "        \n",
    "        indices = np.arange(num_samples)\n",
    "        np.random.shuffle(indices)\n",
    "        \n",
    "        val_indices = indices[:num_val]\n",
    "        train_indices = indices[num_val:]\n",
    "        \n",
    "        split = {\n",
    "            'train': {\n",
    "                'images': train_val_images[train_indices],\n",
    "                'masks': train_val_masks[train_indices],\n",
    "                'types': train_val_types[train_indices]\n",
    "            },\n",
    "            'val': {\n",
    "                'images': train_val_images[val_indices],\n",
    "                'masks': train_val_masks[val_indices],\n",
    "                'types': train_val_types[val_indices]\n",
    "            },\n",
    "            'test': {\n",
    "                'images': all_images[test_fold],\n",
    "                'masks': all_masks[test_fold],\n",
    "                'types': all_types[test_fold]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        splits.append(split)\n",
    "    \n",
    "    return splits\n",
    "\n",
    "data_splits = create_train_val_test_split(all_images, all_masks, all_types)\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777cdd29-242c-499b-a86a-ea807b0e4edd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import functional as TF\n",
    "from scipy.ndimage import gaussian_filter, map_coordinates, distance_transform_edt\n",
    "from skimage.segmentation import slic\n",
    "from skimage.measure import regionprops\n",
    "\n",
    "class CellSegmentationDataset(Dataset):\n",
    "    def __init__(self, images, masks, types, image_transform=None, mask_transform=None, augment=False):\n",
    "        self.images = images\n",
    "        self.masks = masks\n",
    "        self.types = types\n",
    "        self.image_transform = image_transform\n",
    "        self.mask_transform = mask_transform\n",
    "        self.augment = augment\n",
    "        \n",
    "        # Get unique tissue types and create a mapping\n",
    "        self.unique_tissue_types = np.unique(self.types)\n",
    "        self.tissue_type_to_idx = {t: i for i, t in enumerate(self.unique_tissue_types)}\n",
    "\n",
    "        # Get unique cell types (excluding background)\n",
    "        self.unique_cell_types = np.arange(self.masks[0].shape[-1] - 1)  # Exclude last channel (background)\n",
    "        self.cell_type_to_idx = {t: i for i, t in enumerate(self.unique_cell_types)}\n",
    "\n",
    "        print(f\"Number of unique cell types: {len(self.unique_cell_types)}\")\n",
    "        print(f\"Shape of first mask: {self.masks[0].shape}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        mask = self.masks[idx]\n",
    "        tissue_type = self.types[idx]\n",
    "\n",
    "        # Normalize image to 0-1 range and convert to float32\n",
    "        image = ((image - image.min()) / (image.max() - image.min())).astype(np.float32)\n",
    "        \n",
    "        # Create binary mask from the last channel (background) and convert to float32\n",
    "        binary_mask = (mask[..., -1] == 0).astype(np.float32)  # Invert the background mask\n",
    "\n",
    "        # Create multi-class mask for cell types (all channels except the last one)\n",
    "        multi_class_mask = mask[..., :-1].astype(np.float32)\n",
    "        multi_class_mask = np.divide(multi_class_mask, np.maximum(np.max(multi_class_mask), 1e-8))  # Normalize to 0-1 range\n",
    "\n",
    "        # Apply binary mask to multi-class mask to exclude background\n",
    "        multi_class_mask = multi_class_mask * binary_mask[..., np.newaxis]\n",
    "\n",
    "        # Generate HV maps\n",
    "        hv_map = self.generate_hv_map(binary_mask)\n",
    "\n",
    "        # Create global cell labels\n",
    "        global_cell_labels = np.zeros(len(self.unique_cell_types), dtype=np.float32)\n",
    "        for i in range(multi_class_mask.shape[-1]):\n",
    "            if np.any(multi_class_mask[..., i] > 0):\n",
    "                global_cell_labels[i] = 1\n",
    "\n",
    "        if self.augment:\n",
    "            image, binary_mask, multi_class_mask, hv_map = self.apply_augmentation(image, binary_mask, multi_class_mask, hv_map)\n",
    "\n",
    "        if self.image_transform:\n",
    "            image = self.image_transform(image)\n",
    "\n",
    "        if self.mask_transform:\n",
    "            binary_mask = self.mask_transform(binary_mask)\n",
    "            multi_class_mask = self.mask_transform(multi_class_mask)\n",
    "            hv_map = self.mask_transform(hv_map)\n",
    "        else:\n",
    "            # If no mask_transform, convert to tensor manually\n",
    "            binary_mask = torch.from_numpy(binary_mask).unsqueeze(0)\n",
    "            multi_class_mask = torch.from_numpy(multi_class_mask).permute(2, 0, 1)\n",
    "            hv_map = torch.from_numpy(hv_map).permute(2, 0, 1)\n",
    "\n",
    "        # Create one-hot encoded tensor for tissue type\n",
    "        tissue_type_idx = self.tissue_type_to_idx[tissue_type]\n",
    "        tissue_type_onehot = torch.zeros(len(self.unique_tissue_types))\n",
    "        tissue_type_onehot[tissue_type_idx] = 1\n",
    "\n",
    "        # Convert global cell labels to tensor\n",
    "        global_cell_labels = torch.from_numpy(global_cell_labels)\n",
    "\n",
    "        return image, binary_mask, multi_class_mask, hv_map, tissue_type_onehot, global_cell_labels\n",
    "\n",
    "    def generate_hv_map(self, binary_mask):\n",
    "        label_img = (binary_mask * 255).astype(np.uint8)\n",
    "        label_img = cv2.connectedComponents(label_img)[1]\n",
    "        \n",
    "        h_map = np.zeros_like(binary_mask, dtype=np.float32)\n",
    "        v_map = np.zeros_like(binary_mask, dtype=np.float32)\n",
    "\n",
    "        for region in regionprops(label_img):\n",
    "            coords = region.coords\n",
    "            center = region.centroid\n",
    "            \n",
    "            h_map[coords[:, 0], coords[:, 1]] = (coords[:, 1] - center[1]) / (region.bbox[3] - region.bbox[1] + 1e-5)\n",
    "            v_map[coords[:, 0], coords[:, 1]] = (coords[:, 0] - center[0]) / (region.bbox[2] - region.bbox[0] + 1e-5)\n",
    "\n",
    "        hv_map = np.stack([h_map, v_map], axis=-1)\n",
    "        return hv_map\n",
    "\n",
    "\n",
    "    def apply_augmentation(self, image, binary_mask, multi_class_mask, hv_map):\n",
    "        # Convert numpy arrays to tensors\n",
    "        image = torch.from_numpy(image).permute(2, 0, 1)\n",
    "        binary_mask = torch.from_numpy(binary_mask).unsqueeze(0)\n",
    "        multi_class_mask = torch.from_numpy(multi_class_mask).permute(2, 0, 1)\n",
    "        hv_map = torch.from_numpy(hv_map).permute(2, 0, 1)\n",
    "\n",
    "        original_size = image.shape[1:]\n",
    "\n",
    "        # Random 90-degree rotation\n",
    "        if torch.rand(1) < 0.5:\n",
    "            k = torch.randint(1, 4, (1,)).item()\n",
    "            image = torch.rot90(image, k, [1, 2])\n",
    "            binary_mask = torch.rot90(binary_mask, k, [1, 2])\n",
    "            multi_class_mask = torch.rot90(multi_class_mask, k, [1, 2])\n",
    "            hv_map = torch.rot90(hv_map, k, [1, 2])\n",
    "\n",
    "        # Random horizontal flip\n",
    "        if torch.rand(1) < 0.5:\n",
    "            image = TF.hflip(image)\n",
    "            binary_mask = TF.hflip(binary_mask)\n",
    "            multi_class_mask = TF.hflip(multi_class_mask)\n",
    "            hv_map = TF.hflip(hv_map)\n",
    "            hv_map[0] = -hv_map[0]  # Flip horizontal map\n",
    "\n",
    "        # Random vertical flip\n",
    "        if torch.rand(1) < 0.5:\n",
    "            image = TF.vflip(image)\n",
    "            binary_mask = TF.vflip(binary_mask)\n",
    "            multi_class_mask = TF.vflip(multi_class_mask)\n",
    "            hv_map = TF.vflip(hv_map)\n",
    "            hv_map[1] = -hv_map[1]  # Flip vertical map\n",
    "\n",
    "        # Random scaling (downscaling)\n",
    "        if torch.rand(1) < 0.5:\n",
    "            scale_factor = torch.FloatTensor(1).uniform_(0.8, 1.0).item()\n",
    "            new_size = [max(224, int(s * scale_factor)) for s in image.shape[1:]]\n",
    "            image = TF.resize(image, new_size)\n",
    "            binary_mask = TF.resize(binary_mask, new_size)\n",
    "            multi_class_mask = TF.resize(multi_class_mask, new_size, interpolation=TF.InterpolationMode.NEAREST)\n",
    "\n",
    "        # Elastic transformation\n",
    "        if torch.rand(1) < 0.5:\n",
    "            image = self.elastic_transform(image.permute(1, 2, 0).numpy())\n",
    "            binary_mask = self.elastic_transform(binary_mask.squeeze().numpy(), is_mask=True)\n",
    "            multi_class_mask = self.elastic_transform(multi_class_mask.permute(1, 2, 0).numpy(), is_mask=True)\n",
    "            image = torch.from_numpy(image).permute(2, 0, 1)\n",
    "            binary_mask = torch.from_numpy(binary_mask).unsqueeze(0)\n",
    "            multi_class_mask = torch.from_numpy(multi_class_mask).permute(2, 0, 1)\n",
    "\n",
    "        # Ensure image is large enough for subsequent operations\n",
    "        if min(image.shape[1:]) < 224:\n",
    "            scale_factor = 224 / min(image.shape[1:])\n",
    "            new_size = [int(s * scale_factor) for s in image.shape[1:]]\n",
    "            image = TF.resize(image, new_size)\n",
    "            binary_mask = TF.resize(binary_mask, new_size)\n",
    "            multi_class_mask = TF.resize(multi_class_mask, new_size, interpolation=TF.InterpolationMode.NEAREST)\n",
    "\n",
    "        # Blurring\n",
    "        if torch.rand(1) < 0.5:\n",
    "            sigma = torch.FloatTensor(1).uniform_(0.1, 2.0).item()\n",
    "            image = torch.from_numpy(gaussian_filter(image.numpy(), sigma=(0, sigma, sigma)))\n",
    "\n",
    "        # Gaussian noise\n",
    "        if torch.rand(1) < 0.5:\n",
    "            noise = torch.randn_like(image) * 0.1\n",
    "            image = image + noise\n",
    "            image = torch.clamp(image, 0, 1)\n",
    "\n",
    "        # Color jittering\n",
    "        if torch.rand(1) < 0.5:\n",
    "            brightness_factor = torch.tensor(1.0).uniform_(0.8, 1.2).item()\n",
    "            contrast_factor = torch.tensor(1.0).uniform_(0.8, 1.2).item()\n",
    "            saturation_factor = torch.tensor(1.0).uniform_(0.8, 1.2).item()\n",
    "            hue_factor = torch.tensor(1.0).uniform_(-0.1, 0.1).item()\n",
    "            image = TF.adjust_brightness(image, brightness_factor)\n",
    "            image = TF.adjust_contrast(image, contrast_factor)\n",
    "            image = TF.adjust_saturation(image, saturation_factor)\n",
    "            image = TF.adjust_hue(image, hue_factor)\n",
    "\n",
    "        # SLIC superpixels\n",
    "        if torch.rand(1) < 0.5:\n",
    "            image = self.apply_slic(image)\n",
    "\n",
    "        # Zoom blur\n",
    "        if torch.rand(1) < 0.5:\n",
    "            image = self.zoom_blur(image)\n",
    "\n",
    "        # Random cropping with resizing\n",
    "        if torch.rand(1) < 0.5:\n",
    "            i, j, h, w = transforms.RandomCrop.get_params(image, output_size=(224, 224))\n",
    "            image = TF.crop(image, i, j, h, w)\n",
    "            binary_mask = TF.crop(binary_mask, i, j, h, w)\n",
    "            multi_class_mask = TF.crop(multi_class_mask, i, j, h, w)\n",
    "\n",
    "        # Resize back to original size\n",
    "        image = TF.resize(image, original_size)\n",
    "        binary_mask = TF.resize(binary_mask, original_size)\n",
    "        multi_class_mask = TF.resize(multi_class_mask, original_size, interpolation=TF.InterpolationMode.NEAREST)\n",
    "        hv_map = TF.resize(hv_map, original_size, interpolation=TF.InterpolationMode.BILINEAR)\n",
    "\n",
    "        return image, binary_mask, multi_class_mask, hv_map\n",
    "\n",
    "    def elastic_transform(self, image, alpha=1, sigma=0.1, alpha_affine=0.1, is_mask=False):\n",
    "        \"\"\"Elastic deformation of images as described in [Simard2003]_.\"\"\"\n",
    "        random_state = np.random.RandomState(None)\n",
    "\n",
    "        if image.ndim == 2:\n",
    "            shape = image.shape\n",
    "        elif image.ndim == 3:\n",
    "            shape = image.shape[:2]\n",
    "        else:\n",
    "            raise ValueError(\"Image must be 2D or 3D\")\n",
    "\n",
    "        # Random affine\n",
    "        center_square = np.float32(shape) // 2\n",
    "        square_size = min(shape) // 3\n",
    "        pts1 = np.float32([center_square + square_size, [center_square[0]+square_size, center_square[1]-square_size], center_square - square_size])\n",
    "        pts2 = pts1 + random_state.uniform(-alpha_affine, alpha_affine, size=pts1.shape).astype(np.float32)\n",
    "        M = cv2.getAffineTransform(pts1, pts2)\n",
    "\n",
    "        if is_mask:\n",
    "            if image.ndim == 2:\n",
    "                image = cv2.warpAffine(image, M, shape[::-1], borderMode=cv2.BORDER_CONSTANT, flags=cv2.INTER_NEAREST)\n",
    "            else:\n",
    "                image = np.stack([cv2.warpAffine(image[:,:,i], M, shape[::-1], borderMode=cv2.BORDER_CONSTANT, flags=cv2.INTER_NEAREST) for i in range(image.shape[2])], axis=2)\n",
    "        else:\n",
    "            if image.ndim == 2:\n",
    "                image = cv2.warpAffine(image, M, shape[::-1], borderMode=cv2.BORDER_REFLECT_101)\n",
    "            else:\n",
    "                image = np.stack([cv2.warpAffine(image[:,:,i], M, shape[::-1], borderMode=cv2.BORDER_REFLECT_101) for i in range(image.shape[2])], axis=2)\n",
    "\n",
    "        dx = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma) * alpha\n",
    "        dy = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma) * alpha\n",
    "\n",
    "        x, y = np.meshgrid(np.arange(shape[1]), np.arange(shape[0]))\n",
    "        indices = np.reshape(y+dy, (-1, 1)), np.reshape(x+dx, (-1, 1))\n",
    "\n",
    "        if is_mask:\n",
    "            if image.ndim == 2:\n",
    "                return map_coordinates(image, indices, order=0, mode='constant').reshape(shape)\n",
    "            else:\n",
    "                return np.stack([map_coordinates(image[:,:,i], indices, order=0, mode='constant').reshape(shape) for i in range(image.shape[2])], axis=2)\n",
    "        else:\n",
    "            if image.ndim == 2:\n",
    "                return map_coordinates(image, indices, order=1, mode='reflect').reshape(shape)\n",
    "            else:\n",
    "                return np.stack([map_coordinates(image[:,:,i], indices, order=1, mode='reflect').reshape(shape) for i in range(image.shape[2])], axis=2)\n",
    "\n",
    "    def apply_slic(self, image):\n",
    "        image_np = image.numpy().transpose(1, 2, 0)\n",
    "        segments = slic(image_np, n_segments=100, compactness=10, sigma=1)\n",
    "        out = np.zeros_like(image_np)\n",
    "        for i in np.unique(segments):\n",
    "            mask = segments == i\n",
    "            out[mask] = np.mean(image_np[mask], axis=0)\n",
    "        return torch.from_numpy(out.transpose(2, 0, 1))\n",
    "\n",
    "    def zoom_blur(self, image, max_factor=1.2):\n",
    "        c, h, w = image.shape\n",
    "        zoom_factor = torch.FloatTensor(1).uniform_(1, max_factor).item()\n",
    "        zh = int(np.round(h * zoom_factor))\n",
    "        zw = int(np.round(w * zoom_factor))\n",
    "        zoom_image = TF.resize(image, (zh, zw))\n",
    "        zoom_image = TF.center_crop(zoom_image, (h, w))\n",
    "        return (image + zoom_image) / 2\n",
    "\n",
    "# Usage example\n",
    "# Usage example\n",
    "chosen_split = 2\n",
    "\n",
    "# Define transforms\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda x: x if isinstance(x, torch.Tensor) else torch.from_numpy(x).permute(2, 0, 1)),\n",
    "    transforms.Lambda(lambda x: x.float())\n",
    "])\n",
    "\n",
    "mask_transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda x: x if isinstance(x, torch.Tensor) else torch.from_numpy(x).unsqueeze(0)),\n",
    "    transforms.Lambda(lambda x: x.float())\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = CellSegmentationDataset(\n",
    "    data_splits[chosen_split]['train']['images'],\n",
    "    data_splits[chosen_split]['train']['masks'],\n",
    "    data_splits[chosen_split]['train']['types'],\n",
    "    image_transform=image_transform,\n",
    "    mask_transform=mask_transform,\n",
    "    augment=True  # Enable augmentation for training set\n",
    ")\n",
    "\n",
    "val_dataset = CellSegmentationDataset(\n",
    "    data_splits[chosen_split]['val']['images'],\n",
    "    data_splits[chosen_split]['val']['masks'],\n",
    "    data_splits[chosen_split]['val']['types'],\n",
    "    image_transform=image_transform,\n",
    "    mask_transform=mask_transform,\n",
    "    augment=False  # No augmentation for validation set\n",
    ")\n",
    "\n",
    "test_dataset = CellSegmentationDataset(\n",
    "    data_splits[chosen_split]['test']['images'],\n",
    "    data_splits[chosen_split]['test']['masks'],\n",
    "    data_splits[chosen_split]['test']['types'],\n",
    "    image_transform=image_transform,\n",
    "    mask_transform=mask_transform,\n",
    "    augment=False  # No augmentation for test set\n",
    ")\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# Check first item in train_dataset\n",
    "print(\"\\nChecking first item in train_dataset:\")\n",
    "image, binary_mask, multi_class_mask, hv_map, tissue_type_onehot, global_cell_labels = train_dataset[0]\n",
    "print(f\"Image shape: {image.shape}, dtype: {image.dtype}\")\n",
    "print(f\"Binary mask shape: {binary_mask.shape}, dtype: {binary_mask.dtype}\")\n",
    "print(f\"Multi-class mask shape: {multi_class_mask.shape}, dtype: {multi_class_mask.dtype}\")\n",
    "print(f\"HV map shape: {hv_map.shape}, dtype: {hv_map.dtype}\")\n",
    "print(f\"Tissue type one-hot encoding: {tissue_type_onehot}\")\n",
    "print(f\"Global cell labels: {global_cell_labels}\")\n",
    "print(f\"Image min: {image.min().item():.4f}, max: {image.max().item():.4f}\")\n",
    "print(f\"Binary mask min: {binary_mask.min().item():.4f}, max: {binary_mask.max().item():.4f}\")\n",
    "print(f\"Multi-class mask min: {multi_class_mask.min().item():.4f}, max: {multi_class_mask.max().item():.4f}\")\n",
    "print(f\"HV map min: {hv_map.min().item():.4f}, max: {hv_map.max().item():.4f}\")\n",
    "print(f\"Unique tissue types: {train_dataset.unique_tissue_types}\")\n",
    "print(f\"Unique cell types: {train_dataset.unique_cell_types}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6812ae-c39e-4973-8581-481209482e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def visualize_samples(dataset, num_samples=2, set_name=\"\"):\n",
    "    fig, axes = plt.subplots(num_samples, 6, figsize=(30, 5*num_samples))\n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        idx = np.random.randint(len(dataset))\n",
    "        \n",
    "        # Get the sample\n",
    "        try:\n",
    "            sample = dataset[idx]\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting sample {idx} from {set_name} dataset: {str(e)}\")\n",
    "            continue\n",
    "        \n",
    "        # Unpack the sample\n",
    "        if len(sample) == 6:\n",
    "            image, binary_mask, multi_class_mask, hv_map, tissue_type_onehot, global_cell_labels = sample\n",
    "        else:\n",
    "            print(f\"Unexpected number of items in sample: {len(sample)}\")\n",
    "            continue\n",
    "        \n",
    "        # Print shapes and dtypes\n",
    "        print(f\"\\nSample {i + 1} from {set_name} dataset:\")\n",
    "        print(f\"Image shape: {image.shape}, dtype: {image.dtype}\")\n",
    "        print(f\"Binary mask shape: {binary_mask.shape}, dtype: {binary_mask.dtype}\")\n",
    "        print(f\"Multi-class mask shape: {multi_class_mask.shape}, dtype: {multi_class_mask.dtype}\")\n",
    "        print(f\"HV map shape: {hv_map.shape}, dtype: {hv_map.dtype}\")\n",
    "        print(f\"Tissue type onehot shape: {tissue_type_onehot.shape}, dtype: {tissue_type_onehot.dtype}\")\n",
    "        print(f\"Global cell labels shape: {global_cell_labels.shape}, dtype: {global_cell_labels.dtype}\")\n",
    "        \n",
    "        # Convert to numpy and ensure correct shape\n",
    "        image = image.permute(1, 2, 0).numpy()\n",
    "        binary_mask = binary_mask.squeeze().numpy()\n",
    "        multi_class_mask = multi_class_mask.squeeze().numpy()\n",
    "        hv_map = hv_map.squeeze().numpy()\n",
    "        \n",
    "        # Adjust multi_class_mask shape if necessary\n",
    "        if multi_class_mask.ndim == 3 and multi_class_mask.shape[-1] == 5:\n",
    "            multi_class_mask = np.transpose(multi_class_mask, (2, 0, 1))\n",
    "        \n",
    "        # Adjust hv_map shape if necessary\n",
    "        if hv_map.ndim == 3 and hv_map.shape[-1] == 2:\n",
    "            hv_map = np.transpose(hv_map, (2, 0, 1))\n",
    "        \n",
    "        # Print min and max values\n",
    "        print(f\"Image min: {image.min():.4f}, max: {image.max():.4f}\")\n",
    "        print(f\"Binary mask min: {binary_mask.min():.4f}, max: {binary_mask.max():.4f}\")\n",
    "        print(f\"Multi-class mask min: {multi_class_mask.min():.4f}, max: {multi_class_mask.max():.4f}\")\n",
    "        print(f\"HV map min: {hv_map.min():.4f}, max: {hv_map.max():.4f}\")\n",
    "        \n",
    "        # Original Image\n",
    "        axes[i, 0].imshow(image)\n",
    "        axes[i, 0].set_title(f\"{set_name} Sample {i+1}\\nOriginal Image\")\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # Binary Segmentation\n",
    "        axes[i, 1].imshow(binary_mask, cmap='gray')\n",
    "        axes[i, 1].set_title(\"Binary Segmentation\")\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        # Cell Classification\n",
    "        num_classes = multi_class_mask.shape[0]\n",
    "        colors = plt.cm.get_cmap('tab10')(np.linspace(0, 1, num_classes))\n",
    "        \n",
    "        # Create the colored cell classification image\n",
    "        cell_class_image = np.zeros((*multi_class_mask.shape[1:], 3))\n",
    "        for class_idx in range(num_classes):\n",
    "            class_mask = multi_class_mask[class_idx] > 0\n",
    "            color = colors[class_idx][:3]\n",
    "            cell_class_image[class_mask] = color\n",
    "        \n",
    "        axes[i, 2].imshow(cell_class_image)\n",
    "        axes[i, 2].set_title(\"Cell Classification\")\n",
    "        axes[i, 2].axis('off')\n",
    "        \n",
    "        # HV Map - Horizontal component\n",
    "        axes[i, 3].imshow(hv_map[0], cmap='coolwarm', vmin=-1, vmax=1)\n",
    "        axes[i, 3].set_title(\"HV Map - Horizontal\")\n",
    "        axes[i, 3].axis('off')\n",
    "        \n",
    "        # HV Map - Vertical component\n",
    "        axes[i, 4].imshow(hv_map[1], cmap='coolwarm', vmin=-1, vmax=1)\n",
    "        axes[i, 4].set_title(\"HV Map - Vertical\")\n",
    "        axes[i, 4].axis('off')\n",
    "        \n",
    "        # Tissue Type and Global Cell Labels\n",
    "        axes[i, 5].axis('off')\n",
    "        tissue_type_idx = tissue_type_onehot.argmax().item()\n",
    "        axes[i, 5].text(0.5, 0.9, f\"Tissue Type: {tissue_type_idx}\", \n",
    "                        horizontalalignment='center', verticalalignment='center',\n",
    "                        fontsize=10, fontweight='bold', transform=axes[i, 5].transAxes)\n",
    "        \n",
    "        axes[i, 5].text(0.5, 0.7, \"Global Cell Labels:\", \n",
    "                        horizontalalignment='center', verticalalignment='center',\n",
    "                        fontsize=10, fontweight='bold', transform=axes[i, 5].transAxes)\n",
    "        \n",
    "        for j, label in enumerate(global_cell_labels):\n",
    "            axes[i, 5].text(0.5, 0.6 - j*0.1, f\"Class {j}: {label.item():.0f}\", \n",
    "                            horizontalalignment='center', verticalalignment='center',\n",
    "                            fontsize=10, transform=axes[i, 5].transAxes)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize samples from each dataset\n",
    "visualize_samples(train_dataset, num_samples=2, set_name=\"Train\")\n",
    "visualize_samples(val_dataset, num_samples=2, set_name=\"Validation\")\n",
    "visualize_samples(test_dataset, num_samples=2, set_name=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4e8746-cc9c-4de6-9957-a24ff920d4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy import ndimage\n",
    "\n",
    "def find_boundaries(labeled_mask):\n",
    "    boundaries = np.zeros_like(labeled_mask, dtype=bool)\n",
    "    for label in np.unique(labeled_mask):\n",
    "        if label == 0:  # Skip background\n",
    "            continue\n",
    "        cell_mask = labeled_mask == label\n",
    "        dilated = ndimage.binary_dilation(cell_mask)\n",
    "        cell_boundary = dilated & ~cell_mask\n",
    "        boundaries |= cell_boundary\n",
    "    return boundaries\n",
    "\n",
    "def visualize_samples(dataset, num_samples=2, set_name=\"\"):\n",
    "    fig, axes = plt.subplots(num_samples, 8, figsize=(40, 5*num_samples))\n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        idx = np.random.randint(len(dataset))\n",
    "        \n",
    "        # Get the sample\n",
    "        try:\n",
    "            sample = dataset[idx]\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting sample {idx} from {set_name} dataset: {str(e)}\")\n",
    "            continue\n",
    "        \n",
    "        # Unpack the sample\n",
    "        if len(sample) == 6:\n",
    "            image, binary_mask, multi_class_mask, hv_map, tissue_type_onehot, global_cell_labels = sample\n",
    "        else:\n",
    "            print(f\"Unexpected number of items in sample: {len(sample)}\")\n",
    "            continue\n",
    "        \n",
    "        # Print shapes and dtypes\n",
    "        print(f\"\\nSample {i + 1} from {set_name} dataset:\")\n",
    "        print(f\"Image shape: {image.shape}, dtype: {image.dtype}\")\n",
    "        print(f\"Binary mask shape: {binary_mask.shape}, dtype: {binary_mask.dtype}\")\n",
    "        print(f\"Multi-class mask shape: {multi_class_mask.shape}, dtype: {multi_class_mask.dtype}\")\n",
    "        print(f\"HV map shape: {hv_map.shape}, dtype: {hv_map.dtype}\")\n",
    "        print(f\"Tissue type onehot shape: {tissue_type_onehot.shape}, dtype: {tissue_type_onehot.dtype}\")\n",
    "        print(f\"Global cell labels shape: {global_cell_labels.shape}, dtype: {global_cell_labels.dtype}\")\n",
    "        \n",
    "        # Convert to numpy and ensure correct shape\n",
    "        image = image.permute(1, 2, 0).numpy()\n",
    "        binary_mask = binary_mask.squeeze().numpy()\n",
    "        multi_class_mask = multi_class_mask.squeeze().numpy()\n",
    "        hv_map = hv_map.squeeze().numpy()\n",
    "        \n",
    "        # Adjust multi_class_mask shape if necessary\n",
    "        if multi_class_mask.ndim == 3 and multi_class_mask.shape[-1] == 5:\n",
    "            multi_class_mask = np.transpose(multi_class_mask, (2, 0, 1))\n",
    "        \n",
    "        # Adjust hv_map shape if necessary\n",
    "        if hv_map.ndim == 3 and hv_map.shape[-1] == 2:\n",
    "            hv_map = np.transpose(hv_map, (2, 0, 1))\n",
    "        \n",
    "        # Print min and max values\n",
    "        print(f\"Image min: {image.min():.4f}, max: {image.max():.4f}\")\n",
    "        print(f\"Binary mask min: {binary_mask.min():.4f}, max: {binary_mask.max():.4f}\")\n",
    "        print(f\"Multi-class mask min: {multi_class_mask.min():.4f}, max: {multi_class_mask.max():.4f}\")\n",
    "        print(f\"HV map min: {hv_map.min():.4f}, max: {hv_map.max():.4f}\")\n",
    "        \n",
    "        # Original Image\n",
    "        axes[i, 0].imshow(image)\n",
    "        axes[i, 0].set_title(f\"{set_name} Sample {i+1}\\nOriginal Image\")\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # Binary Segmentation\n",
    "        axes[i, 1].imshow(binary_mask, cmap='gray')\n",
    "        axes[i, 1].set_title(\"Binary Segmentation\")\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        # Cell Classification\n",
    "        num_classes = multi_class_mask.shape[0]\n",
    "        colors = plt.cm.get_cmap('tab10')(np.linspace(0, 1, num_classes))\n",
    "        \n",
    "        # Create the colored cell classification image\n",
    "        cell_class_image = np.zeros((*multi_class_mask.shape[1:], 3))\n",
    "        for class_idx in range(num_classes):\n",
    "            class_mask = multi_class_mask[class_idx] > 0\n",
    "            color = colors[class_idx][:3]\n",
    "            cell_class_image[class_mask] = color\n",
    "        \n",
    "        axes[i, 2].imshow(cell_class_image)\n",
    "        axes[i, 2].set_title(\"Cell Classification\")\n",
    "        axes[i, 2].axis('off')\n",
    "        \n",
    "        # HV Map - Horizontal component\n",
    "        axes[i, 3].imshow(hv_map[0], cmap='coolwarm', vmin=-1, vmax=1)\n",
    "        axes[i, 3].set_title(\"HV Map - Horizontal\")\n",
    "        axes[i, 3].axis('off')\n",
    "        \n",
    "        # HV Map - Vertical component\n",
    "        axes[i, 4].imshow(hv_map[1], cmap='coolwarm', vmin=-1, vmax=1)\n",
    "        axes[i, 4].set_title(\"HV Map - Vertical\")\n",
    "        axes[i, 4].axis('off')\n",
    "        \n",
    "        # Combined HV Map\n",
    "        combined_hv = np.sqrt(np.square(hv_map[0]) + np.square(hv_map[1]))\n",
    "        axes[i, 5].imshow(combined_hv, cmap='viridis')\n",
    "        axes[i, 5].set_title(\"Combined HV Map\")\n",
    "        axes[i, 5].axis('off')\n",
    "        \n",
    "        # Cell Boundaries\n",
    "        labeled_mask = np.argmax(multi_class_mask, axis=0) + 1  # +1 to reserve 0 for background\n",
    "        labeled_mask[binary_mask == 0] = 0  # Set background to 0\n",
    "        boundaries = find_boundaries(labeled_mask)\n",
    "        \n",
    "        axes[i, 6].imshow(image)\n",
    "        axes[i, 6].imshow(boundaries, alpha=0.4, cmap='gray')\n",
    "        axes[i, 6].set_title(\"Cell Boundaries\")\n",
    "        axes[i, 6].axis('off')\n",
    "        \n",
    "        # Tissue Type and Global Cell Labels\n",
    "        axes[i, 7].axis('off')\n",
    "        tissue_type_idx = tissue_type_onehot.argmax().item()\n",
    "        axes[i, 7].text(0.5, 0.9, f\"Tissue Type: {tissue_type_idx}\", \n",
    "                        horizontalalignment='center', verticalalignment='center',\n",
    "                        fontsize=10, fontweight='bold', transform=axes[i, 7].transAxes)\n",
    "        \n",
    "        axes[i, 7].text(0.5, 0.7, \"Global Cell Labels:\", \n",
    "                        horizontalalignment='center', verticalalignment='center',\n",
    "                        fontsize=10, fontweight='bold', transform=axes[i, 7].transAxes)\n",
    "        \n",
    "        for j, label in enumerate(global_cell_labels):\n",
    "            axes[i, 7].text(0.5, 0.6 - j*0.1, f\"Class {j}: {label.item():.0f}\", \n",
    "                            horizontalalignment='center', verticalalignment='center',\n",
    "                            fontsize=10, transform=axes[i, 7].transAxes)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize samples from each dataset\n",
    "visualize_samples(train_dataset, num_samples=2, set_name=\"Train\")\n",
    "visualize_samples(val_dataset, num_samples=2, set_name=\"Validation\")\n",
    "visualize_samples(test_dataset, num_samples=2, set_name=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03895bd-734a-4423-b70c-1893e086beb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy import ndimage\n",
    "\n",
    "def visualize_cell_boundaries(dataset, num_samples=1, set_name=\"Test\"):\n",
    "    fig, axes = plt.subplots(num_samples, 2, figsize=(20, 10*num_samples))\n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # Get a random sample\n",
    "        idx = np.random.randint(len(dataset))\n",
    "        image, binary_mask, multi_class_mask, hv_map, tissue_type_onehot, global_cell_labels = dataset[idx]\n",
    "        \n",
    "        # Convert tensors to numpy arrays\n",
    "        image = image.permute(1, 2, 0).numpy()\n",
    "        binary_mask = binary_mask.squeeze().numpy()\n",
    "        multi_class_mask = multi_class_mask.numpy()\n",
    "        \n",
    "        # Create a labeled mask where each cell has a unique ID\n",
    "        labeled_mask = np.argmax(multi_class_mask, axis=0) + 1  # +1 to reserve 0 for background\n",
    "        labeled_mask[binary_mask == 0] = 0  # Set background to 0\n",
    "        \n",
    "        # Find boundaries\n",
    "        boundaries = find_boundaries(labeled_mask)\n",
    "        \n",
    "        # Ensure boundaries is 2D\n",
    "        if boundaries.ndim > 2:\n",
    "            boundaries = np.max(boundaries, axis=2)\n",
    "        \n",
    "        # Display original image\n",
    "        axes[i, 0].imshow(image)\n",
    "        axes[i, 0].set_title(f\"{set_name} Sample {i+1}: Original Image\")\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # Display image with cell boundaries\n",
    "        axes[i, 1].imshow(image)\n",
    "        axes[i, 1].imshow(boundaries, alpha=0.4, cmap='gray')\n",
    "        axes[i, 1].set_title(f\"{set_name} Sample {i+1}: Cell Boundaries\")\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        # Print additional information\n",
    "        tissue_type = dataset.unique_tissue_types[torch.argmax(tissue_type_onehot).item()]\n",
    "        present_cell_types = [dataset.unique_cell_types[i] for i, present in enumerate(global_cell_labels) if present]\n",
    "        \n",
    "        print(f\"\\nSample {i + 1} from {set_name} dataset:\")\n",
    "        print(f\"Tissue Type: {tissue_type}\")\n",
    "        print(f\"Present Cell Types: {present_cell_types}\")\n",
    "        print(f\"Image shape: {image.shape}, dtype: {image.dtype}\")\n",
    "        print(f\"Boundaries shape: {boundaries.shape}, dtype: {boundaries.dtype}\")\n",
    "        print(f\"Image min: {image.min():.4f}, max: {image.max():.4f}\")\n",
    "        print(f\"Boundaries min: {boundaries.min():.4f}, max: {boundaries.max():.4f}\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def find_boundaries(labeled_mask):\n",
    "    boundaries = np.zeros_like(labeled_mask, dtype=bool)\n",
    "    for label in np.unique(labeled_mask):\n",
    "        if label == 0:  # Skip background\n",
    "            continue\n",
    "        cell_mask = labeled_mask == label\n",
    "        dilated = ndimage.binary_dilation(cell_mask)\n",
    "        cell_boundary = dilated & ~cell_mask\n",
    "        boundaries |= cell_boundary\n",
    "    return boundaries\n",
    "\n",
    "# Visualize samples from the test dataset\n",
    "visualize_cell_boundaries(test_dataset, num_samples=2)\n",
    "\n",
    "def find_boundaries(labeled_mask):\n",
    "    boundaries = np.zeros_like(labeled_mask, dtype=bool)\n",
    "    for label in np.unique(labeled_mask):\n",
    "        if label == 0:  # Skip background\n",
    "            continue\n",
    "        cell_mask = labeled_mask == label\n",
    "        dilated = ndimage.binary_dilation(cell_mask)\n",
    "        cell_boundary = dilated & ~cell_mask\n",
    "        boundaries |= cell_boundary\n",
    "    return boundaries\n",
    "\n",
    "# Visualize samples from the test dataset\n",
    "visualize_cell_boundaries(test_dataset, num_samples=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae11384c-c01e-434e-86e5-4c1aca96d0ec",
   "metadata": {},
   "source": [
    "## model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90bad30-6bfa-40b0-8dab-9f1669037e33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import swin_t, Swin_T_Weights\n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.norm1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.norm2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se = SEBlock(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.norm1(self.conv1(x)))\n",
    "        x = self.relu(self.norm2(self.conv2(x)))\n",
    "        x = self.se(x)\n",
    "        return x\n",
    "\n",
    "class SwinEncoder(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super().__init__()\n",
    "        if pretrained:\n",
    "            weights = Swin_T_Weights.IMAGENET1K_V1\n",
    "        else:\n",
    "            weights = None\n",
    "        self.swin = swin_t(weights=weights)\n",
    "        self.swin.head = nn.Identity()  # Remove the classifier head\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = []\n",
    "        for i, layer in enumerate(self.swin.features):\n",
    "            x = layer(x)\n",
    "            if i in [2, 4, 6]:  # Collect features from specific layers\n",
    "                features.append(x)\n",
    "        return features\n",
    "\n",
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        super(AttentionBlock, self).__init__()\n",
    "        self.W_g = nn.Sequential(\n",
    "            nn.Conv2d(F_g, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "        self.W_x = nn.Sequential(\n",
    "            nn.Conv2d(F_l, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, g, x):\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.relu(g1 + x1)\n",
    "        psi = self.psi(psi)\n",
    "        return x * psi\n",
    "\n",
    "class MultiHeadDecoder(nn.Module):\n",
    "    def __init__(self, num_cell_classes, num_tissue_classes):\n",
    "        super().__init__()\n",
    "        self.decoder1 = DecoderBlock(768, 384)\n",
    "        self.decoder2 = DecoderBlock(384 + 384, 192)\n",
    "        self.decoder3 = DecoderBlock(192 + 192, 96)\n",
    "        self.decoder4 = DecoderBlock(96 + 192, 48)\n",
    "        \n",
    "        # Binary cell segmentation (all cells)\n",
    "        self.cell_seg_conv = nn.Conv2d(48, 1, kernel_size=1)\n",
    "        \n",
    "        # Cell type classification\n",
    "        self.cell_class_conv = nn.Conv2d(48, num_cell_classes, kernel_size=1)\n",
    "        \n",
    "        # Tissue classification branch\n",
    "        self.tc_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.tc_fc = nn.Sequential(\n",
    "            nn.Linear(768, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_tissue_classes)\n",
    "        )\n",
    "        \n",
    "        # Global cell classification\n",
    "        self.global_cell_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        self.global_cell_fc = nn.Sequential(\n",
    "            nn.Linear(768, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_cell_classes)\n",
    "        )\n",
    "        \n",
    "        # HV branch\n",
    "        self.hv_conv = nn.Conv2d(48, 2, kernel_size=1)  # 2 channels for horizontal and vertical maps\n",
    "        \n",
    "        self.attention1 = AttentionBlock(F_g=384, F_l=384, F_int=192)\n",
    "        self.attention2 = AttentionBlock(F_g=192, F_l=192, F_int=96)\n",
    "        self.attention3 = AttentionBlock(F_g=96, F_l=192, F_int=48)\n",
    "\n",
    "    def forward(self, features):\n",
    "        x = features[-1]\n",
    "        x = x.permute(0, 3, 1, 2)  # Change from [B, H, W, C] to [B, C, H, W]\n",
    "        x = self.decoder1(x)\n",
    "        x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        \n",
    "        skip1 = F.interpolate(features[-2].permute(0, 3, 1, 2), size=x.shape[2:], mode='bilinear', align_corners=False)\n",
    "        x = torch.cat([x, self.attention1(x, skip1)], dim=1)\n",
    "        x = self.decoder2(x)\n",
    "        x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        \n",
    "        skip2 = F.interpolate(features[-3].permute(0, 3, 1, 2), size=x.shape[2:], mode='bilinear', align_corners=False)\n",
    "        x = torch.cat([x, self.attention2(x, skip2)], dim=1)\n",
    "        x = self.decoder3(x)\n",
    "        x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        \n",
    "        skip3 = F.interpolate(features[0].permute(0, 3, 1, 2), size=x.shape[2:], mode='bilinear', align_corners=False)\n",
    "        x = torch.cat([x, self.attention3(x, skip3)], dim=1)\n",
    "        x = self.decoder4(x)\n",
    "        x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # Binary cell segmentation (all cells)\n",
    "        cell_seg_out = self.cell_seg_conv(x)\n",
    "        cell_seg_out = F.interpolate(cell_seg_out, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # Cell type classification\n",
    "        cell_class_out = self.cell_class_conv(x)\n",
    "        cell_class_out = F.interpolate(cell_class_out, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # Tissue classification (tc)\n",
    "        tc_out = self.tc_pool(features[-1].permute(0, 3, 1, 2))\n",
    "        tc_out = tc_out.view(tc_out.size(0), -1)\n",
    "        tc_out = self.tc_fc(tc_out)\n",
    "        \n",
    "        # Global cell classification\n",
    "        global_cell_features = self.global_cell_pool(features[-1].permute(0, 3, 1, 2))\n",
    "        global_cell_features = global_cell_features.view(global_cell_features.size(0), -1)\n",
    "        global_cell_out = self.global_cell_fc(global_cell_features)\n",
    "        \n",
    "        # HV distance maps\n",
    "        hv_out = self.hv_conv(x)\n",
    "        hv_out = F.interpolate(hv_out, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        \n",
    "        return cell_seg_out, cell_class_out, tc_out, global_cell_out, hv_out\n",
    "\n",
    "class ModifiedCellSwin(nn.Module):\n",
    "    def __init__(self, num_cell_classes, num_tissue_classes, seg_threshold=0.5):\n",
    "        super().__init__()\n",
    "        self.encoder = SwinEncoder()\n",
    "        self.decoder = MultiHeadDecoder(num_cell_classes, num_tissue_classes)\n",
    "        self.seg_threshold = seg_threshold\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x)\n",
    "        cell_seg_out, cell_class_out, tc_out, global_cell_out, hv_out = self.decoder(features)\n",
    "        \n",
    "        # Apply binary segmentation mask to cell classification\n",
    "        cell_seg_mask = (torch.sigmoid(cell_seg_out) > self.seg_threshold).float()\n",
    "        cell_class_out_masked = cell_class_out * cell_seg_mask\n",
    "        \n",
    "        return cell_seg_out, cell_class_out_masked, tc_out, global_cell_out, hv_out\n",
    "\n",
    "# Initialize the model\n",
    "num_cell_classes = 5  # 5 cell types\n",
    "num_tissue_classes = len(train_dataset.unique_tissue_types)  # Should be 19 based on your data\n",
    "model = ModifiedCellSwin(num_cell_classes, num_tissue_classes).float()\n",
    "print(\"Modified CellSwin model with binary segmentation, classification, HV maps, and global cell classification defined.\")\n",
    "\n",
    "# Print model structure\n",
    "print(model)\n",
    "\n",
    "# Verify output shapes\n",
    "sample_input = torch.randn(1, 3, 256, 256)  # Batch size 1, 3 channels, 256x256 image\n",
    "cell_seg_out, cell_class_out_masked, tc_out, global_cell_out, hv_out = model(sample_input)\n",
    "print(f\"cell_seg_out shape: {cell_seg_out.shape}\")\n",
    "print(f\"cell_class_out_masked shape: {cell_class_out_masked.shape}\")\n",
    "print(f\"tc_out shape: {tc_out.shape}\")\n",
    "print(f\"global_cell_out shape: {global_cell_out.shape}\")\n",
    "print(f\"hv_out shape: {hv_out.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb23c42-e58d-4084-b671-cab2c539cbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FocalTverskyLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.7, beta=0.3, gamma=4/3):\n",
    "        super(FocalTverskyLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        inputs = torch.sigmoid(inputs)\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        TP = (inputs * targets).sum()    \n",
    "        FP = ((1-targets) * inputs).sum()\n",
    "        FN = (targets * (1-inputs)).sum()\n",
    "        \n",
    "        Tversky = (TP + 1e-5) / (TP + self.alpha*FP + self.beta*FN + 1e-5)  \n",
    "        FocalTversky = (1 - Tversky)**self.gamma\n",
    "        \n",
    "        return FocalTversky\n",
    "\n",
    "class MultiTaskLoss(nn.Module):\n",
    "    def __init__(self, num_classes, num_tissue_types):\n",
    "        super(MultiTaskLoss, self).__init__()\n",
    "        self.focal_tversky_loss = FocalTverskyLoss()\n",
    "        self.cell_class_loss = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "        self.tissue_class_loss = nn.CrossEntropyLoss()\n",
    "        self.global_cell_loss = nn.BCEWithLogitsLoss()\n",
    "        self.hv_loss = nn.MSELoss()\n",
    "\n",
    "    def forward(self, cell_seg_out, cell_class_out, tc_out, global_cell_out, hv_out,\n",
    "                cell_seg_target, cell_class_target, tissue_type_target, global_cell_target, hv_target):\n",
    "        \n",
    "\n",
    "        # Adjust shapes if necessary\n",
    "        if cell_class_target.dim() == 5:\n",
    "            cell_class_target = cell_class_target.squeeze(1).permute(0, 3, 1, 2)\n",
    "        if hv_target.dim() == 5:\n",
    "            hv_target = hv_target.squeeze(1).permute(0, 3, 1, 2)\n",
    "\n",
    "        # Cell segmentation loss (Focal Tversky)\n",
    "        cell_seg_loss = self.focal_tversky_loss(cell_seg_out, cell_seg_target)\n",
    "        \n",
    "        # Cell classification loss\n",
    "        cell_class_out_reshaped = cell_class_out.permute(0, 2, 3, 1).contiguous().view(-1, cell_class_out.size(1))\n",
    "        cell_class_target_reshaped = cell_class_target.permute(0, 2, 3, 1).contiguous().view(-1, cell_class_target.size(1))\n",
    "        cell_class_loss = self.cell_class_loss(cell_class_out_reshaped, cell_class_target_reshaped.argmax(dim=1))\n",
    "        \n",
    "        # Tissue classification loss\n",
    "        tissue_class_loss = self.tissue_class_loss(tc_out, tissue_type_target.argmax(dim=1))\n",
    "        \n",
    "        # Global cell classification loss\n",
    "        global_cell_loss = self.global_cell_loss(global_cell_out, global_cell_target)\n",
    "        \n",
    "        # HV branch: Horizontal and vertical distance map loss\n",
    "        hv_loss = self.hv_loss(hv_out, hv_target)\n",
    "        \n",
    "        # Compute gradients of HV maps\n",
    "        hv_out_grad = self.compute_gradients(hv_out)\n",
    "        hv_target_grad = self.compute_gradients(hv_target)\n",
    "        hv_grad_loss = self.hv_loss(hv_out_grad, hv_target_grad)\n",
    "        \n",
    "        # Combine losses\n",
    "        total_loss = cell_seg_loss + cell_class_loss + tissue_class_loss + global_cell_loss + hv_loss + hv_grad_loss\n",
    "        \n",
    "        return total_loss, {\n",
    "            'cell_seg_loss': cell_seg_loss.item(),\n",
    "            'cell_class_loss': cell_class_loss.item(),\n",
    "            'tissue_class_loss': tissue_class_loss.item(),\n",
    "            'global_cell_loss': global_cell_loss.item(),\n",
    "            'hv_loss': hv_loss.item(),\n",
    "            'hv_grad_loss': hv_grad_loss.item()\n",
    "        }\n",
    "\n",
    "    def compute_gradients(self, tensor):\n",
    "        # Compute gradients\n",
    "        dx = tensor[:, :, :, 1:] - tensor[:, :, :, :-1]\n",
    "        dy = tensor[:, :, 1:, :] - tensor[:, :, :-1, :]\n",
    "        \n",
    "        # Pad the gradients to match the original size\n",
    "        dx = F.pad(dx, (0, 1, 0, 0), mode='replicate')\n",
    "        dy = F.pad(dy, (0, 0, 0, 1), mode='replicate')\n",
    "        \n",
    "        return torch.cat([dx, dy], dim=1)\n",
    "\n",
    "# Usage example\n",
    "criterion = MultiTaskLoss(num_classes=5, num_tissue_types=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07c791c-d0fb-40be-9d42-f0a4603c0e08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, train_loader, val_loader, num_epochs=10, batch_size=16, learning_rate=1e-4):\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    criterion = MultiTaskLoss(\n",
    "        num_classes=5, \n",
    "        num_tissue_types=19\n",
    "    )\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        loss_dict_sum = {\n",
    "            'cell_seg_loss': 0, 'cell_class_loss': 0, 'tissue_class_loss': 0,\n",
    "            'global_cell_loss': 0, 'hv_loss': 0, 'hv_grad_loss': 0\n",
    "        }\n",
    "        \n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "            images, binary_masks, multi_class_masks, hv_maps, tissue_types, global_cell_labels = batch\n",
    "            images = images.to(device)\n",
    "            binary_masks = binary_masks.to(device)\n",
    "            multi_class_masks = multi_class_masks.to(device)\n",
    "            hv_maps = hv_maps.to(device)\n",
    "            tissue_types = tissue_types.to(device)\n",
    "            global_cell_labels = global_cell_labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            try:\n",
    "                cell_seg_out, cell_class_out, tc_out, global_cell_out, hv_out = model(images)\n",
    "\n",
    "                loss, loss_dict = criterion(cell_seg_out, cell_class_out, tc_out, global_cell_out, hv_out,\n",
    "                                            binary_masks, multi_class_masks, tissue_types, global_cell_labels, hv_maps)\n",
    "\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                for k, v in loss_dict.items():\n",
    "                    loss_dict_sum[k] += v\n",
    "            \n",
    "            except RuntimeError as e:\n",
    "                print(f\"Error in training batch: {e}\")\n",
    "                raise e\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        avg_loss_dict = {k: v / len(train_loader) for k, v in loss_dict_sum.items()}\n",
    "\n",
    "        # Validation loop\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_loss_dict_sum = {k: 0 for k in loss_dict_sum.keys()}\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                images, binary_masks, multi_class_masks, hv_maps, tissue_types, global_cell_labels = batch\n",
    "                images = images.to(device)\n",
    "                binary_masks = binary_masks.to(device)\n",
    "                multi_class_masks = multi_class_masks.to(device)\n",
    "                hv_maps = hv_maps.to(device)\n",
    "                tissue_types = tissue_types.to(device)\n",
    "                global_cell_labels = global_cell_labels.to(device)\n",
    "\n",
    "\n",
    "                cell_seg_out, cell_class_out, tc_out, global_cell_out, hv_out = model(images)\n",
    "\n",
    "\n",
    "                loss, loss_dict = criterion(cell_seg_out, cell_class_out, tc_out, global_cell_out, hv_out,\n",
    "                                            binary_masks, multi_class_masks, tissue_types, global_cell_labels, hv_maps)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                for k, v in loss_dict.items():\n",
    "                    val_loss_dict_sum[k] += v\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        avg_val_loss_dict = {k: v / len(val_loader) for k, v in val_loss_dict_sum.items()}\n",
    "\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"Training Loss: {avg_train_loss:.4f}\")\n",
    "        for k, v in avg_loss_dict.items():\n",
    "            print(f\"  {k}: {v:.4f}\")\n",
    "        print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
    "        for k, v in avg_val_loss_dict.items():\n",
    "            print(f\"  {k}: {v:.4f}\")\n",
    "\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "    print(\"\\nTraining completed!\")\n",
    "    torch.save(model.state_dict(), \"improved_cellswin_model.pth\")\n",
    "    print(\"Model saved successfully!\")\n",
    "\n",
    "# Usage\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "model = ModifiedCellSwin(num_cell_classes=5, num_tissue_classes=19).to(device)\n",
    "\n",
    "# train(model, train_loader, val_loader, num_epochs=60, batch_size=16, learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8186ef00-e38f-4fcc-acb6-37503bd0e8ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Continue training\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "epochs = 100 \n",
    "train(model, train_loader, val_loader, num_epochs=epochs, batch_size=16, learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269e41cf-9598-4315-8728-9313390a0384",
   "metadata": {},
   "source": [
    "## Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbd90f4-8912-43d3-a9f3-974e81cf700e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize the model\n",
    "model = ModifiedCellSwin(num_cell_classes=5, num_tissue_classes=19).to(device)\n",
    "\n",
    "# Load the saved state dict\n",
    "model.load_state_dict(torch.load(\"improved_cellswin_model.pth\", map_location=device))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e465c709-276b-44fa-86dc-fbea65a67e84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fceeb6b5-46c1-4c4c-9a28-6a940c8cdfa2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from scipy import ndimage as ndi\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "# Assuming you have already defined and loaded your ModifiedCellSwin model\n",
    "def postprocess_hv(hv_map, cell_prob, prob_thresh=0.5, hv_thresh=0.2):\n",
    "    # Convert tensors to numpy arrays\n",
    "    hv_map = hv_map.cpu().numpy()\n",
    "    cell_prob = cell_prob.cpu().numpy()\n",
    "\n",
    "    # Compute gradients of HV maps\n",
    "    grad_h = np.abs(hv_map[0, 1:, :] - hv_map[0, :-1, :])\n",
    "    grad_v = np.abs(hv_map[1, :, 1:] - hv_map[1, :, :-1])\n",
    "\n",
    "    # Pad gradients to match original size\n",
    "    grad_h = np.pad(grad_h, ((1, 0), (0, 0)), mode='constant')\n",
    "    grad_v = np.pad(grad_v, ((0, 0), (1, 0)), mode='constant')\n",
    "\n",
    "    # Combine gradients\n",
    "    grad_combined = np.maximum(grad_h, grad_v)\n",
    "\n",
    "    # Create binary mask\n",
    "    cell_mask = cell_prob > prob_thresh\n",
    "    grad_mask = grad_combined > hv_thresh\n",
    "\n",
    "    # Combine masks\n",
    "    mask = cell_mask & (~grad_mask)\n",
    "\n",
    "    # Find peaks (cell centers)\n",
    "    peaks = peak_local_max(cell_prob, min_distance=3, threshold_abs=prob_thresh, labels=mask)\n",
    "\n",
    "    # If no peaks are found, return a blank segmentation\n",
    "    if len(peaks) == 0:\n",
    "        return np.zeros_like(cell_prob, dtype=np.int32).squeeze()\n",
    "\n",
    "    # Create markers for watershed\n",
    "    markers = np.zeros_like(cell_prob, dtype=np.int32)\n",
    "    markers[tuple(peaks.T)] = np.arange(1, len(peaks) + 1)\n",
    "\n",
    "    # Perform watershed\n",
    "    segmentation = watershed(-cell_prob, markers, mask=mask)\n",
    "\n",
    "    return segmentation.squeeze()  # Add squeeze() here\n",
    "\n",
    "def predict_and_postprocess(model, image):\n",
    "    with torch.no_grad():\n",
    "        cell_seg_out, cell_class_out, tc_out, global_cell_out, hv_out = model(image.unsqueeze(0))\n",
    "    \n",
    "    # Apply sigmoid to cell segmentation output\n",
    "    cell_prob = torch.sigmoid(cell_seg_out)\n",
    "    \n",
    "    # Postprocess\n",
    "    segmentation = postprocess_hv(hv_out[0], cell_prob[0])\n",
    "    \n",
    "    return segmentation, cell_class_out.squeeze(0), tc_out.squeeze(0), global_cell_out.squeeze(0)\n",
    "\n",
    "def calculate_metrics(pred_mask, true_mask):\n",
    "    pred_flat = pred_mask.flatten()\n",
    "    true_flat = true_mask.flatten()\n",
    "    \n",
    "    # Calculate F1 score, precision, and recall\n",
    "    f1 = f1_score(true_flat, pred_flat, average='weighted', zero_division=1)\n",
    "    precision = precision_score(true_flat, pred_flat, average='weighted', zero_division=1)\n",
    "    recall = recall_score(true_flat, pred_flat, average='weighted', zero_division=1)\n",
    "    \n",
    "    return f1, precision, recall\n",
    "\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    total_f1, total_precision, total_recall = 0, 0, 0\n",
    "    num_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            images, binary_masks, _, _, _, _ = batch\n",
    "            images = images.to(device)\n",
    "            \n",
    "            for i in range(images.size(0)):\n",
    "                segmentation, _, _, _ = predict_and_postprocess(model, images[i])\n",
    "                \n",
    "                # Assuming binary_masks contains the ground truth segmentation\n",
    "                true_mask = binary_masks[i].squeeze().cpu().numpy()\n",
    "                \n",
    "\n",
    "                \n",
    "                f1, precision, recall = calculate_metrics(segmentation, true_mask)\n",
    "                \n",
    "                total_f1 += f1\n",
    "                total_precision += precision\n",
    "                total_recall += recall\n",
    "                num_samples += 1\n",
    "\n",
    "    \n",
    "    avg_f1 = total_f1 / num_samples\n",
    "    avg_precision = total_precision / num_samples\n",
    "    avg_recall = total_recall / num_samples\n",
    "    \n",
    "    return avg_f1, avg_precision, avg_recall\n",
    "\n",
    "# Visualization function\n",
    "def visualize_results(image, true_mask, pred_mask, save_path=None):\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    ax1.imshow(image.permute(1, 2, 0).cpu().numpy())\n",
    "    ax1.set_title('Original Image')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    ax2.imshow(true_mask, cmap='nipy_spectral')\n",
    "    ax2.set_title('True Mask')\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    # Convert pred_mask to int32 if it's not already\n",
    "    pred_mask = pred_mask.astype(np.int32) if pred_mask.dtype != np.int32 else pred_mask\n",
    "    ax3.imshow(pred_mask, cmap='nipy_spectral')\n",
    "    ax3.set_title('Predicted Mask')\n",
    "    ax3.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "    else:\n",
    "        plt.show()\n",
    "    \n",
    "    plt.close(fig)  # Close the figure to free up memory\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Set the device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Initialize the model (assuming you have this defined)\n",
    "    model = ModifiedCellSwin(num_cell_classes=5, num_tissue_classes=19).to(device)\n",
    "\n",
    "    # Load the saved state dict\n",
    "    model.load_state_dict(torch.load(\"improved_cellswin_model.pth\", map_location=device))\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    print(\"Model loaded successfully!\")\n",
    "\n",
    "    # Run evaluation\n",
    "    avg_f1, avg_precision, avg_recall = evaluate_model(model, test_loader, device)\n",
    "\n",
    "    print(f\"Average F1 Score: {avg_f1:.4f}\")\n",
    "    print(f\"Average Precision: {avg_precision:.4f}\")\n",
    "    print(f\"Average Recall: {avg_recall:.4f}\")\n",
    "\n",
    "    # Visualize some results (optional)\n",
    "# Visualize some results (optional)\n",
    "    for i, (images, binary_masks, _, _, _, _) in enumerate(test_loader):\n",
    "        if i >= 5:  # Visualize first 5 images\n",
    "            break\n",
    "        image = images[0].to(device)\n",
    "        true_mask = binary_masks[0].squeeze().cpu().numpy()\n",
    "        pred_mask, _, _, _ = predict_and_postprocess(model, image)\n",
    "\n",
    "        print(f\"Pred mask shape: {pred_mask.shape}\")\n",
    "        print(f\"Unique values in pred mask: {np.unique(pred_mask)}\")\n",
    "\n",
    "        visualize_results(image.cpu(), true_mask, pred_mask, f'result_{i}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ea8b07-0923-4ad9-8790-d884df673685",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "\n",
    "def postprocess_hv(hv_map, cell_prob, prob_thresh=0.5, hv_thresh=0.1):\n",
    "    # Convert tensors to numpy arrays\n",
    "    hv_map = hv_map.cpu().numpy()\n",
    "    cell_prob = cell_prob.cpu().numpy().squeeze()\n",
    "\n",
    "    # Compute gradients of HV maps\n",
    "    grad_h = np.abs(hv_map[0, 1:, :] - hv_map[0, :-1, :])\n",
    "    grad_v = np.abs(hv_map[1, :, 1:] - hv_map[1, :, :-1])\n",
    "\n",
    "    # Pad gradients to match original size\n",
    "    grad_h = np.pad(grad_h, ((1, 0), (0, 0)), mode='constant')\n",
    "    grad_v = np.pad(grad_v, ((0, 0), (1, 0)), mode='constant')\n",
    "\n",
    "    # Combine gradients\n",
    "    grad_combined = np.maximum(grad_h, grad_v)\n",
    "\n",
    "    # Create binary mask from cell probability\n",
    "    cell_mask = cell_prob > prob_thresh\n",
    "\n",
    "    # Find local maxima (cell centers)\n",
    "    distance = ndi.distance_transform_edt(cell_mask)\n",
    "    coordinates = peak_local_max(distance, footprint=np.ones((3, 3)), labels=cell_mask)\n",
    "    local_maxi = np.zeros_like(cell_mask, dtype=bool)\n",
    "    local_maxi[tuple(coordinates.T)] = True\n",
    "\n",
    "    # Create markers for watershed\n",
    "    markers, _ = ndi.label(local_maxi)\n",
    "\n",
    "    # Invert cell probability for watershed\n",
    "    cell_prob_inv = 1 - cell_prob\n",
    "\n",
    "    # Perform watershed\n",
    "    segmentation = watershed(cell_prob_inv, markers, mask=cell_mask)\n",
    "\n",
    "    return segmentation\n",
    "\n",
    "def predict_and_postprocess(model, image):\n",
    "    with torch.no_grad():\n",
    "        cell_seg_out, cell_class_out, tc_out, global_cell_out, hv_out = model(image.unsqueeze(0))\n",
    "    \n",
    "    print(f\"Cell seg out shape: {cell_seg_out.shape}\")\n",
    "    print(f\"Cell seg out min/max: {cell_seg_out.min().item():.4f}/{cell_seg_out.max().item():.4f}\")\n",
    "    print(f\"HV out shape: {hv_out.shape}\")\n",
    "    print(f\"HV out min/max: {hv_out.min().item():.4f}/{hv_out.max().item():.4f}\")\n",
    "\n",
    "    # Apply sigmoid to cell segmentation output\n",
    "    cell_prob = torch.sigmoid(cell_seg_out)\n",
    "    \n",
    "    # Postprocess\n",
    "    segmentation = postprocess_hv(hv_out[0], cell_prob[0])\n",
    "    \n",
    "    return segmentation, cell_class_out.squeeze(0), tc_out.squeeze(0), global_cell_out.squeeze(0), cell_prob[0], hv_out[0]\n",
    "\n",
    "def visualize_results(image, true_mask, segmentation, hv_map, cell_prob, cell_class_out, multi_class_mask):\n",
    "    fig, axs = plt.subplots(2, 4, figsize=(20, 10))\n",
    "    \n",
    "    # Original Image\n",
    "    axs[0, 0].imshow(image.permute(1, 2, 0).cpu().numpy())\n",
    "    axs[0, 0].set_title('Original Image')\n",
    "    axs[0, 0].axis('off')\n",
    "    \n",
    "    # Ground Truth Binary Segmentation\n",
    "    axs[0, 1].imshow(true_mask, cmap='gray')\n",
    "    axs[0, 1].set_title('GT Binary Segmentation')\n",
    "    axs[0, 1].axis('off')\n",
    "    \n",
    "    # Predicted Instance Segmentation\n",
    "    axs[0, 2].imshow(segmentation, cmap='nipy_spectral')\n",
    "    axs[0, 2].set_title('Predicted Instance Segmentation')\n",
    "    axs[0, 2].axis('off')\n",
    "    \n",
    "    # Cell Probability\n",
    "    axs[0, 3].imshow(cell_prob.squeeze().cpu().numpy(), cmap='viridis')\n",
    "    axs[0, 3].set_title('Cell Probability')\n",
    "    axs[0, 3].axis('off')\n",
    "    \n",
    "    # HV Map\n",
    "    axs[1, 0].imshow(hv_map[0], cmap='coolwarm')\n",
    "    axs[1, 0].set_title('Horizontal Map')\n",
    "    axs[1, 0].axis('off')\n",
    "    \n",
    "    axs[1, 1].imshow(hv_map[1], cmap='coolwarm')\n",
    "    axs[1, 1].set_title('Vertical Map')\n",
    "    axs[1, 1].axis('off')\n",
    "    \n",
    "    # Ground Truth Cell Classification\n",
    "    if multi_class_mask.ndim == 3:\n",
    "        num_classes = multi_class_mask.shape[-1]\n",
    "        colors = plt.cm.get_cmap('tab10')(np.linspace(0, 1, num_classes))\n",
    "        \n",
    "        gt_cell_class_image = np.zeros((*multi_class_mask.shape[:2], 3))\n",
    "        for class_idx in range(num_classes):\n",
    "            class_mask = multi_class_mask[..., class_idx] > 0\n",
    "            color = colors[class_idx][:3]\n",
    "            gt_cell_class_image[class_mask] = color\n",
    "    else:\n",
    "        gt_cell_class_image = multi_class_mask\n",
    "    \n",
    "    axs[1, 2].imshow(gt_cell_class_image)\n",
    "    axs[1, 2].set_title('Ground Truth\\nCell Classification')\n",
    "    axs[1, 2].axis('off')\n",
    "    \n",
    "    # Predicted Cell Classification\n",
    "    num_classes = cell_class_out.shape[0]\n",
    "    pred_cell_class_image = np.zeros((*cell_class_out.shape[1:], 3))\n",
    "    cell_class_out_argmax = np.argmax(cell_class_out.cpu().numpy(), axis=0)\n",
    "\n",
    "    for class_idx in range(num_classes):\n",
    "        class_mask = (cell_class_out_argmax == class_idx) & (segmentation > 0)\n",
    "        color = colors[class_idx][:3]\n",
    "        pred_cell_class_image[class_mask] = color\n",
    "\n",
    "    pred_cell_class_image[segmentation == 0] = [0, 0, 0]\n",
    "    \n",
    "    axs[1, 3].imshow(pred_cell_class_image)\n",
    "    axs[1, 3].set_title('Predicted\\nCell Classification')\n",
    "    axs[1, 3].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Set the device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Initialize the model (assuming you have this defined)\n",
    "    model = ModifiedCellSwin(num_cell_classes=5, num_tissue_classes=19).to(device)\n",
    "\n",
    "    # Load the saved state dict\n",
    "    model.load_state_dict(torch.load(\"improved_cellswin_model.pth\", map_location=device))\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    print(\"Model loaded successfully!\")\n",
    "\n",
    "    # Process and visualize 5 samples\n",
    "    for i, (images, binary_masks, multi_class_masks, hv_maps, tissue_types, global_cell_labels) in enumerate(test_loader):\n",
    "        if i >= 5:\n",
    "            break\n",
    "        \n",
    "        image = images[0].to(device)\n",
    "        true_mask = binary_masks[0].squeeze().cpu().numpy()\n",
    "        true_hv_map = hv_maps[0].squeeze().cpu().numpy()\n",
    "        multi_class_mask = multi_class_masks[0].squeeze().cpu().numpy()\n",
    "        \n",
    "        segmentation, cell_class_out, tc_out, global_cell_out, cell_prob, hv_out = predict_and_postprocess(model, image)\n",
    "        \n",
    "        print(f\"\\nSample {i+1}:\")\n",
    "        print(f\"True mask shape: {true_mask.shape}\")\n",
    "        print(f\"Segmentation shape: {segmentation.shape}\")\n",
    "        print(f\"Unique values in true mask: {np.unique(true_mask)}\")\n",
    "        print(f\"Unique values in segmentation: {np.unique(segmentation)}\")\n",
    "        \n",
    "        visualize_results(image.cpu(), true_mask, segmentation, hv_out.cpu().numpy(), cell_prob, cell_class_out, multi_class_mask)\n",
    "\n",
    "        # Print additional information\n",
    "        print(f\"Binary Mask - Unique values: GT {np.unique(true_mask)}, Pred {np.unique(segmentation > 0)}\")\n",
    "        print(f\"Multi-class Mask - Unique values: GT {np.unique(np.argmax(multi_class_mask, axis=-1) if multi_class_mask.ndim == 3 else multi_class_mask)}, Pred {np.unique(cell_class_out.argmax(dim=0).cpu().numpy()[segmentation > 0])}\")\n",
    "        \n",
    "        # Count cells of each type\n",
    "        num_classes = cell_class_out.shape[0]\n",
    "        for j in range(num_classes):\n",
    "            gt_count = np.sum(np.argmax(multi_class_mask, axis=-1) == j) if multi_class_mask.ndim == 3 else np.sum(multi_class_mask == j)\n",
    "            pred_count = np.sum((cell_class_out.argmax(dim=0).cpu().numpy() == j) & (segmentation > 0))\n",
    "            print(f\"Class {j} (GT | Pred): {gt_count} | {pred_count}\")\n",
    "        \n",
    "        print(f\"Tissue Types - GT {tissue_types[0].argmax().item()}, Pred {tc_out.argmax().item()}\")\n",
    "        print(f\"Global Cell Labels - GT {global_cell_labels[0].argmax().item()}, Pred {global_cell_out.argmax().item()}\")\n",
    "        \n",
    "        # Print prediction confidence\n",
    "        for j in range(num_classes):\n",
    "            class_confidence = cell_class_out[j].cpu().numpy()\n",
    "            print(f\"Class {j} Confidence:\")\n",
    "            print(f\"  Min: {class_confidence.min():.4f}\")\n",
    "            print(f\"  Max: {class_confidence.max():.4f}\")\n",
    "            print(f\"  Mean: {class_confidence.mean():.4f}\")\n",
    "            print(f\"  Std: {class_confidence.std():.4f}\")\n",
    "\n",
    "    print(\"\\nVisualization completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c00360f-5b0c-40c9-bfb0-b5fb0840a03e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9652726d-af3e-46bc-96d7-975a06c6e6ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b15005-9f24-4006-9d9c-791334739a24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c957dc-7586-4d11-a517-01877fea013f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "\n",
    "def visualize_results(model, test_loader, device, num_samples=5):\n",
    "    model.eval()\n",
    "    \n",
    "    fig, axes = plt.subplots(num_samples, 7, figsize=(35, 5*num_samples))\n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (images, binary_masks, multi_class_masks, hv_maps, tissue_types, global_cell_labels) in enumerate(test_loader):\n",
    "            if i >= num_samples:\n",
    "                break\n",
    "            \n",
    "            images = images.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            cell_seg_out, cell_class_out, tc_out, global_cell_out, hv_out = model(images)\n",
    "            \n",
    "            # Move tensors to CPU and convert to numpy for visualization\n",
    "            image = images[0].cpu().permute(1, 2, 0).numpy()\n",
    "            binary_mask = binary_masks[0, 0].cpu().numpy()\n",
    "            multi_class_mask = multi_class_masks[0].squeeze().cpu().numpy()\n",
    "            cell_seg_out_img = cell_seg_out[0, 0].cpu().numpy()\n",
    "            cell_class_out_img = cell_class_out[0].cpu().numpy()\n",
    "            hv_out_img = hv_out[0].cpu().numpy()\n",
    "            \n",
    "            # Normalize image if necessary\n",
    "            if image.max() > 1:\n",
    "                image = image / 255.0\n",
    "            \n",
    "            # Print shapes for debugging\n",
    "            print(f\"Sample {i} shapes:\")\n",
    "            print(f\"image: {image.shape}\")\n",
    "            print(f\"binary_mask: {binary_mask.shape}\")\n",
    "            print(f\"multi_class_mask: {multi_class_mask.shape}\")\n",
    "            print(f\"cell_seg_out_img: {cell_seg_out_img.shape}\")\n",
    "            print(f\"cell_class_out_img: {cell_class_out_img.shape}\")\n",
    "            print(f\"hv_out_img: {hv_out_img.shape}\")\n",
    "            \n",
    "            # Original Image\n",
    "            axes[i, 0].imshow(image)\n",
    "            axes[i, 0].set_title(f\"Sample {i+1}\\nOriginal Image\")\n",
    "            axes[i, 0].axis('off')\n",
    "            \n",
    "            # Ground Truth Binary Segmentation\n",
    "            axes[i, 1].imshow(binary_mask, cmap='gray')\n",
    "            axes[i, 1].set_title(\"GT Binary Segmentation\")\n",
    "            axes[i, 1].axis('off')\n",
    "            \n",
    "            # Predicted Binary Segmentation\n",
    "            axes[i, 2].imshow(cell_seg_out_img > 0.5, cmap='gray')\n",
    "            axes[i, 2].set_title(\"Predicted Binary Segmentation\")\n",
    "            axes[i, 2].axis('off')\n",
    "            \n",
    "            # Ground Truth Cell Classification\n",
    "            num_classes = multi_class_mask.shape[-1]\n",
    "            colors = plt.cm.get_cmap('tab10')(np.linspace(0, 1, num_classes))\n",
    "            \n",
    "            gt_cell_class_image = np.zeros((*multi_class_mask.shape[:2], 3))\n",
    "            for class_idx in range(num_classes):\n",
    "                class_mask = multi_class_mask[..., class_idx] > 0\n",
    "                color = colors[class_idx][:3]\n",
    "                gt_cell_class_image[class_mask] = color\n",
    "            \n",
    "            axes[i, 3].imshow(gt_cell_class_image)\n",
    "            axes[i, 3].set_title(\"Ground Truth\\nCell Classification\")\n",
    "            axes[i, 3].axis('off')\n",
    "            \n",
    "            # Predicted Cell Classification\n",
    "            pred_cell_class_image = np.zeros((*cell_class_out_img.shape[1:], 3))\n",
    "            cell_class_out_argmax = np.argmax(cell_class_out_img, axis=0)\n",
    "            binary_pred = cell_seg_out_img > 0.5\n",
    "\n",
    "            for class_idx in range(num_classes):\n",
    "                class_mask = (cell_class_out_argmax == class_idx) & binary_pred\n",
    "                color = colors[class_idx][:3]\n",
    "                pred_cell_class_image[class_mask] = color\n",
    "\n",
    "            pred_cell_class_image[~binary_pred] = [0, 0, 0]\n",
    "            \n",
    "            axes[i, 4].imshow(pred_cell_class_image)\n",
    "            axes[i, 4].set_title(\"Predicted\\nCell Classification\")\n",
    "            axes[i, 4].axis('off')\n",
    "            \n",
    "            # HV Map Visualization\n",
    "            hv_magnitude = np.sqrt(np.sum(hv_out_img**2, axis=0))\n",
    "            axes[i, 5].imshow(hv_magnitude, cmap='viridis')\n",
    "            axes[i, 5].set_title(\"HV Map Magnitude\")\n",
    "            axes[i, 5].axis('off')\n",
    "\n",
    "            # Cell Boundaries using HV Map\n",
    "            hv_grad_x = cv2.Sobel(hv_out_img[0], cv2.CV_64F, 1, 0, ksize=3)\n",
    "            hv_grad_y = cv2.Sobel(hv_out_img[1], cv2.CV_64F, 0, 1, ksize=3)\n",
    "            hv_edges = np.sqrt(hv_grad_x**2 + hv_grad_y**2)\n",
    "\n",
    "            # Normalize edge intensities\n",
    "            hv_edges = (hv_edges - hv_edges.min()) / (hv_edges.max() - hv_edges.min())\n",
    "\n",
    "            # Threshold edges to create binary boundary map\n",
    "            boundary_threshold = np.percentile(hv_edges, 98)  # Adjust this percentile as needed\n",
    "            cell_boundaries = (hv_edges > boundary_threshold).astype(np.uint8)\n",
    "\n",
    "            # Apply morphological operations to thin and clean up the boundaries\n",
    "            kernel = np.ones((3,3), np.uint8)\n",
    "            cell_boundaries = cv2.morphologyEx(cell_boundaries, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "            cell_boundaries = cv2.dilate(cell_boundaries, kernel, iterations=1)\n",
    "\n",
    "            # Create RGB boundary image with thin white lines\n",
    "            boundary_rgb = np.zeros((*cell_boundaries.shape, 3), dtype=np.float32)\n",
    "            boundary_rgb[cell_boundaries > 0] = [1, 1, 1]  # White boundaries\n",
    "\n",
    "            # Combine predicted cell classification with boundary overlay\n",
    "            combined_image = pred_cell_class_image.copy()\n",
    "            combined_image[cell_boundaries > 0] = [1, 1, 1]  # Set boundary pixels to white\n",
    "\n",
    "            axes[i, 6].imshow(combined_image)\n",
    "            axes[i, 6].set_title(\"Predicted Classification\\nwith Cell Boundaries\")\n",
    "            axes[i, 6].axis('off')\n",
    "\n",
    "            # Tissue Type\n",
    "            predicted_tissue = tc_out[0].argmax().item()\n",
    "            axes[i, 6].text(0.5, -0.1, f\"Predicted Tissue Type: {predicted_tissue}\", \n",
    "                            horizontalalignment='center', verticalalignment='center',\n",
    "                            fontsize=10, fontweight='bold', transform=axes[i, 6].transAxes)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "        # Print additional information\n",
    "        print(f\"\\nSample {i+1}:\")\n",
    "        print(f\"Binary Mask - Unique values: GT {np.unique(binary_mask)}, Pred {np.unique(cell_seg_out_img > 0.5)}\")\n",
    "        print(f\"Multi-class Mask - Unique values: GT {np.unique(np.argmax(multi_class_mask, axis=-1))}, Pred {np.unique(cell_class_out_argmax[binary_pred])}\")\n",
    "        \n",
    "        # Count cells of each type\n",
    "        for j in range(num_classes):\n",
    "            gt_count = np.sum(np.argmax(multi_class_mask, axis=-1) == j)\n",
    "            pred_count = np.sum((cell_class_out_argmax == j) & binary_pred)\n",
    "            print(f\"Class {j} (GT | Pred): {gt_count} | {pred_count}\")\n",
    "        \n",
    "        print(f\"Tissue Types - GT {tissue_types[0].argmax().item()}, Pred {predicted_tissue}\")\n",
    "        print(f\"Global Cell Labels - GT {global_cell_labels[0].argmax().item()}, Pred {global_cell_out[0].argmax().item()}\")\n",
    "        \n",
    "        # Print prediction confidence\n",
    "        for j in range(num_classes):\n",
    "            class_confidence = cell_class_out_img[j]\n",
    "            print(f\"Class {j} Confidence:\")\n",
    "            print(f\"  Min: {class_confidence.min():.4f}\")\n",
    "            print(f\"  Max: {class_confidence.max():.4f}\")\n",
    "            print(f\"  Mean: {class_confidence.mean():.4f}\")\n",
    "            print(f\"  Std: {class_confidence.std():.4f}\")\n",
    "\n",
    "# Call the function\n",
    "visualize_results(model, test_loader, device, num_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a9f786-602b-4673-8ac2-85f3ad4c71f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "\n",
    "def visualize_results(model, test_loader, device, num_samples=5):\n",
    "    model.eval()\n",
    "    \n",
    "    fig, axes = plt.subplots(num_samples, 4, figsize=(20, 5*num_samples))\n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (images, binary_masks, _, _, _, _) in enumerate(test_loader):\n",
    "            if i >= num_samples:\n",
    "                break\n",
    "            \n",
    "            images = images.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            cell_seg_out, _, _, _, hv_out = model(images)\n",
    "            \n",
    "            # Move tensors to CPU and convert to numpy for visualization\n",
    "            image = images[0].cpu().permute(1, 2, 0).numpy()\n",
    "            binary_mask = binary_masks[0, 0].cpu().numpy()\n",
    "            cell_seg_out_img = cell_seg_out[0, 0].cpu().numpy()\n",
    "            hv_out_img = hv_out[0].cpu().numpy()\n",
    "            \n",
    "            # Normalize image if necessary\n",
    "            if image.max() > 1:\n",
    "                image = image / 255.0\n",
    "            \n",
    "            # Original Image\n",
    "            axes[i, 0].imshow(image)\n",
    "            axes[i, 0].set_title(f\"Sample {i+1}\\nOriginal Image\")\n",
    "            axes[i, 0].axis('off')\n",
    "            \n",
    "            # Ground Truth Binary Segmentation\n",
    "            axes[i, 1].imshow(binary_mask, cmap='gray')\n",
    "            axes[i, 1].set_title(\"GT Binary Segmentation\")\n",
    "            axes[i, 1].axis('off')\n",
    "            \n",
    "            # Predicted Binary Segmentation\n",
    "            axes[i, 2].imshow(cell_seg_out_img > 0.5, cmap='gray')\n",
    "            axes[i, 2].set_title(\"Predicted Binary Segmentation\")\n",
    "            axes[i, 2].axis('off')\n",
    "            \n",
    "            # Predicted Segmentation with Cell Boundaries using HV maps\n",
    "            cell_boundaries = get_cell_boundaries(cell_seg_out_img, hv_out_img)\n",
    "            \n",
    "            # Create a copy of the original image for drawing\n",
    "            image_with_boundaries = image.copy()\n",
    "            \n",
    "            # Draw cell boundaries\n",
    "            image_with_boundaries[cell_boundaries > 0] = [1, 0, 0]  # Red color for boundaries\n",
    "            \n",
    "            # Display the image with boundaries\n",
    "            axes[i, 3].imshow(image_with_boundaries)\n",
    "            axes[i, 3].set_title(\"Predicted Segmentation\\nwith Cell Boundaries\")\n",
    "            axes[i, 3].axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "        # Print additional information\n",
    "        print(f\"\\nSample {i+1}:\")\n",
    "        print(f\"Binary Mask - Unique values: GT {np.unique(binary_mask)}, Pred {np.unique(cell_seg_out_img > 0.5)}\")\n",
    "\n",
    "def get_cell_boundaries(cell_seg_out, hv_map):\n",
    "    # Threshold the cell segmentation output\n",
    "    binary_mask = (cell_seg_out > 0.5).astype(np.uint8)\n",
    "    \n",
    "    # Get initial boundaries from binary mask\n",
    "    edges = cv2.Canny(binary_mask, 0.5, 1)\n",
    "    \n",
    "    # Calculate gradients of HV map\n",
    "    h_map, v_map = hv_map[0], hv_map[1]\n",
    "    grad_h = cv2.Sobel(h_map, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    grad_v = cv2.Sobel(v_map, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    \n",
    "    # Compute edge map from HV gradients\n",
    "    hv_edges = np.sqrt(grad_h**2 + grad_v**2)\n",
    "    \n",
    "    # Normalize HV edge map\n",
    "    hv_edges = (hv_edges - hv_edges.min()) / (hv_edges.max() - hv_edges.min())\n",
    "    \n",
    "    # Threshold HV edge map to get potential cell separations\n",
    "    hv_threshold = 0.5  # Increased threshold to focus on stronger edges\n",
    "    hv_boundaries = (hv_edges > hv_threshold).astype(np.uint8)\n",
    "    \n",
    "    # Combine binary mask edges with HV boundaries\n",
    "    cell_boundaries = np.maximum(edges, hv_boundaries)\n",
    "    \n",
    "    # Thin boundaries\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    cell_boundaries = cv2.morphologyEx(cell_boundaries, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    cell_boundaries = cv2.dilate(cell_boundaries, kernel, iterations=1)\n",
    "    \n",
    "    return cell_boundaries\n",
    "\n",
    "# Call the function\n",
    "visualize_results(model, test_loader, device, num_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1e8714-8849-42ed-887a-f58a953f3705",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "\n",
    "def visualize_results(model, test_loader, device, num_samples=5):\n",
    "    model.eval()\n",
    "    \n",
    "    # Convert the test_loader to a list for random sampling\n",
    "    all_samples = list(test_loader)\n",
    "    total_samples = len(all_samples)\n",
    "    \n",
    "    # Randomly select indices\n",
    "    selected_indices = random.sample(range(total_samples), min(num_samples, total_samples))\n",
    "    \n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, 5*num_samples))\n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, idx in enumerate(selected_indices):\n",
    "            images, binary_masks, _, _, _, _ = all_samples[idx]\n",
    "            \n",
    "            images = images.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            cell_seg_out, _, _, _, _ = model(images)\n",
    "            \n",
    "            # Move tensors to CPU and convert to numpy for visualization\n",
    "            image = images[0].cpu().permute(1, 2, 0).numpy()\n",
    "            binary_mask = binary_masks[0, 0].cpu().numpy()\n",
    "            cell_seg_out_img = cell_seg_out[0, 0].cpu().numpy()\n",
    "            \n",
    "            # Normalize image if necessary\n",
    "            if image.max() > 1:\n",
    "                image = image / 255.0\n",
    "            \n",
    "            # Original Image\n",
    "            axes[i, 0].imshow(image)\n",
    "            axes[i, 0].set_title(f\"Sample {idx}\\nOriginal Image\")\n",
    "            axes[i, 0].axis('off')\n",
    "            \n",
    "            # Ground Truth Binary Segmentation\n",
    "            axes[i, 1].imshow(binary_mask, cmap='gray')\n",
    "            axes[i, 1].set_title(\"GT Binary Segmentation\")\n",
    "            axes[i, 1].axis('off')\n",
    "            \n",
    "            # Predicted Binary Segmentation\n",
    "            axes[i, 2].imshow(cell_seg_out_img > 0.5, cmap='gray')\n",
    "            axes[i, 2].set_title(\"Predicted Binary Segmentation\")\n",
    "            axes[i, 2].axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "        # Print additional information\n",
    "        print(f\"\\nSample {idx}:\")\n",
    "        print(f\"Binary Mask - Unique values: GT {np.unique(binary_mask)}, Pred {np.unique(cell_seg_out_img > 0.5)}\")\n",
    "\n",
    "# Call the function\n",
    "visualize_results(model, test_loader, device, num_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc94fdcd-799d-4e4c-9bbe-63ba12b4a5fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157f8522-aa91-4c54-b4cd-f41e6839f3a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "\n",
    "def visualize_results(model, test_loader, device, num_samples=5):\n",
    "    model.eval()\n",
    "    \n",
    "    fig, axes = plt.subplots(num_samples, 7, figsize=(35, 5*num_samples))\n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (images, binary_masks, multi_class_masks, hv_maps, tissue_types, global_cell_labels) in enumerate(test_loader):\n",
    "            if i >= num_samples:\n",
    "                break\n",
    "            \n",
    "            images = images.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            cell_seg_out, cell_class_out, tc_out, global_cell_out, hv_out = model(images)\n",
    "            \n",
    "            # Move tensors to CPU and convert to numpy for visualization\n",
    "            image = images[0].cpu().permute(1, 2, 0).numpy()\n",
    "            binary_mask = binary_masks[0, 0].cpu().numpy()\n",
    "            multi_class_mask = multi_class_masks[0].squeeze().cpu().numpy()\n",
    "            cell_seg_out_img = cell_seg_out[0, 0].cpu().numpy()\n",
    "            cell_class_out_img = cell_class_out[0].cpu().numpy()\n",
    "            hv_out_img = hv_out[0].cpu().numpy()\n",
    "            \n",
    "            # Normalize image if necessary\n",
    "            if image.max() > 1:\n",
    "                image = image / 255.0\n",
    "            \n",
    "            # Original Image\n",
    "            axes[i, 0].imshow(image)\n",
    "            axes[i, 0].set_title(f\"Sample {i+1}\\nOriginal Image\")\n",
    "            axes[i, 0].axis('off')\n",
    "            \n",
    "            # Ground Truth Binary Segmentation\n",
    "            axes[i, 1].imshow(binary_mask, cmap='gray')\n",
    "            axes[i, 1].set_title(\"GT Binary Segmentation\")\n",
    "            axes[i, 1].axis('off')\n",
    "            \n",
    "            # Predicted Binary Segmentation\n",
    "            axes[i, 2].imshow(cell_seg_out_img > 0.5, cmap='gray')\n",
    "            axes[i, 2].set_title(\"Predicted Binary Segmentation\")\n",
    "            axes[i, 2].axis('off')\n",
    "            \n",
    "            # Ground Truth Cell Classification\n",
    "            num_classes = multi_class_mask.shape[-1]\n",
    "            colors = plt.colormaps['tab10'](np.linspace(0, 1, num_classes))\n",
    "            \n",
    "            gt_cell_class_image = np.zeros((*multi_class_mask.shape[:2], 3))\n",
    "            for class_idx in range(num_classes):\n",
    "                class_mask = multi_class_mask[..., class_idx] > 0\n",
    "                color = colors[class_idx][:3]\n",
    "                gt_cell_class_image[class_mask] = color\n",
    "            \n",
    "            axes[i, 3].imshow(gt_cell_class_image)\n",
    "            axes[i, 3].set_title(\"Ground Truth\\nCell Classification\")\n",
    "            axes[i, 3].axis('off')\n",
    "            \n",
    "            # Predicted Cell Classification\n",
    "            pred_cell_class_image = np.zeros((*cell_class_out_img.shape[1:], 3))\n",
    "            cell_class_out_argmax = np.argmax(cell_class_out_img, axis=0)\n",
    "            binary_pred = cell_seg_out_img > 0.5\n",
    "\n",
    "            for class_idx in range(num_classes):\n",
    "                class_mask = (cell_class_out_argmax == class_idx) & binary_pred\n",
    "                color = colors[class_idx][:3]\n",
    "                pred_cell_class_image[class_mask] = color\n",
    "\n",
    "            pred_cell_class_image[~binary_pred] = [0, 0, 0]\n",
    "            \n",
    "            axes[i, 4].imshow(pred_cell_class_image)\n",
    "            axes[i, 4].set_title(\"Predicted\\nCell Classification\")\n",
    "            axes[i, 4].axis('off')\n",
    "            \n",
    "            # HV Map Visualization (only for detected cells)\n",
    "            hv_magnitude = np.sqrt(np.sum(hv_out_img**2, axis=0))\n",
    "            hv_magnitude_masked = hv_magnitude * binary_pred\n",
    "            axes[i, 5].imshow(hv_magnitude_masked, cmap='viridis')\n",
    "            axes[i, 5].set_title(\"HV Map Magnitude\\n(Detected Cells Only)\")\n",
    "            axes[i, 5].axis('off')\n",
    "\n",
    "            # Cell Boundaries using HV Map (only for detected cells)\n",
    "            gx = cv2.Sobel(hv_magnitude_masked, cv2.CV_32F, 1, 0, ksize=3)\n",
    "            gy = cv2.Sobel(hv_magnitude_masked, cv2.CV_32F, 0, 1, ksize=3)\n",
    "            grad_mag = np.sqrt(gx**2 + gy**2)\n",
    "            grad_mag = (grad_mag - grad_mag.min()) / (grad_mag.max() - grad_mag.min() + 1e-8)\n",
    "\n",
    "            # Threshold to get boundaries\n",
    "            threshold = 0.1  # Adjust this value to control boundary detection sensitivity\n",
    "            boundary_mask = (grad_mag > threshold).astype(np.uint8)\n",
    "\n",
    "            # Combine predicted cell classification with boundary overlay\n",
    "            combined_image = pred_cell_class_image.copy()\n",
    "            combined_image[boundary_mask > 0] = [1, 1, 1]  # Set boundary pixels to white\n",
    "\n",
    "            # Only show boundaries where cells are detected\n",
    "            combined_image[~binary_pred] = [0, 0, 0]  # Set non-cell areas to black\n",
    "\n",
    "            axes[i, 6].imshow(combined_image)\n",
    "            axes[i, 6].set_title(\"Predicted Classification\\nwith Cell Boundaries\")\n",
    "            axes[i, 6].axis('off')\n",
    "\n",
    "            # Tissue Type prediction\n",
    "            predicted_tissue = tc_out[0].argmax().item()\n",
    "            axes[i, 6].text(0.5, -0.1, f\"Predicted Tissue Type: {predicted_tissue}\", \n",
    "                            horizontalalignment='center', verticalalignment='center',\n",
    "                            fontsize=10, fontweight='bold', transform=axes[i, 6].transAxes)\n",
    "\n",
    "    \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "        # Print additional information\n",
    "        print(f\"\\nSample {i+1}:\")\n",
    "        print(f\"Binary Mask - Unique values: GT {np.unique(binary_mask)}, Pred {np.unique(cell_seg_out_img > 0.5)}\")\n",
    "        print(f\"Multi-class Mask - Unique values: GT {np.unique(np.argmax(multi_class_mask, axis=-1))}, Pred {np.unique(cell_class_out_argmax[binary_pred])}\")\n",
    "        \n",
    "        # Count cells of each type\n",
    "        for j in range(num_classes):\n",
    "            gt_count = np.sum(np.argmax(multi_class_mask, axis=-1) == j)\n",
    "            pred_count = np.sum((cell_class_out_argmax == j) & binary_pred)\n",
    "            print(f\"Class {j} (GT | Pred): {gt_count} | {pred_count}\")\n",
    "        \n",
    "        print(f\"Tissue Types - GT {tissue_types[0].argmax().item()}, Pred {predicted_tissue}\")\n",
    "        print(f\"Global Cell Labels - GT {global_cell_labels[0].argmax().item()}, Pred {global_cell_out[0].argmax().item()}\")\n",
    "        \n",
    "        # Print prediction confidence\n",
    "        for j in range(num_classes):\n",
    "            class_confidence = cell_class_out_img[j]\n",
    "            print(f\"Class {j} Confidence:\")\n",
    "            print(f\"  Min: {class_confidence.min():.4f}\")\n",
    "            print(f\"  Max: {class_confidence.max():.4f}\")\n",
    "            print(f\"  Mean: {class_confidence.mean():.4f}\")\n",
    "            print(f\"  Std: {class_confidence.std():.4f}\")\n",
    "\n",
    "# Usage\n",
    "visualize_results(model, test_loader, device, num_samples=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae6e253-64e5-4a3c-97c1-841e571ad358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "\n",
    "def visualize_results(model, test_loader, device, num_samples=5):\n",
    "    model.eval()\n",
    "    \n",
    "    fig, axes = plt.subplots(num_samples, 8, figsize=(40, 5*num_samples))\n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (images, binary_masks, multi_class_masks, hv_maps, tissue_types, global_cell_labels) in enumerate(test_loader):\n",
    "            if i >= num_samples:\n",
    "                break\n",
    "            \n",
    "            images = images.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            cell_seg_out, cell_class_out, tc_out, global_cell_out, hv_out = model(images)\n",
    "            \n",
    "            # Move tensors to CPU and convert to numpy for visualization\n",
    "            image = images[0].cpu().permute(1, 2, 0).numpy()\n",
    "            binary_mask = binary_masks[0, 0].cpu().numpy()\n",
    "            multi_class_mask = multi_class_masks[0].squeeze().cpu().numpy()\n",
    "            cell_seg_out_img = cell_seg_out[0, 0].cpu().numpy()\n",
    "            cell_class_out_img = cell_class_out[0].cpu().numpy()\n",
    "            hv_out_img = hv_out[0].cpu().numpy()\n",
    "            \n",
    "            # Normalize image if necessary\n",
    "            if image.max() > 1:\n",
    "                image = image / 255.0\n",
    "            \n",
    "            # Original Image\n",
    "            axes[i, 0].imshow(image)\n",
    "            axes[i, 0].set_title(f\"Sample {i+1}\\nOriginal Image\")\n",
    "            axes[i, 0].axis('off')\n",
    "            \n",
    "            # Ground Truth Binary Segmentation\n",
    "            axes[i, 1].imshow(binary_mask, cmap='gray')\n",
    "            axes[i, 1].set_title(\"GT Binary Segmentation\")\n",
    "            axes[i, 1].axis('off')\n",
    "            \n",
    "            # Predicted Binary Segmentation\n",
    "            axes[i, 2].imshow(cell_seg_out_img > 0.5, cmap='gray')\n",
    "            axes[i, 2].set_title(\"Predicted Binary Segmentation\")\n",
    "            axes[i, 2].axis('off')\n",
    "            \n",
    "            # Ground Truth Cell Classification\n",
    "            num_classes = multi_class_mask.shape[-1]\n",
    "            colors = plt.colormaps['tab10'](np.linspace(0, 1, num_classes))\n",
    "            \n",
    "            gt_cell_class_image = np.zeros((*multi_class_mask.shape[:2], 3))\n",
    "            for class_idx in range(num_classes):\n",
    "                class_mask = multi_class_mask[..., class_idx] > 0\n",
    "                color = colors[class_idx][:3]\n",
    "                gt_cell_class_image[class_mask] = color\n",
    "            \n",
    "            axes[i, 3].imshow(gt_cell_class_image)\n",
    "            axes[i, 3].set_title(\"Ground Truth\\nCell Classification\")\n",
    "            axes[i, 3].axis('off')\n",
    "            \n",
    "            # Predicted Cell Classification\n",
    "            pred_cell_class_image = np.zeros((*cell_class_out_img.shape[1:], 3))\n",
    "            cell_class_out_argmax = np.argmax(cell_class_out_img, axis=0)\n",
    "            binary_pred = cell_seg_out_img > 0.5\n",
    "\n",
    "            for class_idx in range(num_classes):\n",
    "                class_mask = (cell_class_out_argmax == class_idx) & binary_pred\n",
    "                color = colors[class_idx][:3]\n",
    "                pred_cell_class_image[class_mask] = color\n",
    "\n",
    "            pred_cell_class_image[~binary_pred] = [0, 0, 0]\n",
    "            \n",
    "            axes[i, 4].imshow(pred_cell_class_image)\n",
    "            axes[i, 4].set_title(\"Predicted\\nCell Classification\")\n",
    "            axes[i, 4].axis('off')\n",
    "            \n",
    "            # HV Map Visualization (only for detected cells)\n",
    "            hv_magnitude = np.sqrt(np.sum(hv_out_img**2, axis=0))\n",
    "            hv_magnitude_masked = hv_magnitude * binary_pred\n",
    "            axes[i, 5].imshow(hv_magnitude_masked, cmap='viridis')\n",
    "            axes[i, 5].set_title(\"HV Map Magnitude\\n(Detected Cells Only)\")\n",
    "            axes[i, 5].axis('off')\n",
    "\n",
    "            # Cell Boundaries using HV Map (only for detected cells)\n",
    "            gx = cv2.Sobel(hv_magnitude_masked, cv2.CV_32F, 1, 0, ksize=3)\n",
    "            gy = cv2.Sobel(hv_magnitude_masked, cv2.CV_32F, 0, 1, ksize=3)\n",
    "            grad_mag = np.sqrt(gx**2 + gy**2)\n",
    "            grad_mag = (grad_mag - grad_mag.min()) / (grad_mag.max() - grad_mag.min() + 1e-8)\n",
    "\n",
    "            # Threshold to get boundaries\n",
    "            threshold = 0.1  # Adjust this value to control boundary detection sensitivity\n",
    "            boundary_mask = (grad_mag > threshold).astype(np.uint8)\n",
    "\n",
    "            # Combine predicted cell classification with boundary overlay\n",
    "            combined_image = pred_cell_class_image.copy()\n",
    "            combined_image[boundary_mask > 0] = [1, 1, 1]  # Set boundary pixels to white\n",
    "\n",
    "            # Only show boundaries where cells are detected\n",
    "            combined_image[~binary_pred] = [0, 0, 0]  # Set non-cell areas to black\n",
    "\n",
    "            axes[i, 6].imshow(combined_image)\n",
    "            axes[i, 6].set_title(\"Predicted Classification\\nwith Cell Boundaries\")\n",
    "            axes[i, 6].axis('off')\n",
    "\n",
    "            # New image: Original image with colored cell boundaries overlay\n",
    "            original_with_boundaries = image.copy()\n",
    "            for class_idx in range(num_classes):\n",
    "                class_mask = (cell_class_out_argmax == class_idx) & binary_pred\n",
    "                color = colors[class_idx][:3]\n",
    "                \n",
    "                # Create a boundary mask for this class\n",
    "                class_boundary = cv2.dilate(class_mask.astype(np.uint8), np.ones((5,5), np.uint8), iterations=1) - class_mask.astype(np.uint8)\n",
    "                \n",
    "                # Apply colored boundary to the original image\n",
    "                original_with_boundaries[class_boundary > 0] = color\n",
    "\n",
    "            axes[i, 7].imshow(original_with_boundaries)\n",
    "            axes[i, 7].set_title(\"Original Image with\\nColored Cell Boundaries\")\n",
    "            axes[i, 7].axis('off')\n",
    "\n",
    "            # Tissue Type prediction\n",
    "            predicted_tissue = tc_out[0].argmax().item()\n",
    "            axes[i, 7].text(0.5, -0.1, f\"Predicted Tissue Type: {predicted_tissue}\", \n",
    "                            horizontalalignment='center', verticalalignment='center',\n",
    "                            fontsize=10, fontweight='bold', transform=axes[i, 7].transAxes)\n",
    "\n",
    "    \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Usage\n",
    "visualize_results(model, test_loader, device, num_samples=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a1daae-bfca-4c09-84ae-2ef649e18329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "\n",
    "def visualize_results(model, test_loader, device, num_samples=5):\n",
    "    model.eval()\n",
    "    \n",
    "    fig, axes = plt.subplots(num_samples, 8, figsize=(40, 5*num_samples))\n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (images, binary_masks, multi_class_masks, hv_maps, tissue_types, global_cell_labels) in enumerate(test_loader):\n",
    "            if i >= num_samples:\n",
    "                break\n",
    "            \n",
    "            images = images.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            cell_seg_out, cell_class_out, tc_out, global_cell_out, hv_out = model(images)\n",
    "            \n",
    "            # Move tensors to CPU and convert to numpy for visualization\n",
    "            image = images[0].cpu().permute(1, 2, 0).numpy()\n",
    "            binary_mask = binary_masks[0, 0].cpu().numpy()\n",
    "            multi_class_mask = multi_class_masks[0].squeeze().cpu().numpy()\n",
    "            cell_seg_out_img = cell_seg_out[0, 0].cpu().numpy()\n",
    "            cell_class_out_img = cell_class_out[0].cpu().numpy()\n",
    "            hv_out_img = hv_out[0].cpu().numpy()\n",
    "            \n",
    "            # Normalize image if necessary\n",
    "            if image.max() > 1:\n",
    "                image = image / 255.0\n",
    "            \n",
    "            # Original Image\n",
    "            axes[i, 0].imshow(image)\n",
    "            axes[i, 0].set_title(f\"Sample {i+1}\\nOriginal Image\")\n",
    "            axes[i, 0].axis('off')\n",
    "            \n",
    "            # Ground Truth Binary Segmentation\n",
    "            axes[i, 1].imshow(binary_mask, cmap='gray')\n",
    "            axes[i, 1].set_title(\"GT Binary Segmentation\")\n",
    "            axes[i, 1].axis('off')\n",
    "            \n",
    "            # Predicted Binary Segmentation\n",
    "            axes[i, 2].imshow(cell_seg_out_img > 0.5, cmap='gray')\n",
    "            axes[i, 2].set_title(\"Predicted Binary Segmentation\")\n",
    "            axes[i, 2].axis('off')\n",
    "            \n",
    "            # Ground Truth Cell Classification\n",
    "            num_classes = multi_class_mask.shape[-1]\n",
    "            colors = plt.colormaps['tab10'](np.linspace(0, 1, num_classes))\n",
    "            \n",
    "            gt_cell_class_image = np.zeros((*multi_class_mask.shape[:2], 3))\n",
    "            for class_idx in range(num_classes):\n",
    "                class_mask = multi_class_mask[..., class_idx] > 0\n",
    "                color = colors[class_idx][:3]\n",
    "                gt_cell_class_image[class_mask] = color\n",
    "            \n",
    "            axes[i, 3].imshow(gt_cell_class_image)\n",
    "            axes[i, 3].set_title(\"Ground Truth\\nCell Classification\")\n",
    "            axes[i, 3].axis('off')\n",
    "            \n",
    "            # Predicted Cell Classification\n",
    "            pred_cell_class_image = np.zeros((*cell_class_out_img.shape[1:], 3))\n",
    "            cell_class_out_argmax = np.argmax(cell_class_out_img, axis=0)\n",
    "            binary_pred = cell_seg_out_img > 0.5\n",
    "\n",
    "            for class_idx in range(num_classes):\n",
    "                class_mask = (cell_class_out_argmax == class_idx) & binary_pred\n",
    "                color = colors[class_idx][:3]\n",
    "                pred_cell_class_image[class_mask] = color\n",
    "\n",
    "            pred_cell_class_image[~binary_pred] = [0, 0, 0]\n",
    "            \n",
    "            axes[i, 4].imshow(pred_cell_class_image)\n",
    "            axes[i, 4].set_title(\"Predicted\\nCell Classification\")\n",
    "            axes[i, 4].axis('off')\n",
    "            \n",
    "            # HV Map Visualization (only for detected cells)\n",
    "            hv_magnitude = np.sqrt(np.sum(hv_out_img**2, axis=0))\n",
    "            hv_magnitude_masked = hv_magnitude * binary_pred\n",
    "            axes[i, 5].imshow(hv_magnitude_masked, cmap='viridis')\n",
    "            axes[i, 5].set_title(\"HV Map Magnitude\\n(Detected Cells Only)\")\n",
    "            axes[i, 5].axis('off')\n",
    "\n",
    "            # Cell Boundaries using HV Map (only for detected cells)\n",
    "            gx = cv2.Sobel(hv_magnitude_masked, cv2.CV_32F, 1, 0, ksize=3)\n",
    "            gy = cv2.Sobel(hv_magnitude_masked, cv2.CV_32F, 0, 1, ksize=3)\n",
    "            grad_mag = np.sqrt(gx**2 + gy**2)\n",
    "            grad_mag = (grad_mag - grad_mag.min()) / (grad_mag.max() - grad_mag.min() + 1e-8)\n",
    "\n",
    "            # Threshold to get boundaries\n",
    "            threshold = 0.1  # Adjust this value to control boundary detection sensitivity\n",
    "            boundary_mask = (grad_mag > threshold).astype(np.uint8)\n",
    "\n",
    "            # Combine predicted cell classification with boundary overlay\n",
    "            combined_image = pred_cell_class_image.copy()\n",
    "            combined_image[boundary_mask > 0] = [1, 1, 1]  # Set boundary pixels to white\n",
    "\n",
    "            # Only show boundaries where cells are detected\n",
    "            combined_image[~binary_pred] = [0, 0, 0]  # Set non-cell areas to black\n",
    "\n",
    "            axes[i, 6].imshow(combined_image)\n",
    "            axes[i, 6].set_title(\"Predicted Classification\\nwith Cell Boundaries\")\n",
    "            axes[i, 6].axis('off')\n",
    "\n",
    "            # New image: Original image with colored cell boundaries overlay\n",
    "            original_with_boundaries = image.copy()\n",
    "            for class_idx in range(num_classes):\n",
    "                class_mask = (cell_class_out_argmax == class_idx) & binary_pred\n",
    "                color = colors[class_idx][:3]\n",
    "                \n",
    "                # Create a boundary mask for this class\n",
    "                class_boundary = cv2.dilate(class_mask.astype(np.uint8), np.ones((5,5), np.uint8), iterations=1) - class_mask.astype(np.uint8)\n",
    "                \n",
    "                # Apply colored boundary to the original image\n",
    "                original_with_boundaries[class_boundary > 0] = color\n",
    "\n",
    "            axes[i, 7].imshow(original_with_boundaries)\n",
    "            axes[i, 7].set_title(\"Original Image with\\nColored Cell Boundaries\")\n",
    "            axes[i, 7].axis('off')\n",
    "\n",
    "            # Tissue Type prediction\n",
    "            predicted_tissue = tc_out[0].argmax().item()\n",
    "            axes[i, 7].text(0.5, -0.1, f\"Predicted Tissue Type: {predicted_tissue}\", \n",
    "                            horizontalalignment='center', verticalalignment='center',\n",
    "                            fontsize=10, fontweight='bold', transform=axes[i, 7].transAxes)\n",
    "\n",
    "    \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Usage\n",
    "visualize_results(model, test_loader, device, num_samples=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e34313-9405-412c-a419-88459a3986c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "\n",
    "def visualize_results(model, test_loader, device, num_samples=5):\n",
    "    model.eval()\n",
    "    \n",
    "    fig, axes = plt.subplots(num_samples, 8, figsize=(40, 5*num_samples))\n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (images, binary_masks, multi_class_masks, hv_maps, tissue_types, global_cell_labels) in enumerate(test_loader):\n",
    "            if i >= num_samples:\n",
    "                break\n",
    "            \n",
    "            images = images.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            cell_seg_out, cell_class_out, tc_out, global_cell_out, hv_out = model(images)\n",
    "            \n",
    "            # Move tensors to CPU and convert to numpy for visualization\n",
    "            image = images[0].cpu().permute(1, 2, 0).numpy()\n",
    "            binary_mask = binary_masks[0, 0].cpu().numpy()\n",
    "            multi_class_mask = multi_class_masks[0].squeeze().cpu().numpy()\n",
    "            cell_seg_out_img = cell_seg_out[0, 0].cpu().numpy()\n",
    "            cell_class_out_img = cell_class_out[0].cpu().numpy()\n",
    "            hv_out_img = hv_out[0].cpu().numpy()\n",
    "            \n",
    "            # Normalize image if necessary\n",
    "            if image.max() > 1:\n",
    "                image = image / 255.0\n",
    "            \n",
    "            # Original Image\n",
    "            axes[i, 0].imshow(image)\n",
    "            axes[i, 0].set_title(f\"Sample {i+1}\\nOriginal Image\")\n",
    "            axes[i, 0].axis('off')\n",
    "            \n",
    "            # Ground Truth Binary Segmentation\n",
    "            axes[i, 1].imshow(binary_mask, cmap='gray')\n",
    "            axes[i, 1].set_title(\"GT Binary Segmentation\")\n",
    "            axes[i, 1].axis('off')\n",
    "            \n",
    "            # Predicted Binary Segmentation\n",
    "            axes[i, 2].imshow(cell_seg_out_img > 0.5, cmap='gray')\n",
    "            axes[i, 2].set_title(\"Predicted Binary Segmentation\")\n",
    "            axes[i, 2].axis('off')\n",
    "            \n",
    "            # Ground Truth Cell Classification\n",
    "\n",
    "\n",
    "            # New image: Original image with colored cell boundaries overlay\n",
    "            original_with_boundaries = image.copy()\n",
    "            for class_idx in range(num_classes):\n",
    "                class_mask = (cell_class_out_argmax == class_idx) & binary_pred\n",
    "                color = colors[class_idx][:3]\n",
    "                \n",
    "                # Create a boundary mask for this class\n",
    "                class_boundary = cv2.dilate(class_mask.astype(np.uint8), np.ones((5,5), np.uint8), iterations=1) - class_mask.astype(np.uint8)\n",
    "                \n",
    "                # Apply colored boundary to the original image\n",
    "                original_with_boundaries[class_boundary > 0] = color\n",
    "\n",
    "            axes[i, 7].imshow(original_with_boundaries)\n",
    "            axes[i, 7].set_title(\"Original Image with\\nColored Cell Boundaries\")\n",
    "            axes[i, 7].axis('off')\n",
    "\n",
    "            # Tissue Type prediction\n",
    "            predicted_tissue = tc_out[0].argmax().item()\n",
    "            axes[i, 7].text(0.5, -0.1, f\"Predicted Tissue Type: {predicted_tissue}\", \n",
    "                            horizontalalignment='center', verticalalignment='center',\n",
    "                            fontsize=10, fontweight='bold', transform=axes[i, 7].transAxes)\n",
    "\n",
    "    \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Usage\n",
    "visualize_results(model, test_loader, device, num_samples=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c56cbe1-c4f3-4267-9d5f-937241b4c815",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea83dfd-7f33-43a6-a5b3-b8a3a628aecf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from skimage import measure\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
    "\n",
    "def pair_coordinates(true_centroids, pred_centroids, pairing_radius):\n",
    "    if len(true_centroids) == 0 or len(pred_centroids) == 0:\n",
    "        return np.array([]), np.arange(len(true_centroids)), np.arange(len(pred_centroids))\n",
    "    \n",
    "    true_centroids = true_centroids[:, :2]\n",
    "    pred_centroids = pred_centroids[:, :2]\n",
    "    \n",
    "    distances = np.linalg.norm(true_centroids[:, None] - pred_centroids[None, :], axis=-1)\n",
    "    true_indices, pred_indices = linear_sum_assignment(distances)\n",
    "    \n",
    "    paired = []\n",
    "    unpaired_true = []\n",
    "    unpaired_pred = []\n",
    "    \n",
    "    for true_idx, pred_idx in zip(true_indices, pred_indices):\n",
    "        if distances[true_idx, pred_idx] <= pairing_radius:\n",
    "            paired.append((true_idx, pred_idx))\n",
    "        else:\n",
    "            unpaired_true.append(true_idx)\n",
    "            unpaired_pred.append(pred_idx)\n",
    "    \n",
    "    return np.array(paired), np.array(unpaired_true), np.array(unpaired_pred)\n",
    "\n",
    "def calculate_instance_map(binary_mask):\n",
    "    return measure.label(binary_mask)\n",
    "\n",
    "def get_centroids(instance_map):\n",
    "    props = measure.regionprops(instance_map)\n",
    "    centroids = np.array([prop.centroid for prop in props])\n",
    "    if centroids.size == 0:\n",
    "        return np.empty((0, 2))\n",
    "    elif centroids.ndim == 1:\n",
    "        return centroids.reshape(1, -1)\n",
    "    else:\n",
    "        return centroids[:, :2]\n",
    "\n",
    "def cell_detection_scores(paired_true, paired_pred, unpaired_true, unpaired_pred):\n",
    "    tp = len(paired_true)\n",
    "    fp = len(unpaired_pred)\n",
    "    fn = len(unpaired_true)\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return f1, precision, recall\n",
    "\n",
    "def calculate_metrics_across_all_test_sets(model, test_loader, device, pairing_radius=12):\n",
    "    model.eval()\n",
    "    \n",
    "    paired_all_global = []\n",
    "    unpaired_true_all_global = []\n",
    "    unpaired_pred_all_global = []\n",
    "    \n",
    "    all_true_cell_classes = []\n",
    "    all_pred_cell_classes = []\n",
    "    all_true_tissue_types = []\n",
    "    all_pred_tissue_types = []\n",
    "    all_true_global_cell_labels = []\n",
    "    all_pred_global_cell_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            images, binary_masks, multi_class_masks, hv_maps, tissue_types, global_cell_labels = batch\n",
    "            images = images.to(device)\n",
    "            binary_masks = binary_masks.to(device)\n",
    "            multi_class_masks = multi_class_masks.to(device)\n",
    "            tissue_types = tissue_types.to(device)\n",
    "            global_cell_labels = global_cell_labels.to(device)\n",
    "            \n",
    "            cell_seg_out, cell_class_out, tc_out, global_cell_out, hv_out = model(images)\n",
    "            \n",
    "            # Process segmentation\n",
    "            pred_masks = (torch.sigmoid(cell_seg_out) > 0.5).float()\n",
    "            \n",
    "            for true_mask, pred_mask in zip(binary_masks.cpu().numpy(), pred_masks.cpu().numpy()):\n",
    "                true_instance_map = calculate_instance_map(true_mask)\n",
    "                pred_instance_map = calculate_instance_map(pred_mask)\n",
    "                \n",
    "                true_centroids = get_centroids(true_instance_map)\n",
    "                pred_centroids = get_centroids(pred_instance_map)\n",
    "                \n",
    "                paired, unpaired_true, unpaired_pred = pair_coordinates(true_centroids, pred_centroids, pairing_radius)\n",
    "                \n",
    "                paired_all_global.extend(paired.flatten())\n",
    "                unpaired_true_all_global.extend(unpaired_true.flatten())\n",
    "                unpaired_pred_all_global.extend(unpaired_pred.flatten())\n",
    "            \n",
    "            # Process cell classification\n",
    "            true_cell_classes = multi_class_masks.squeeze(1).argmax(dim=-1).cpu().numpy()\n",
    "            pred_cell_classes = cell_class_out.argmax(dim=1).cpu().numpy()\n",
    "            all_true_cell_classes.append(true_cell_classes)\n",
    "            all_pred_cell_classes.append(pred_cell_classes)\n",
    "            \n",
    "            # Process tissue classification\n",
    "            true_tissue_types = tissue_types.argmax(dim=1).cpu().numpy()\n",
    "            pred_tissue_types = tc_out.argmax(dim=1).cpu().numpy()\n",
    "            all_true_tissue_types.extend(true_tissue_types)\n",
    "            all_pred_tissue_types.extend(pred_tissue_types)\n",
    "            \n",
    "            # Process global cell classification\n",
    "            true_global_cell_labels = global_cell_labels.cpu().numpy()\n",
    "            pred_global_cell_labels = (torch.sigmoid(global_cell_out) > 0.5).float().cpu().numpy()\n",
    "            all_true_global_cell_labels.extend(true_global_cell_labels)\n",
    "            all_pred_global_cell_labels.extend(pred_global_cell_labels)\n",
    "\n",
    "    # Concatenate all cell classification results\n",
    "    all_true_cell_classes = np.concatenate(all_true_cell_classes)\n",
    "    all_pred_cell_classes = np.concatenate(all_pred_cell_classes)\n",
    "\n",
    "    # Calculate segmentation metrics\n",
    "    paired_all = np.array(paired_all_global).reshape(-1, 2)\n",
    "    unpaired_true_all = np.array(unpaired_true_all_global)\n",
    "    unpaired_pred_all = np.array(unpaired_pred_all_global)\n",
    "    \n",
    "    seg_f1, seg_precision, seg_recall = cell_detection_scores(\n",
    "        paired_true=paired_all[:, 0],\n",
    "        paired_pred=paired_all[:, 1],\n",
    "        unpaired_true=unpaired_true_all,\n",
    "        unpaired_pred=unpaired_pred_all\n",
    "    )\n",
    "    \n",
    "    # Calculate cell classification metrics\n",
    "    cell_f1, cell_precision, cell_recall, _ = precision_recall_fscore_support(\n",
    "        all_true_cell_classes.flatten(), all_pred_cell_classes.flatten(), average='weighted'\n",
    "    )\n",
    "    \n",
    "    # Calculate per-class cell classification metrics\n",
    "    cell_class_metrics = precision_recall_fscore_support(\n",
    "        all_true_cell_classes.flatten(), all_pred_cell_classes.flatten(), average=None\n",
    "    )\n",
    "    \n",
    "    # Calculate tissue classification metrics\n",
    "    tissue_f1, tissue_precision, tissue_recall, _ = precision_recall_fscore_support(\n",
    "        all_true_tissue_types, all_pred_tissue_types, average='weighted'\n",
    "    )\n",
    "    \n",
    "    # Calculate global cell classification metrics\n",
    "    global_cell_f1, global_cell_precision, global_cell_recall, _ = precision_recall_fscore_support(\n",
    "        all_true_global_cell_labels, all_pred_global_cell_labels, average='weighted'\n",
    "    )\n",
    "    \n",
    "    print(\"Metrics across all test sets:\")\n",
    "    print(f\"Segmentation - F1: {seg_f1:.4f}, Precision: {seg_precision:.4f}, Recall: {seg_recall:.4f}\")\n",
    "    print(f\"Cell Classification - F1: {cell_f1:.4f}, Precision: {cell_precision:.4f}, Recall: {cell_recall:.4f}\")\n",
    "    print(f\"Tissue Classification - F1: {tissue_f1:.4f}, Precision: {tissue_precision:.4f}, Recall: {tissue_recall:.4f}\")\n",
    "    print(f\"Global Cell Classification - F1: {global_cell_f1:.4f}, Precision: {global_cell_precision:.4f}, Recall: {global_cell_recall:.4f}\")\n",
    "    \n",
    "    print(\"\\nPer-class Cell Classification Metrics:\")\n",
    "    for i, (f1, precision, recall, _) in enumerate(zip(*cell_class_metrics)):\n",
    "        print(f\"Class {i} - F1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'segmentation': {'f1': seg_f1, 'precision': seg_precision, 'recall': seg_recall},\n",
    "        'cell_classification': {'f1': cell_f1, 'precision': cell_precision, 'recall': cell_recall},\n",
    "        'tissue_classification': {'f1': tissue_f1, 'precision': tissue_precision, 'recall': tissue_recall},\n",
    "        'global_cell_classification': {'f1': global_cell_f1, 'precision': global_cell_precision, 'recall': global_cell_recall},\n",
    "        'per_class_cell_metrics': cell_class_metrics\n",
    "    }\n",
    "\n",
    "# Usage\n",
    "model = ModifiedCellSwin(num_cell_classes=5, num_tissue_classes=19).to(device)\n",
    "model.load_state_dict(torch.load(\"improved_cellswin_model.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "metrics = calculate_metrics_across_all_test_sets(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dc2f4d-6413-445b-9bf9-b0e96b369589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results(model, test_loader, device, num_samples=5):\n",
    "    model.eval()\n",
    "    \n",
    "    fig, axes = plt.subplots(num_samples, 8, figsize=(40, 5*num_samples))\n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (images, binary_masks, multi_class_masks, hv_maps, tissue_types, global_cell_labels) in enumerate(test_loader):\n",
    "            if i >= num_samples:\n",
    "                break\n",
    "            \n",
    "            images = images.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            cell_seg_out, cell_class_out, tc_out, global_cell_out, hv_out = model(images)\n",
    "            \n",
    "            # Move tensors to CPU and convert to numpy for visualization\n",
    "            image = images[0].cpu().permute(1, 2, 0).numpy()\n",
    "            binary_mask = binary_masks[0, 0].cpu().numpy()\n",
    "            multi_class_mask = multi_class_masks[0].squeeze().cpu().numpy()\n",
    "            cell_seg_out_img = cell_seg_out[0, 0].cpu().numpy()\n",
    "            cell_class_out_img = cell_class_out[0].cpu().numpy()\n",
    "            hv_out_img = hv_out[0].cpu().numpy()\n",
    "            \n",
    "            # Normalize image if necessary\n",
    "            if image.max() > 1:\n",
    "                image = image / 255.0\n",
    "            \n",
    "            # Original Image\n",
    "            axes[i, 0].imshow(image)\n",
    "            axes[i, 0].set_title(f\"Sample {i+1}\\nOriginal Image\")\n",
    "            axes[i, 0].axis('off')\n",
    "            \n",
    "            # Ground Truth Binary Segmentation\n",
    "            axes[i, 1].imshow(binary_mask, cmap='gray')\n",
    "            axes[i, 1].set_title(\"GT Binary Segmentation\")\n",
    "            axes[i, 1].axis('off')\n",
    "            \n",
    "            # Predicted Binary Segmentation\n",
    "            axes[i, 2].imshow(cell_seg_out_img > 0.5, cmap='gray')\n",
    "            axes[i, 2].set_title(\"Predicted Binary Segmentation\")\n",
    "            axes[i, 2].axis('off')\n",
    "            \n",
    "            # Ground Truth Cell Classification\n",
    "            num_classes = multi_class_mask.shape[-1]\n",
    "            colors = plt.colormaps['tab10'](np.linspace(0, 1, num_classes))\n",
    "            \n",
    "            gt_cell_class_image = np.zeros((*multi_class_mask.shape[:2], 3))\n",
    "            for class_idx in range(num_classes):\n",
    "                class_mask = multi_class_mask[..., class_idx] > 0\n",
    "                color = colors[class_idx][:3]\n",
    "                gt_cell_class_image[class_mask] = color\n",
    "            \n",
    "            axes[i, 3].imshow(gt_cell_class_image)\n",
    "            axes[i, 3].set_title(\"Ground Truth\\nCell Classification\")\n",
    "            axes[i, 3].axis('off')\n",
    "            \n",
    "            # Predicted Cell Classification\n",
    "            pred_cell_class_image = np.zeros((*cell_class_out_img.shape[1:], 3))\n",
    "            cell_class_out_argmax = np.argmax(cell_class_out_img, axis=0)\n",
    "            binary_pred = cell_seg_out_img > 0.5\n",
    "\n",
    "            for class_idx in range(num_classes):\n",
    "                class_mask = (cell_class_out_argmax == class_idx) & binary_pred\n",
    "                color = colors[class_idx][:3]\n",
    "                pred_cell_class_image[class_mask] = color\n",
    "\n",
    "            pred_cell_class_image[~binary_pred] = [0, 0, 0]\n",
    "            \n",
    "            axes[i, 4].imshow(pred_cell_class_image)\n",
    "            axes[i, 4].set_title(\"Predicted\\nCell Classification\")\n",
    "            axes[i, 4].axis('off')\n",
    "            \n",
    "            # HV Map Visualization (only for detected cells)\n",
    "            hv_magnitude = np.sqrt(np.sum(hv_out_img**2, axis=0))\n",
    "            hv_magnitude_masked = hv_magnitude * binary_pred\n",
    "            axes[i, 5].imshow(hv_magnitude_masked, cmap='viridis')\n",
    "            axes[i, 5].set_title(\"HV Map Magnitude\\n(Detected Cells Only)\")\n",
    "            axes[i, 5].axis('off')\n",
    "\n",
    "            # Predicted Instance Segmentation\n",
    "            cell_prob = torch.sigmoid(cell_seg_out[0])\n",
    "            segmentation = postprocess_hv(hv_out[0], cell_prob)\n",
    "            \n",
    "            # Create a colormap for instance segmentation\n",
    "            n_instances = len(np.unique(segmentation)) - 1  # Subtract 1 to exclude background\n",
    "            instance_cmap = plt.cm.get_cmap('tab20')  # You can change this to any colormap you prefer\n",
    "            instance_colors = instance_cmap(np.linspace(0, 1, n_instances))\n",
    "            \n",
    "            # Create instance segmentation image\n",
    "            instance_seg_image = np.zeros((*segmentation.shape, 3))\n",
    "            for idx, label in enumerate(np.unique(segmentation)):\n",
    "                if label == 0:  # background\n",
    "                    continue\n",
    "                instance_seg_image[segmentation == label] = instance_colors[idx-1, :3]\n",
    "            \n",
    "            axes[i, 6].imshow(instance_seg_image)\n",
    "            axes[i, 6].set_title(\"Predicted Instance\\nSegmentation\")\n",
    "            axes[i, 6].axis('off')\n",
    "\n",
    "            # Original image with instance segmentation overlay\n",
    "            overlay_image = image.copy()\n",
    "            for label in np.unique(segmentation):\n",
    "                if label == 0:  # background\n",
    "                    continue\n",
    "                mask = segmentation == label\n",
    "                boundary = cv2.dilate(mask.astype(np.uint8), np.ones((3,3), np.uint8), iterations=1) - mask.astype(np.uint8)\n",
    "                overlay_image[boundary > 0] = instance_colors[label-1, :3]\n",
    "\n",
    "            axes[i, 7].imshow(overlay_image)\n",
    "            axes[i, 7].set_title(\"Original Image with\\nInstance Segmentation\")\n",
    "            axes[i, 7].axis('off')\n",
    "\n",
    "            # Tissue Type prediction\n",
    "            predicted_tissue = tc_out[0].argmax().item()\n",
    "            axes[i, 7].text(0.5, -0.1, f\"Predicted Tissue Type: {predicted_tissue}\", \n",
    "                            horizontalalignment='center', verticalalignment='center',\n",
    "                            fontsize=10, fontweight='bold', transform=axes[i, 7].transAxes)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Usage\n",
    "visualize_results(model, test_loader, device, num_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67dff54-c48a-4e08-b461-12462f6d7489",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from scipy import ndimage as ndi\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def postprocess_hv(hv_map, cell_prob, prob_thresh=0.5, hv_thresh=0.2, min_distance=3):\n",
    "\n",
    "    hv_map = hv_map.cpu().numpy()\n",
    "    cell_prob = cell_prob.cpu().numpy()\n",
    "\n",
    "    grad_h = np.abs(hv_map[0, 1:, :] - hv_map[0, :-1, :])\n",
    "    grad_v = np.abs(hv_map[1, :, 1:] - hv_map[1, :, :-1])\n",
    "\n",
    "    grad_h = np.pad(grad_h, ((1, 0), (0, 0)), mode='constant')\n",
    "    grad_v = np.pad(grad_v, ((0, 0), (1, 0)), mode='constant')\n",
    "\n",
    "    grad_combined = np.maximum(grad_h, grad_v)\n",
    "\n",
    "    cell_mask = cell_prob > prob_thresh\n",
    "    grad_mask = grad_combined > hv_thresh\n",
    "\n",
    "    mask = cell_mask & (~grad_mask)\n",
    "\n",
    "\n",
    "    # Adjust peak detection parameters\n",
    "    peaks = peak_local_max(cell_prob, min_distance=min_distance, \n",
    "                           threshold_abs=prob_thresh * 0.5,  # Lower the threshold\n",
    "                           exclude_border=False, labels=mask)\n",
    "\n",
    "\n",
    "    if len(peaks) == 0:\n",
    "        return np.zeros_like(cell_prob, dtype=np.int32).squeeze()\n",
    "\n",
    "    markers = np.zeros_like(cell_prob, dtype=np.int32)\n",
    "    markers[tuple(peaks.T)] = np.arange(1, len(peaks) + 1)\n",
    "\n",
    "    segmentation = watershed(-cell_prob, markers, mask=mask)\n",
    "\n",
    "\n",
    "    return segmentation.squeeze()\n",
    "\n",
    "def predict_and_postprocess(model, image):\n",
    "    with torch.no_grad():\n",
    "        cell_seg_out, cell_class_out, tc_out, global_cell_out, hv_out = model(image.unsqueeze(0))\n",
    "    \n",
    "    cell_prob = torch.sigmoid(cell_seg_out)\n",
    "    \n",
    "\n",
    "    \n",
    "    segmentation = postprocess_hv(hv_out[0], cell_prob[0])\n",
    "    \n",
    "    return segmentation, cell_class_out.squeeze(0), tc_out.squeeze(0), global_cell_out.squeeze(0)\n",
    "\n",
    "\n",
    "def calculate_metrics(pred_mask, true_mask):\n",
    "    pred_flat = pred_mask.flatten()\n",
    "    true_flat = true_mask.flatten()\n",
    "    \n",
    "    # Calculate F1 score, precision, and recall\n",
    "    f1 = f1_score(true_flat, pred_flat, average='weighted', zero_division=1)\n",
    "    precision = precision_score(true_flat, pred_flat, average='weighted', zero_division=1)\n",
    "    recall = recall_score(true_flat, pred_flat, average='weighted', zero_division=1)\n",
    "    \n",
    "    return f1, precision, recall\n",
    "\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    total_f1, total_precision, total_recall = 0, 0, 0\n",
    "    num_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            images, binary_masks, _, _, _, _ = batch\n",
    "            images = images.to(device)\n",
    "            \n",
    "            for i in range(images.size(0)):\n",
    "                segmentation, _, _, _ = predict_and_postprocess(model, images[i])\n",
    "                \n",
    "                # Assuming binary_masks contains the ground truth segmentation\n",
    "                true_mask = binary_masks[i].squeeze().cpu().numpy()\n",
    "                \n",
    "                f1, precision, recall = calculate_metrics(segmentation, true_mask)\n",
    "                \n",
    "                total_f1 += f1\n",
    "                total_precision += precision\n",
    "                total_recall += recall\n",
    "                num_samples += 1\n",
    "\n",
    "    avg_f1 = total_f1 / num_samples\n",
    "    avg_precision = total_precision / num_samples\n",
    "    avg_recall = total_recall / num_samples\n",
    "    \n",
    "    return avg_f1, avg_precision, avg_recall\n",
    "\n",
    "def visualize_results(image, true_mask, pred_mask, save_path=None):\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    ax1.imshow(image.permute(1, 2, 0).cpu().numpy())\n",
    "    ax1.set_title('Original Image')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    ax2.imshow(true_mask, cmap='nipy_spectral')\n",
    "    ax2.set_title('True Mask')\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    # Convert pred_mask to int32 if it's not already\n",
    "    pred_mask = pred_mask.astype(np.int32) if pred_mask.dtype != np.int32 else pred_mask\n",
    "    ax3.imshow(pred_mask, cmap='nipy_spectral')\n",
    "    ax3.set_title('Predicted Mask')\n",
    "    ax3.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "    else:\n",
    "        plt.show()\n",
    "    \n",
    "    plt.close(fig)  # Close the figure to free up memory\n",
    "\n",
    "# Setup and main execution\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize the model\n",
    "model = ModifiedCellSwin(num_cell_classes=5, num_tissue_classes=19).to(device)\n",
    "\n",
    "# Load the saved state dict\n",
    "model.load_state_dict(torch.load(\"improved_cellswin_model.pth\", map_location=device))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# Assuming you have a test_loader defined\n",
    "# test_loader = ...\n",
    "\n",
    "# Run evaluation\n",
    "avg_f1, avg_precision, avg_recall = evaluate_model(model, test_loader, device)\n",
    "\n",
    "print(f\"Average F1 Score: {avg_f1:.4f}\")\n",
    "print(f\"Average Precision: {avg_precision:.4f}\")\n",
    "print(f\"Average Recall: {avg_recall:.4f}\")\n",
    "\n",
    "# Visualize some results (optional)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6315c20-557b-4133-a841-be9e67d4e549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports and Setup\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Cell 2: Define helper functions\n",
    "def calculate_class_metrics(predictions, ground_truth, num_classes):\n",
    "    pred_reshaped = predictions.permute(0, 2, 3, 1).reshape(-1, num_classes)\n",
    "    pred_labels = torch.argmax(pred_reshaped, dim=1).cpu().numpy()\n",
    "    \n",
    "    true_reshaped = ground_truth.squeeze(1).reshape(-1, num_classes)\n",
    "    true_labels = torch.argmax(true_reshaped, dim=1).cpu().numpy()\n",
    "    \n",
    "    metrics = {}\n",
    "    for class_idx in range(num_classes):\n",
    "        metrics[f'class_{class_idx}'] = {\n",
    "            'accuracy': accuracy_score(true_labels == class_idx, pred_labels == class_idx),\n",
    "            'precision': precision_score(true_labels == class_idx, pred_labels == class_idx, zero_division=0),\n",
    "            'recall': recall_score(true_labels == class_idx, pred_labels == class_idx, zero_division=0),\n",
    "            'f1_score': f1_score(true_labels == class_idx, pred_labels == class_idx, zero_division=0)\n",
    "        }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def analyze_class_distribution(predictions, ground_truth, num_classes):\n",
    "    pred_reshaped = predictions.permute(0, 2, 3, 1).reshape(-1, num_classes)\n",
    "    pred_labels = torch.argmax(pred_reshaped, dim=1).cpu().numpy()\n",
    "    \n",
    "    true_reshaped = ground_truth.squeeze(1).reshape(-1, num_classes)\n",
    "    true_labels = torch.argmax(true_reshaped, dim=1).cpu().numpy()\n",
    "    \n",
    "    gt_distribution = {}\n",
    "    pred_distribution = {}\n",
    "    \n",
    "    for class_idx in range(num_classes):\n",
    "        gt_count = np.sum(true_labels == class_idx)\n",
    "        pred_count = np.sum(pred_labels == class_idx)\n",
    "        \n",
    "        gt_distribution[f'class_{class_idx}'] = gt_count\n",
    "        pred_distribution[f'class_{class_idx}'] = pred_count\n",
    "    \n",
    "    return gt_distribution, pred_distribution\n",
    "\n",
    "def plot_class_metrics(metrics):\n",
    "    class_names = list(metrics.keys())\n",
    "    accuracies = [m['accuracy'] for m in metrics.values()]\n",
    "    precisions = [m['precision'] for m in metrics.values()]\n",
    "    recalls = [m['recall'] for m in metrics.values()]\n",
    "    f1_scores = [m['f1_score'] for m in metrics.values()]\n",
    "\n",
    "    x = np.arange(len(class_names))\n",
    "    width = 0.2\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax.bar(x - 1.5*width, accuracies, width, label='Accuracy')\n",
    "    ax.bar(x - 0.5*width, precisions, width, label='Precision')\n",
    "    ax.bar(x + 0.5*width, recalls, width, label='Recall')\n",
    "    ax.bar(x + 1.5*width, f1_scores, width, label='F1-score')\n",
    "\n",
    "    ax.set_ylabel('Scores')\n",
    "    ax.set_title('Class-wise Metrics')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(class_names)\n",
    "    ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_class_distribution(gt_distribution, pred_distribution):\n",
    "    class_names = list(gt_distribution.keys())\n",
    "    gt_counts = list(gt_distribution.values())\n",
    "    pred_counts = list(pred_distribution.values())\n",
    "\n",
    "    x = np.arange(len(class_names))\n",
    "    width = 0.35\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax.bar(x - width/2, gt_counts, width, label='Ground Truth')\n",
    "    ax.bar(x + width/2, pred_counts, width, label='Predicted')\n",
    "\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title('Class Distribution: Ground Truth vs Predicted')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(class_names)\n",
    "    ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Cell 3: Model and Data Setup\n",
    "# Assuming your model is already defined and loaded\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Assuming test_loader is already defined\n",
    "num_classes = 5  # Adjust if necessary\n",
    "\n",
    "# Cell 4: Collect predictions\n",
    "all_predictions = []\n",
    "all_ground_truths = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (images, binary_masks, cell_classes, tissue_classes, global_cell_count, _) in enumerate(test_loader):\n",
    "        if i >= 3:  # Process only 3 samples\n",
    "            break\n",
    "        \n",
    "        images = images.to(device)\n",
    "        cell_classes = cell_classes.to(device)\n",
    "        \n",
    "        model_output = model(images)\n",
    "        class_predictions = model_output[1]  # Assuming class predictions are the second output\n",
    "        \n",
    "        all_predictions.append(class_predictions)\n",
    "        all_ground_truths.append(cell_classes)\n",
    "        \n",
    "        print(f\"Processed sample {i+1}\")\n",
    "        print(f\"Class predictions shape: {class_predictions.shape}\")\n",
    "        print(f\"Ground truth shape: {cell_classes.shape}\")\n",
    "\n",
    "# Cell 5: Calculate metrics and analyze class distribution\n",
    "predictions = torch.cat(all_predictions, dim=0)\n",
    "ground_truth = torch.cat(all_ground_truths, dim=0)\n",
    "\n",
    "metrics = calculate_class_metrics(predictions, ground_truth, num_classes)\n",
    "gt_distribution, pred_distribution = analyze_class_distribution(predictions, ground_truth, num_classes)\n",
    "\n",
    "print(\"\\nGround Truth Class Distribution:\")\n",
    "for class_idx, count in gt_distribution.items():\n",
    "    print(f\"{class_idx}: {count}\")\n",
    "\n",
    "print(\"\\nPredicted Class Distribution:\")\n",
    "for class_idx, count in pred_distribution.items():\n",
    "    print(f\"{class_idx}: {count}\")\n",
    "\n",
    "print(\"\\nClass-wise Metrics:\")\n",
    "for class_idx, class_metrics in metrics.items():\n",
    "    print(f\"\\nMetrics for {class_idx}:\")\n",
    "    for metric_name, metric_value in class_metrics.items():\n",
    "        print(f\"  {metric_name}: {metric_value:.4f}\")\n",
    "\n",
    "# Cell 6: Visualize results\n",
    "plot_class_metrics(metrics)\n",
    "plot_class_distribution(gt_distribution, pred_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb7c507-79f0-42f4-8956-e40b9b4826f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def calculate_class_metrics(predictions, ground_truth, num_classes):\n",
    "    pred_reshaped = predictions.permute(0, 2, 3, 1).reshape(-1, num_classes)\n",
    "    pred_labels = torch.argmax(pred_reshaped, dim=1).cpu().numpy()\n",
    "    \n",
    "    true_reshaped = ground_truth.squeeze(1).reshape(-1, num_classes)\n",
    "    true_labels = torch.argmax(true_reshaped, dim=1).cpu().numpy()\n",
    "    \n",
    "    metrics = {}\n",
    "    for class_idx in range(num_classes):\n",
    "        metrics[f'class_{class_idx}'] = {\n",
    "            'accuracy': accuracy_score(true_labels == class_idx, pred_labels == class_idx),\n",
    "            'precision': precision_score(true_labels == class_idx, pred_labels == class_idx, zero_division=0),\n",
    "            'recall': recall_score(true_labels == class_idx, pred_labels == class_idx, zero_division=0),\n",
    "            'f1_score': f1_score(true_labels == class_idx, pred_labels == class_idx, zero_division=0)\n",
    "        }\n",
    "    \n",
    "    # Calculate overall metrics\n",
    "    metrics['overall'] = {\n",
    "        'accuracy': accuracy_score(true_labels, pred_labels),\n",
    "        'precision': precision_score(true_labels, pred_labels, average='weighted', zero_division=0),\n",
    "        'recall': recall_score(true_labels, pred_labels, average='weighted', zero_division=0),\n",
    "        'f1_score': f1_score(true_labels, pred_labels, average='weighted', zero_division=0)\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Assuming your model is already defined and loaded\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Assuming test_loader is already defined\n",
    "num_classes = 5  # Adjust if necessary\n",
    "\n",
    "all_predictions = []\n",
    "all_ground_truths = []\n",
    "\n",
    "total_batches = len(test_loader)\n",
    "print(f\"Processing test set ({total_batches} batches):\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (images, binary_masks, cell_classes, tissue_classes, global_cell_count, _) in enumerate(test_loader):\n",
    "        images = images.to(device)\n",
    "        cell_classes = cell_classes.to(device)\n",
    "        \n",
    "        model_output = model(images)\n",
    "        class_predictions = model_output[1]  # Assuming class predictions are the second output\n",
    "        \n",
    "        all_predictions.append(class_predictions)\n",
    "        all_ground_truths.append(cell_classes)\n",
    "        \n",
    "        if (i + 1) % 10 == 0 or (i + 1) == total_batches:\n",
    "            print(f\"Processed {i + 1}/{total_batches} batches\", end='\\r')\n",
    "\n",
    "print(\"\\nCalculating metrics...\")\n",
    "\n",
    "predictions = torch.cat(all_predictions, dim=0)\n",
    "ground_truth = torch.cat(all_ground_truths, dim=0)\n",
    "\n",
    "metrics = calculate_class_metrics(predictions, ground_truth, num_classes)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nClass-wise Metrics:\")\n",
    "for class_idx, class_metrics in metrics.items():\n",
    "    if class_idx == 'overall':\n",
    "        print(\"\\nOverall Metrics:\")\n",
    "    else:\n",
    "        print(f\"\\nMetrics for {class_idx}:\")\n",
    "    for metric_name, metric_value in class_metrics.items():\n",
    "        print(f\"  {metric_name}: {metric_value:.4f}\")\n",
    "\n",
    "# Print summary in the requested format\n",
    "print(\"\\nSummary:\")\n",
    "print(\"Class\\tAccuracy\\tPrecision\\tRecall\\t\\tF1-score\")\n",
    "for class_idx, class_metrics in metrics.items():\n",
    "    print(f\"{class_idx}\\t{class_metrics['accuracy']:.4f}\\t\\t{class_metrics['precision']:.4f}\\t\\t{class_metrics['recall']:.4f}\\t\\t{class_metrics['f1_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3486eda3-7d91-447c-bfd6-a7ae618507aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yshokrollahi",
   "language": "python",
   "name": "yshokrollahi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
