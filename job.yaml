apiVersion: batch/v1
kind: Job
metadata:
  name: yshokrollahi-vitamin-p
  namespace: yn-gpu-workload
  labels:
    k8s-user: yshokrollahi
spec:
  backoffLimit: 0
  ttlSecondsAfterFinished: 600
  template:
    spec:
      nodeSelector:
        nvidia.com/gpu.present: "true"
        nvidia.com/gpu.product: NVIDIA-H100-80GB-HBM3
      securityContext:
        runAsUser: 297724
        runAsGroup: 1944303352
        fsGroup: 1944303352
        supplementalGroups:
          - 1944271327
          - 900027
      containers:
      - name: main
        image: hpcharbor.mdanderson.edu/yshokrollahi/vitamin-p:latest
        command: ["python", "/workspace/main.py"]
        workingDir: /workspace
        env:
        - name: HOME
          value: /tmp
        - name: PYTHONPATH
          value: /workspace
        - name: CUDA_VISIBLE_DEVICES
          value: "0"
        volumeMounts:
        - name: shm
          mountPath: /dev/shm
        - name: program
          mountPath: /rsrch9/home/plm/idso_fa1_pathology
        - name: checkpoints
          mountPath: /workspace/checkpoints
        - name: cache
          mountPath: /workspace/cache
        resources:
          limits:
            nvidia.com/gpu: 1
            memory: 32Gi
            cpu: "16"
          requests:
            nvidia.com/gpu: 1
            memory: 16Gi
            cpu: "8"
        imagePullPolicy: Always
      restartPolicy: Never
      volumes:
      - name: shm
        emptyDir:
          medium: Memory
          sizeLimit: 21474836480
      - name: program
        persistentVolumeClaim:
          claimName: yshokrollahi-gpu-rsrch9-home-plm
      - name: checkpoints
        persistentVolumeClaim:
          claimName: yshokrollahi-gpu-rsrch9-home-plm
          subPath: codes/yshokrollahi/vitamin-p/checkpoints
      - name: cache
        persistentVolumeClaim:
          claimName: yshokrollahi-gpu-rsrch9-home-plm
          subPath: codes/yshokrollahi/vitamin-p/cache