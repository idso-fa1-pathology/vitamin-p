apiVersion: batch/v1
kind: Job
metadata:
  name: vitamin-p-xenium-inference-region1
  namespace: yn-gpu-workload
spec:
  backoffLimit: 0
  ttlSecondsAfterFinished: 600
  template:
    spec:
      nodeSelector:
        nvidia.com/gpu.present: "true"
        nvidia.com/gpu.product: "NVIDIA-H100-80GB-HBM3"
      securityContext:
        runAsUser: 297724
        runAsGroup: 1944303352
        fsGroup: 1944303352
      volumes:
        - name: shm
          emptyDir:
            medium: Memory
            sizeLimit: '1000Gi'
        - name: program
          persistentVolumeClaim:
            claimName: yshokrollahi-gpu-rsrch9-home-plm
      containers:
        - name: inference-container
          image: hpcharbor.mdanderson.edu/yshokrollahi/vitamin-p:latest
          workingDir: /rsrch9/home/plm/idso_fa1_pathology/codes/yshokrollahi/vitamin-p-latest
          env:
            - name: HOME
              value: /tmp
            - name: PYTHONPATH
              value: /rsrch9/home/plm/idso_fa1_pathology/codes/yshokrollahi/vitamin-p-latest
          volumeMounts:
            - name: shm
              mountPath: "/dev/shm"
            - name: program
              mountPath: "/rsrch9/home/plm/idso_fa1_pathology"
          resources:
            limits:
              nvidia.com/gpu: "1"
              cpu: "30"
              memory: "350Gi"
          command:
            - /bin/bash
            - -c
            - |
              # ==========================================================
              # 1. Create the Python script dynamically inside the pod
              # ==========================================================
              cat << 'EOF' > run_xenium_custom.py
              import torch
              import numpy as np
              import tifffile
              import os
              import tempfile
              import sys
              from pathlib import Path

              # Add parent directory to path to ensure imports work
              sys.path.insert(0, os.getcwd())

              from vitaminp import VitaminPFlex
              from vitaminp.inference import WSIPredictor, ChannelConfig

              # ============================================================================
              # CONFIGURATION
              # ============================================================================
              DATA_DIR = "/rsrch9/home/plm/idso_fa1_pathology/TIER1/paul-xenium/Lung_Anthracosis/output-XETG00522__0057986__Region_1__20251203__234028"
              MORPHOLOGY_DIR = f"{DATA_DIR}/morphology_focus"
              CHECKPOINT_PATH = "checkpoints/vitamin_p_flex_large_fold21_best.pth" # Updated to fold2 based on your previous messages, check if fold21 exists!
              OUTPUT_DIR = "inference_dsp/xenium_results"
              
              print("="*60)
              print("READING ORIGINAL XENIUM CHANNELS")
              print("="*60)

              # Read DAPI channel
              dapi_path = f"{MORPHOLOGY_DIR}/ch0000_dapi.ome.tif"
              print(f"\nReading DAPI: {dapi_path}")
              with tifffile.TiffFile(dapi_path) as tif:
                  dapi = tif.pages[0].asarray()
                  print(f"   ✅ DAPI loaded: {dapi.shape}, dtype={dapi.dtype}")

              # Read CD45/E-cadherin channel
              cd45_path = f"{MORPHOLOGY_DIR}/ch0001_atp1a1_cd45_e-cadherin.ome.tif"
              print(f"Reading CD45/E-cadherin: {cd45_path}")
              with tifffile.TiffFile(cd45_path) as tif:
                  cd45_ecadherin = tif.pages[0].asarray()
                  print(f"   ✅ CD45/E-cadherin loaded: {cd45_ecadherin.shape}, dtype={cd45_ecadherin.dtype}")

              # Stack into 2-channel image (channels, height, width)
              combined = np.stack([dapi, cd45_ecadherin], axis=0)
              print(f"\n✅ Combined shape: {combined.shape} (channels, height, width)")

              # Save as temporary OME-TIFF for WSIPredictor
              # We use the output dir for the temp file to avoid /tmp space issues
              os.makedirs(OUTPUT_DIR, exist_ok=True)
              temp_image_path = os.path.join(OUTPUT_DIR, 'temp_combined_xenium.ome.tiff')
              
              tifffile.imwrite(temp_image_path, combined, photometric='minisblack')
              print(f"✅ Saved temporary file: {temp_image_path}")

              # ============================================================================
              # SETUP MODEL & PREDICTOR
              # ============================================================================
              device = 'cuda' if torch.cuda.is_available() else 'cpu'
              print(f"\nUsing device: {device}")

              # Load Model
              print("\nLoading model...")
              model = VitaminPFlex(model_size='large').to(device)
              
              # Load Checkpoint
              print(f"Loading checkpoint: {CHECKPOINT_PATH}")
              checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)
              # Robust loading (handle state_dict key)
              if isinstance(checkpoint, dict) and 'state_dict' in checkpoint:
                  state_dict = checkpoint['state_dict']
              elif isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
                  state_dict = checkpoint['model_state_dict']
              else:
                  state_dict = checkpoint
              model.load_state_dict(state_dict)
              model.eval()
              print("✅ Model loaded")

              # Create channel config
              config = ChannelConfig(
                  nuclear_channel=0,           # Channel 0: DAPI
                  membrane_channel=1,          # Channel 1: CD45/E-cadherin
                  channel_names={0: 'DAPI', 1: 'CD45_Ecadherin'}
              )

              # Create predictor
              predictor = WSIPredictor(
                  model=model,
                  device=device,
                  patch_size=512,
                  overlap=64,
                  target_mpp=0.2125,          # Xenium pixel size
                  magnification=40,
                  mif_channel_config=config,
                  tissue_dilation=1
              )

              print("\nPredictor settings:")
              print(f"   Patch size: 512")
              print(f"   Overlap: 64")
              print(f"   Target MPP: 0.2125 μm/pixel")
              print(f"   Magnification: 40x")

              # ============================================================================
              # RUN INFERENCE
              # ============================================================================
              print(f"\n{'='*60}")
              print("RUNNING INFERENCE...")
              print(f"{'='*60}")

              results = predictor.predict(
                  wsi_path=temp_image_path,
                  output_dir=OUTPUT_DIR,
                  branch='mif_cell',              # Use cell branch for whole cells
                  filter_tissue=True,
                  tissue_threshold=0.01,
                  clean_overlaps=True,            # Clean boundary artifacts
                  save_geojson=True,              # Save GeoJSON for visualization
                  detection_threshold=0.3,
                  min_area_um=10.0,               # Filter small artifacts (10 μm²)
                  mpp_override=0.263, 
              )

              print(f"\n{'='*60}")
              print("RESULTS")
              print(f"{'='*60}")
              print(f"✅ Found {results['num_detections']} cells in {results['processing_time']:.2f}s")
              print(f"   Output saved to: {results['output_dir']}")

              # Clean up temp file
              if os.path.exists(temp_image_path):
                  os.remove(temp_image_path)
                  print(f"✅ Cleaned up temporary file")
              EOF

              # ==========================================================
              # 2. Run the generated script
              # ==========================================================
              echo "Starting Xenium inference..."
              python run_xenium_custom.py
      restartPolicy: Never