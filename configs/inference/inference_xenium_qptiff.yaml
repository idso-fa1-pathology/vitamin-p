apiVersion: batch/v1
kind: Job
metadata:
  name: vitamin-p-qptiff-inference-fullslide
  namespace: yn-gpu-workload
spec:
  backoffLimit: 0
  ttlSecondsAfterFinished: 600
  template:
    spec:
      nodeSelector:
        nvidia.com/gpu.present: "true"
        nvidia.com/gpu.product: "NVIDIA-H100-80GB-HBM3"
      securityContext:
        runAsUser: 297724
        runAsGroup: 1944303352
        fsGroup: 1944303352
      volumes:
        - name: shm
          emptyDir:
            medium: Memory
            sizeLimit: '1000Gi'
        - name: program
          persistentVolumeClaim:
            claimName: yshokrollahi-gpu-rsrch9-home-plm
      containers:
        - name: inference-container
          image: hpcharbor.mdanderson.edu/yshokrollahi/vitamin-p:latest
          workingDir: /rsrch9/home/plm/idso_fa1_pathology/codes/yshokrollahi/vitamin-p-latest
          env:
            - name: HOME
              value: /tmp
            - name: PYTHONPATH
              value: /rsrch9/home/plm/idso_fa1_pathology/codes/yshokrollahi/vitamin-p-latest
          volumeMounts:
            - name: shm
              mountPath: "/dev/shm"
            - name: program
              mountPath: "/rsrch9/home/plm/idso_fa1_pathology"
          resources:
            limits:
              nvidia.com/gpu: "1"
              cpu: "30"
              memory: "350Gi"
          command:
            - /bin/bash
            - -c
            - |
              # ==========================================================
              # 1. Create the Python script dynamically inside the pod
              # ==========================================================
              cat << 'EOF' > run_qptiff_fullslide.py
              import torch
              import numpy as np
              import tifffile
              import os
              import tempfile
              import sys
              from pathlib import Path

              # Add parent directory to path to ensure imports work
              sys.path.insert(0, os.getcwd())

              from vitaminp import VitaminPFlex
              from vitaminp.inference import WSIPredictor, ChannelConfig

              # ============================================================================
              # CONFIGURATION
              # ============================================================================
              QPTIFF_PATH = "/rsrch9/home/plm/idso_fa1_pathology/TIER1/paul-xenium/Lung_Anthracosis/57986/Scan1/57986_Scan1.er.qptiff"
              CHECKPOINT_PATH = "checkpoints/vitamin_p_flex_large_fold21_best.pth"
              OUTPUT_DIR = "inference_dsp/qptiff_fullslide_results"
              
              # Channel mapping from QPTIFF
              # C1 (index 0): DAPI (nuclear)
              # C11 (index 10): E-cadherin (membrane)
              # C17 (index 16): CD45 (membrane/immune)
              
              print("="*60)
              print("READING QPTIFF CHANNELS")
              print("="*60)

              print(f"\nReading QPTIFF: {QPTIFF_PATH}")

              # Open QPTIFF and extract specific channels
              with tifffile.TiffFile(QPTIFF_PATH) as tif:
                  print(f"  Total pages/channels in file: {len(tif.pages)}")
                  
                  # Read channels (0-based indexing)
                  dapi = tif.pages[0].asarray()  # C1
                  ecadherin = tif.pages[10].asarray()  # C11
                  cd45 = tif.pages[16].asarray()  # C17
                  
                  print(f"  ✅ DAPI (C1) loaded: {dapi.shape}, dtype={dapi.dtype}")
                  print(f"  ✅ E-cadherin (C11) loaded: {ecadherin.shape}, dtype={ecadherin.dtype}")
                  print(f"  ✅ CD45 (C17) loaded: {cd45.shape}, dtype={cd45.dtype}")

              # Merge E-cadherin + CD45 into single membrane channel (max projection)
              print("\nMerging membrane channels (E-cadherin + CD45)...")
              membrane_merged = np.maximum(ecadherin, cd45)
              
              # Stack into 2-channel image (channels, height, width)
              combined = np.stack([dapi, membrane_merged], axis=0)
              print(f"✅ Combined shape: {combined.shape} (channels, height, width)")
              print(f"   Memory usage: {combined.nbytes / 1e9:.2f} GB")

              # Save as temporary OME-TIFF for WSIPredictor
              os.makedirs(OUTPUT_DIR, exist_ok=True)
              temp_image_path = os.path.join(OUTPUT_DIR, 'temp_combined_qptiff.ome.tiff')
              
              print(f"\nSaving temporary file: {temp_image_path}")
              tifffile.imwrite(temp_image_path, combined, photometric='minisblack')
              print(f"✅ Saved temporary file")

              # ============================================================================
              # SETUP MODEL & PREDICTOR
              # ============================================================================
              device = 'cuda' if torch.cuda.is_available() else 'cpu'
              print(f"\n{'='*60}")
              print(f"Using device: {device}")
              print(f"{'='*60}")

              # Load Model
              print("\nLoading model...")
              model = VitaminPFlex(model_size='large').to(device)
              
              # Load Checkpoint
              print(f"Loading checkpoint: {CHECKPOINT_PATH}")
              checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)
              # Robust loading (handle state_dict key)
              if isinstance(checkpoint, dict) and 'state_dict' in checkpoint:
                  state_dict = checkpoint['state_dict']
              elif isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
                  state_dict = checkpoint['model_state_dict']
              else:
                  state_dict = checkpoint
              model.load_state_dict(state_dict)
              model.eval()
              print("✅ Model loaded")

              # Create channel config
              config = ChannelConfig(
                  nuclear_channel=0,           # Channel 0: DAPI
                  membrane_channel=1,          # Channel 1: Merged membrane
                  channel_names={0: 'DAPI', 1: 'Merged_Membrane'}
              )

              # QPTIFF resolution - adjust based on your microscope
              # Common values: 0.25 μm/pixel at 40x, 0.50 μm/pixel at 20x
              QPTIFF_MPP = 0.25

              # Create predictor
              predictor = WSIPredictor(
                  model=model,
                  device=device,
                  patch_size=512,
                  overlap=64,
                  target_mpp=QPTIFF_MPP,
                  magnification=40,
                  mif_channel_config=config
              )

              print("\nPredictor settings:")
              print(f"  Patch size: 512")
              print(f"  Overlap: 64")
              print(f"  Target MPP: {QPTIFF_MPP} μm/pixel")
              print(f"  Magnification: 40x")

              # ============================================================================
              # RUN INFERENCE
              # ============================================================================
              print(f"\n{'='*60}")
              print("RUNNING INFERENCE ON FULL SLIDE...")
              print(f"Image size: {combined.shape[1]} × {combined.shape[2]} pixels")
              print(f"{'='*60}")

              results = predictor.predict(
                  wsi_path=temp_image_path,
                  output_dir=OUTPUT_DIR,
                  branch='mif_cell',              # Use cell branch for whole cells
                  filter_tissue=True,
                  tissue_threshold=0.01,
                  clean_overlaps=True,            # Clean boundary artifacts
                  save_geojson=True,              # Save GeoJSON for visualization
                  detection_threshold=0.3,
                  min_area_um=10.0,               # Filter small artifacts (10 μm²)
              )

              print(f"\n{'='*60}")
              print("RESULTS")
              print(f"{'='*60}")
              print(f"✅ Found {results['num_detections']} cells in {results['processing_time']:.2f}s")
              print(f"   Output saved to: {results['output_dir']}")
              print(f"   Cells per second: {results['num_detections'] / results['processing_time']:.1f}")

              # Clean up temp file
              if os.path.exists(temp_image_path):
                  os.remove(temp_image_path)
                  print(f"✅ Cleaned up temporary file")
              
              print("\n" + "="*60)
              print("INFERENCE COMPLETE!")
              print("="*60)
              EOF

              # ==========================================================
              # 2. Run the generated script
              # ==========================================================
              echo "Starting QPTIFF full slide inference..."
              python run_qptiff_fullslide.py
      restartPolicy: Never