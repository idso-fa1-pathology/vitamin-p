{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "870300a6-b133-4eef-8925-3e21c7f6e028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added /rsrch5/home/plm/yshokrollahi/vitamin-p-new to Python path\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the absolute path to the project root\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "# Add the project root to the Python path\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "print(f\"Added {project_root} to Python path\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da453e51-a915-4126-97b5-f92493ee57af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now try the imports again\n",
    "from models.model import CellSwin\n",
    "from data.dataset import CellSegmentationDataset\n",
    "from models.metrics import iou_score, calculate_object_based_metrics\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from data.data_loading import load_all_folds, create_train_val_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3efd0e73-b5cd-46b0-a845-7150cc6f4440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /rsrch5/home/plm/yshokrollahi/vitamin-p-new/checkpoints/v3_fold2.pth\n",
      "Model loaded successfully and moved to cuda!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "# Get the project root directory\n",
    "project_root = os.path.dirname(os.getcwd())  # Assuming we're in a notebook in a subdirectory\n",
    "\n",
    "# Path to your saved model\n",
    "model_path = os.path.join(project_root, 'checkpoints', 'v3_fold2.pth')\n",
    "\n",
    "# Print the model path to verify\n",
    "print(f\"Loading model from: {model_path}\")\n",
    "\n",
    "# Determine the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize the model architecture\n",
    "trained_model = CellSwin().float()\n",
    "\n",
    "# Load the saved state dict\n",
    "state_dict = torch.load(model_path, map_location=device)\n",
    "\n",
    "# Load the state dict into your model\n",
    "trained_model.load_state_dict(state_dict)\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "trained_model = trained_model.to(device)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "trained_model.eval()\n",
    "\n",
    "print(f\"Model loaded successfully and moved to {device}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab308072-77bd-4d61-840e-57d7b0f6ec30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import torch\n",
    "import random\n",
    "\n",
    "def visualize_prediction_with_metrics(model, test_dataset, device, num_samples=3):\n",
    "    model.eval()\n",
    "    \n",
    "    # Randomly select indices\n",
    "    indices = random.sample(range(len(test_dataset)), num_samples)\n",
    "    \n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, 5*num_samples))\n",
    "    \n",
    "    overall_f1 = 0\n",
    "    overall_precision = 0\n",
    "    overall_recall = 0\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        image, mask = test_dataset[idx]\n",
    "        image = image.unsqueeze(0).to(device)  # Add batch dimension\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(image)\n",
    "        \n",
    "        image = image.cpu().numpy().transpose(0, 2, 3, 1).squeeze()\n",
    "        mask = mask.cpu().numpy().squeeze()\n",
    "        output = output.cpu().numpy().squeeze()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        pred_mask = (output > 0.5).astype(np.uint8)\n",
    "        f1 = f1_score(mask.flatten(), pred_mask.flatten(), average='binary')\n",
    "        precision = precision_score(mask.flatten(), pred_mask.flatten(), average='binary')\n",
    "        recall = recall_score(mask.flatten(), pred_mask.flatten(), average='binary')\n",
    "        \n",
    "        overall_f1 += f1\n",
    "        overall_precision += precision\n",
    "        overall_recall += recall\n",
    "        \n",
    "        # Plotting\n",
    "        axes[i, 0].imshow(image)\n",
    "        axes[i, 0].set_title(f\"Input Image {idx}\")\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # Use a custom colormap for true mask\n",
    "        axes[i, 1].imshow(mask, cmap='gray_r', vmin=0, vmax=1)\n",
    "        axes[i, 1].set_title(f\"True Mask {idx}\")\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        # Use a custom colormap for predicted mask\n",
    "        axes[i, 2].imshow(pred_mask, cmap='gray_r', vmin=0, vmax=1)\n",
    "        axes[i, 2].set_title(f\"Predicted Mask {idx}\\nF1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")\n",
    "        axes[i, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate and print overall metrics\n",
    "    overall_f1 /= num_samples\n",
    "    overall_precision /= num_samples\n",
    "    overall_recall /= num_samples\n",
    "    \n",
    "    print(f\"Overall Metrics (average of {num_samples} samples):\")\n",
    "    print(f\"F1 Score: {overall_f1:.4f}\")\n",
    "    print(f\"Precision: {overall_precision:.4f}\")\n",
    "    print(f\"Recall: {overall_recall:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70b67029-4f56-47e6-8d5c-9c1dd7f9c4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of base_path:\n",
      "['._.DS_Store', '.DS_Store', 'Fold 2', '._Fold 1', 'Fold 1', 'Fold 3']\n",
      "\n",
      "Contents of ../data/raw/H&E/Fold 1:\n",
      "['._images', '._.DS_Store', '._README.md', '._masks', 'images', '.DS_Store', 'README.md', 'masks']\n",
      "\n",
      "Contents of ../data/raw/H&E/Fold 2:\n",
      "['._.DS_Store', '._README.md', 'images', '.DS_Store', 'README.md', 'masks']\n",
      "\n",
      "Contents of ../data/raw/H&E/Fold 3:\n",
      "['._.DS_Store', '._README.md', 'images', '.DS_Store', 'README.md', 'masks']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'data_splits' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 19\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfold_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m model \u001b[38;5;241m=\u001b[39m trained_model  \u001b[38;5;66;03m# Your trained CellViT model\u001b[39;00m\n\u001b[1;32m     18\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m CellSegmentationDataset(\n\u001b[0;32m---> 19\u001b[0m     \u001b[43mdata_splits\u001b[49m[chosen_split][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     20\u001b[0m     data_splits[chosen_split][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmasks\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     21\u001b[0m     image_transform\u001b[38;5;241m=\u001b[39mimage_transform,\n\u001b[1;32m     22\u001b[0m     mask_transform\u001b[38;5;241m=\u001b[39mmask_transform\n\u001b[1;32m     23\u001b[0m )\n\u001b[1;32m     24\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     25\u001b[0m num_test_images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(test_dataset)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_splits' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "base_path = \"../data/raw/H&E\"\n",
    "\n",
    "print(\"Contents of base_path:\")\n",
    "print(os.listdir(base_path))\n",
    "\n",
    "for fold in [\"Fold 1\", \"Fold 2\", \"Fold 3\"]:\n",
    "    fold_path = os.path.join(base_path, fold)\n",
    "    if os.path.exists(fold_path):\n",
    "        print(f\"\\nContents of {fold_path}:\")\n",
    "        print(os.listdir(fold_path))\n",
    "    else:\n",
    "        print(f\"\\n{fold_path} does not exist\")\n",
    "        \n",
    "\n",
    "model = trained_model  # Your trained CellViT model\n",
    "test_dataset = CellSegmentationDataset(\n",
    "    data_splits[chosen_split]['test']['images'],\n",
    "    data_splits[chosen_split]['test']['masks'],\n",
    "    image_transform=image_transform,\n",
    "    mask_transform=mask_transform\n",
    ")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_test_images = len(test_dataset)\n",
    "print(num_test_images)\n",
    "# Visualize and calculate metrics\n",
    "visualize_prediction_with_metrics(model, test_dataset, device, num_samples=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "861d47e0-ef17-49ba-905c-3b981bc2a3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/rsrch5/home/plm/yshokrollahi/vitamin-p-new/notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b4c5cc-649c-4a4e-90aa-18bc8126c2f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yshokrollahi",
   "language": "python",
   "name": "yshokrollahi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
