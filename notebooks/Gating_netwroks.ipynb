{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72ea1e70-a975-4c88-a0f2-dbfc719a1053",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (23.3.1)\n",
      "Collecting pip\n",
      "  Downloading pip-24.3.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Downloading pip-24.3.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "Successfully installed pip-24.3.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: natsort in /home/yshokrollahi/.local/lib/python3.11/site-packages (8.4.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting albumentations\n",
      "  Downloading albumentations-1.4.21-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.11/dist-packages (from albumentations) (1.26.2)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from albumentations) (1.11.4)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from albumentations) (6.0.1)\n",
      "Collecting pydantic>=2.7.0 (from albumentations)\n",
      "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "Collecting albucore==0.0.20 (from albumentations)\n",
      "  Downloading albucore-0.0.20-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting eval-type-backport (from albumentations)\n",
      "  Downloading eval_type_backport-0.2.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opencv-python-headless>=4.9.0.80 (from albumentations)\n",
      "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting stringzilla>=3.10.4 (from albucore==0.0.20->albumentations)\n",
      "  Downloading stringzilla-3.10.10-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl.metadata (79 kB)\n",
      "Collecting simsimd>=5.9.2 (from albucore==0.0.20->albumentations)\n",
      "  Downloading simsimd-6.0.5-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (57 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.7.0->albumentations)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.23.4 (from pydantic>=2.7.0->albumentations)\n",
      "  Downloading pydantic_core-2.23.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.0->albumentations) (4.8.0)\n",
      "Downloading albumentations-1.4.21-py3-none-any.whl (227 kB)\n",
      "Downloading albucore-0.0.20-py3-none-any.whl (12 kB)\n",
      "Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "Downloading pydantic_core-2.23.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading eval_type_backport-0.2.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading simsimd-6.0.5-cp311-cp311-manylinux_2_28_x86_64.whl (605 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m605.1/605.1 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading stringzilla-3.10.10-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl (295 kB)\n",
      "Installing collected packages: stringzilla, simsimd, pydantic-core, opencv-python-headless, eval-type-backport, annotated-types, pydantic, albucore, albumentations\n",
      "Successfully installed albucore-0.0.20 albumentations-1.4.21 annotated-types-0.7.0 eval-type-backport-0.2.0 opencv-python-headless-4.10.0.84 pydantic-2.9.2 pydantic-core-2.23.4 simsimd-6.0.5 stringzilla-3.10.10\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting wandb\n",
      "  Downloading wandb-0.18.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.7)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
      "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.1.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.20.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.7)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /home/yshokrollahi/.local/lib/python3.11/site-packages (from wandb) (2.32.3)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb)\n",
      "  Downloading sentry_sdk-2.18.0-py2.py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting setproctitle (from wandb)\n",
      "  Downloading setproctitle-1.3.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (61.2.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.8.0)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/lib/python3/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2023.11.17)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Downloading wandb-0.18.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.1/16.1 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "Downloading sentry_sdk-2.18.0-py2.py3-none-any.whl (317 kB)\n",
      "Downloading setproctitle-1.3.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
      "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, gitpython, wandb\n",
      "Successfully installed docker-pycreds-0.4.0 gitdb-4.0.11 gitpython-3.1.43 sentry-sdk-2.18.0 setproctitle-1.3.4 smmap-5.0.1 wandb-0.18.7\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torchinfo\n",
      "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
      "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
      "Installing collected packages: torchinfo\n",
      "Successfully installed torchinfo-1.8.0\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting schema\n",
      "  Downloading schema-0.7.7-py2.py3-none-any.whl.metadata (34 kB)\n",
      "Downloading schema-0.7.7-py2.py3-none-any.whl (18 kB)\n",
      "Installing collected packages: schema\n",
      "Successfully installed schema-0.7.7\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torchmetrics\n",
      "  Downloading torchmetrics-1.6.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (1.26.2)\n",
      "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (23.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (2.1.2)\n",
      "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
      "  Downloading lightning_utilities-0.11.8-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (61.2.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.8.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.13.1)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2023.12.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->torchmetrics) (12.3.101)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=2.0.0->torchmetrics) (1.3.0)\n",
      "Downloading torchmetrics-1.6.0-py3-none-any.whl (926 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m926.4/926.4 kB\u001b[0m \u001b[31m98.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lightning_utilities-0.11.8-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: lightning-utilities, torchmetrics\n",
      "Successfully installed lightning-utilities-0.11.8 torchmetrics-1.6.0\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting einops\n",
      "  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n",
      "Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
      "Installing collected packages: einops\n",
      "Successfully installed einops-0.8.0\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting timm\n",
      "  Downloading timm-1.0.11-py3-none-any.whl.metadata (48 kB)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from timm) (2.1.2)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm) (0.16.2)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm) (6.0.1)\n",
      "Requirement already satisfied: huggingface_hub in /home/yshokrollahi/.local/lib/python3.11/site-packages (from timm) (0.26.2)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2023.12.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (23.2)\n",
      "Requirement already satisfied: requests in /home/yshokrollahi/.local/lib/python3.11/site-packages (from huggingface_hub->timm) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/yshokrollahi/.local/lib/python3.11/site-packages (from huggingface_hub->timm) (4.67.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.8.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->timm) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->timm) (12.3.101)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (1.26.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (10.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->timm) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->timm) (1.3.0)\n",
      "Downloading timm-1.0.11-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m128.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: timm\n",
      "Successfully installed timm-1.0.11\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: natsort in /home/yshokrollahi/.local/lib/python3.11/site-packages (8.4.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torchsummary\n",
      "  Downloading torchsummary-1.5.1-py3-none-any.whl.metadata (296 bytes)\n",
      "Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
      "Installing collected packages: torchsummary\n",
      "Successfully installed torchsummary-1.5.1\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: natsort in /home/yshokrollahi/.local/lib/python3.11/site-packages (8.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install natsort\n",
    "!pip install albumentations\n",
    "!pip install wandb\n",
    "!pip install torchinfo\n",
    "!pip install schema\n",
    "!pip install torchmetrics\n",
    "!pip install einops\n",
    "!pip install timm\n",
    "!pip install natsort\n",
    "!pip install torchsummary\n",
    "!pip install natsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a304ad3e-0cd1-4e19-8bcf-0ddda0a75b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported CellViT modules\n",
      "\n",
      "Initializing dataset manager...\n",
      "Successfully loaded configuration files\n",
      "\n",
      "Verifying dataset paths and configurations...\n",
      "\n",
      "Checking PanNuke dataset:\n",
      "Path exists: True\n",
      "dataset_config.yaml exists: True\n",
      "weight_config.yaml exists: True\n",
      "\n",
      "Checking TissueNet dataset:\n",
      "Path exists: True\n",
      "dataset_config.yaml exists: False\n",
      "weight_config.yaml exists: False\n",
      "\n",
      "Setting up TissueNet...\n",
      "\n",
      "Setting up TissueNet datasets...\n",
      "Created train dataset with 10320 samples\n",
      "Created val dataset with 3118 samples\n",
      "Created test dataset with 1324 samples\n",
      "\n",
      "Setting up PanNuke...\n",
      "\n",
      "Setting up PanNuke datasets...\n",
      "Created train dataset with 5179 samples\n",
      "Created val dataset with 2722 samples\n",
      "\n",
      "Setup successful!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add CellViT to python path first\n",
    "cellvit_path = \"/rsrch5/home/plm/yshokrollahi/CellViT\"\n",
    "if cellvit_path not in sys.path:\n",
    "    sys.path.append(cellvit_path)\n",
    "    print(f\"Added {cellvit_path} to Python path\")\n",
    "\n",
    "import yaml\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    from cell_segmentation.datasets.pannuke import PanNukeDataset\n",
    "    from cell_segmentation.datasets.tissuenet import TissueNetDataset\n",
    "    print(\"Successfully imported CellViT modules\")\n",
    "except ImportError as e:\n",
    "    print(f\"Import error: {e}\")\n",
    "    raise\n",
    "\n",
    "class MultiModalDatasetManager:\n",
    "    def __init__(self):\n",
    "        # Dataset paths\n",
    "        self.tissuenet_path = Path(\"/rsrch5/home/plm/yshokrollahi/CellViT/configs/datasets/tissuenet\")\n",
    "        self.pannuke_path = Path(\"/rsrch5/home/plm/yshokrollahi/CellViT/configs/datasets/reassemble\")\n",
    "        \n",
    "        # Config paths\n",
    "        self.tissuenet_config_path = Path(\"/rsrch5/home/plm/yshokrollahi/CellViT/configs/examples/cell_segmentation/vitaminp-tissuenet.yaml\")\n",
    "        self.pannuke_config_path = Path(\"/rsrch5/home/plm/yshokrollahi/CellViT/configs/examples/cell_segmentation/pannuke-vitaminp.yaml\")\n",
    "        \n",
    "        self._load_configs()\n",
    "\n",
    "    def _load_configs(self):\n",
    "        try:\n",
    "            with open(self.tissuenet_config_path, 'r') as file:\n",
    "                self.tissuenet_config = yaml.safe_load(file)\n",
    "            with open(self.pannuke_config_path, 'r') as file:\n",
    "                self.pannuke_config = yaml.safe_load(file)\n",
    "            print(\"Successfully loaded configuration files\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading configs: {e}\")\n",
    "            raise\n",
    "\n",
    "    def get_transforms(self, transform_settings, input_shape=256):\n",
    "        transforms = []\n",
    "        \n",
    "        if input_shape != 256:\n",
    "            transforms.append(A.Resize(input_shape, input_shape))\n",
    "        \n",
    "        transforms.extend([\n",
    "            A.RandomRotate90(p=0.5),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.Downscale(scale_min=0.5, scale_max=1.0, p=0.15),\n",
    "            A.Blur(blur_limit=9, p=0.2),\n",
    "            A.GaussNoise(var_limit=50, p=0.25),\n",
    "            A.ElasticTransform(p=0.2),\n",
    "        ])\n",
    "        \n",
    "        if 'normalize' in transform_settings:\n",
    "            transforms.append(A.Normalize(**transform_settings['normalize']))\n",
    "        \n",
    "        return A.Compose(transforms)\n",
    "\n",
    "    def create_dataloader(self, dataset, config, is_train=False):\n",
    "        if len(dataset) == 0:\n",
    "            raise ValueError(f\"Dataset is empty!\")\n",
    "        \n",
    "        batch_size = config['training']['batch_size']\n",
    "        return DataLoader(dataset, \n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=is_train,\n",
    "                         num_workers=16,\n",
    "                         pin_memory=True)\n",
    "\n",
    "    def setup_tissuenet(self):\n",
    "        print(\"\\nSetting up TissueNet datasets...\")\n",
    "        \n",
    "        # Create transforms\n",
    "        train_transforms = self.get_transforms(self.tissuenet_config['transformations'])\n",
    "        val_transforms = A.Compose([A.Normalize(**self.tissuenet_config['transformations']['normalize'])])\n",
    "        \n",
    "        # Initialize datasets directly using TissueNetDataset\n",
    "        datasets = {\n",
    "            'train': TissueNetDataset(\n",
    "                dataset_path=self.tissuenet_path,\n",
    "                split='train',\n",
    "                transforms=train_transforms,\n",
    "                stardist=False,\n",
    "                regression=False,\n",
    "                cache_dataset=False\n",
    "            ),\n",
    "            'val': TissueNetDataset(\n",
    "                dataset_path=self.tissuenet_path,\n",
    "                split='val',\n",
    "                transforms=val_transforms,\n",
    "                stardist=False,\n",
    "                regression=False,\n",
    "                cache_dataset=False\n",
    "            ),\n",
    "            'test': TissueNetDataset(\n",
    "                dataset_path=self.tissuenet_path,\n",
    "                split='test',\n",
    "                transforms=val_transforms,\n",
    "                stardist=False,\n",
    "                regression=False,\n",
    "                cache_dataset=False\n",
    "            )\n",
    "        }\n",
    "        \n",
    "        # Create dataloaders\n",
    "        dataloaders = {}\n",
    "        for split in datasets:\n",
    "            dataloaders[split] = self.create_dataloader(\n",
    "                datasets[split],\n",
    "                self.tissuenet_config,\n",
    "                is_train=(split == 'train')\n",
    "            )\n",
    "            print(f\"Created {split} dataset with {len(datasets[split])} samples\")\n",
    "            \n",
    "        return datasets, dataloaders\n",
    "\n",
    "    def setup_pannuke(self):\n",
    "        print(\"\\nSetting up PanNuke datasets...\")\n",
    "        \n",
    "        datasets = {\n",
    "            'train': PanNukeDataset(\n",
    "                dataset_path=self.pannuke_path,\n",
    "                folds=[0, 1],  # Use first two folds for training\n",
    "                transforms=None,\n",
    "                stardist=False,\n",
    "                regression=False,\n",
    "                cache_dataset=False\n",
    "            ),\n",
    "            'val': PanNukeDataset(\n",
    "                dataset_path=self.pannuke_path,\n",
    "                folds=[2],  # Use last fold for validation\n",
    "                transforms=None,\n",
    "                stardist=False,\n",
    "                regression=False,\n",
    "                cache_dataset=False\n",
    "            )\n",
    "        }\n",
    "        \n",
    "        dataloaders = {}\n",
    "        for split in datasets:\n",
    "            dataloaders[split] = self.create_dataloader(\n",
    "                datasets[split],\n",
    "                self.pannuke_config,\n",
    "                is_train=(split == 'train')\n",
    "            )\n",
    "            print(f\"Created {split} dataset with {len(datasets[split])} samples\")\n",
    "            \n",
    "        return datasets, dataloaders\n",
    "\n",
    "    def verify_datasets(self):\n",
    "        print(\"\\nVerifying dataset paths and configurations...\")\n",
    "        for path, name in [(self.pannuke_path, \"PanNuke\"), \n",
    "                          (self.tissuenet_path, \"TissueNet\")]:\n",
    "            print(f\"\\nChecking {name} dataset:\")\n",
    "            print(f\"Path exists: {path.exists()}\")\n",
    "            print(f\"dataset_config.yaml exists: {(path / 'dataset_config.yaml').exists()}\")\n",
    "            print(f\"weight_config.yaml exists: {(path / 'weight_config.yaml').exists()}\")\n",
    "\n",
    "# Test the setup\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\nInitializing dataset manager...\")\n",
    "    try:\n",
    "        data_manager = MultiModalDatasetManager()\n",
    "        data_manager.verify_datasets()\n",
    "        \n",
    "        print(\"\\nSetting up TissueNet...\")\n",
    "        tissuenet_datasets, tissuenet_loaders = data_manager.setup_tissuenet()\n",
    "        \n",
    "        print(\"\\nSetting up PanNuke...\")\n",
    "        pannuke_datasets, pannuke_loaders = data_manager.setup_pannuke()\n",
    "        \n",
    "        print(\"\\nSetup successful!\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError during setup: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aaa8f938-2694-400e-b1d0-dd8866470a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def visualize_tissuenet_sample(dataset, title=\"TissueNet Sample\"):\n",
    "#     # Get random sample\n",
    "#     random_idx = np.random.randint(0, len(dataset))\n",
    "#     img, masks, img_name = dataset[random_idx]\n",
    "    \n",
    "#     plt.figure(figsize=(20, 8))\n",
    "    \n",
    "#     # First row: Cell-related visualizations\n",
    "#     plt.subplot(251)\n",
    "#     plt.imshow(img[0].numpy(), cmap='gray')\n",
    "#     plt.title('Channel 1')\n",
    "#     plt.axis('off')\n",
    "    \n",
    "#     plt.subplot(252)\n",
    "#     plt.imshow(img[1].numpy(), cmap='gray')\n",
    "#     plt.title('Channel 2')\n",
    "#     plt.axis('off')\n",
    "    \n",
    "#     plt.subplot(253)\n",
    "#     plt.imshow(masks['cell_mask'], cmap='nipy_spectral')\n",
    "#     plt.title('Cell Instances')\n",
    "#     plt.axis('off')\n",
    "    \n",
    "#     plt.subplot(254)\n",
    "#     plt.imshow(masks['cell_hv_map'][0], cmap='coolwarm')\n",
    "#     plt.title('Cell HV (H)')\n",
    "#     plt.axis('off')\n",
    "    \n",
    "#     plt.subplot(255)\n",
    "#     plt.imshow(masks['cell_hv_map'][1], cmap='coolwarm')\n",
    "#     plt.title('Cell HV (V)')\n",
    "#     plt.axis('off')\n",
    "    \n",
    "#     # Second row: Combined view and nuclei-related visualizations\n",
    "#     plt.subplot(256)\n",
    "#     combined_img = np.stack([\n",
    "#         np.zeros_like(img[0].numpy()),\n",
    "#         img[1].numpy(),\n",
    "#         img[0].numpy()\n",
    "#     ], axis=2)\n",
    "#     if combined_img.max() > 1:\n",
    "#         combined_img = combined_img / combined_img.max()\n",
    "#     plt.imshow(combined_img)\n",
    "#     plt.title('Combined')\n",
    "#     plt.axis('off')\n",
    "    \n",
    "#     plt.subplot(257)\n",
    "#     plt.imshow(masks['nuclei_mask'], cmap='nipy_spectral')\n",
    "#     plt.title('Nuclei Instances')\n",
    "#     plt.axis('off')\n",
    "    \n",
    "#     plt.subplot(258)\n",
    "#     plt.imshow(masks['nuclei_hv_map'][0], cmap='coolwarm')\n",
    "#     plt.title('Nuclei HV (H)')\n",
    "#     plt.axis('off')\n",
    "    \n",
    "#     plt.subplot(259)\n",
    "#     plt.imshow(masks['nuclei_hv_map'][1], cmap='coolwarm')\n",
    "#     plt.title('Nuclei HV (V)')\n",
    "#     plt.axis('off')\n",
    "    \n",
    "#     plt.subplot(2,5,10)\n",
    "#     nuclei_hv_magnitude = np.sqrt(masks['nuclei_hv_map'][0]**2 + masks['nuclei_hv_map'][1]**2)\n",
    "#     plt.imshow(nuclei_hv_magnitude, cmap='viridis')\n",
    "#     plt.title('Nuclei HV Magnitude')\n",
    "#     plt.axis('off')\n",
    "    \n",
    "#     plt.suptitle(f\"{title} - {img_name}\")\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# def visualize_pannuke_sample(dataset, title=\"PanNuke Sample\"):\n",
    "#     # Get random sample\n",
    "#     random_idx = np.random.randint(0, len(dataset))\n",
    "#     img, masks, tissue_type, img_name = dataset[random_idx]\n",
    "    \n",
    "#     plt.figure(figsize=(15, 5))\n",
    "    \n",
    "#     # Original image\n",
    "#     plt.subplot(131)\n",
    "#     plt.imshow(img.permute(1, 2, 0))\n",
    "#     plt.title(f'Original Image\\nTissue: {tissue_type}')\n",
    "#     plt.axis('off')\n",
    "    \n",
    "#     # Instance map\n",
    "#     plt.subplot(132)\n",
    "#     plt.imshow(masks['instance_map'], cmap='nipy_spectral')\n",
    "#     plt.title('Instance Map')\n",
    "#     plt.axis('off')\n",
    "    \n",
    "#     # Nuclei type map\n",
    "#     plt.subplot(133)\n",
    "#     plt.imshow(masks['nuclei_type_map'], cmap='tab20')\n",
    "#     plt.title('Nuclei Type Map')\n",
    "#     plt.axis('off')\n",
    "    \n",
    "#     plt.suptitle(f\"{title} - {img_name}\")\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# # Test visualization with the dataset manager\n",
    "# if __name__ == \"__main__\":\n",
    "#     print(\"\\nInitializing dataset manager...\")\n",
    "#     data_manager = MultiModalDatasetManager()\n",
    "    \n",
    "#     # Setup datasets\n",
    "#     tissuenet_datasets, tissuenet_loaders = data_manager.setup_tissuenet()\n",
    "#     pannuke_datasets, pannuke_loaders = data_manager.setup_pannuke()\n",
    "    \n",
    "#     print(\"\\nVisualizing TissueNet samples:\")\n",
    "#     for split in ['train', 'val', 'test']:\n",
    "#         print(f\"\\nVisualizing {split} split:\")\n",
    "#         visualize_tissuenet_sample(tissuenet_datasets[split], f\"TissueNet {split.capitalize()}\")\n",
    "    \n",
    "#     print(\"\\nVisualizing PanNuke samples:\")\n",
    "#     for split in ['train', 'val']:\n",
    "#         print(f\"\\nVisualizing {split} split:\")\n",
    "#         visualize_pannuke_sample(pannuke_datasets[split], f\"PanNuke {split.capitalize()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29d6fa4-2e1f-4408-8b49-161e5f924d12",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf9668e6-2a8d-4b58-aa41-6a35ce9f0d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import swin_v2_b, Swin_V2_B_Weights\n",
    "from typing import List, Tuple, Literal, OrderedDict\n",
    "import numpy as np\n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "class Conv2DBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "        super(Conv2DBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.relu(self.bn(self.conv(x))) + 1e-5 * torch.sum(torch.pow(self.conv.weight, 2))\n",
    "\n",
    "class Deconv2DBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=2, stride=2):\n",
    "        super(Deconv2DBlock, self).__init__()\n",
    "        self.deconv = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.relu(self.bn(self.deconv(x)))\n",
    "\n",
    "\n",
    "class SwinEncoder(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super().__init__()\n",
    "        if pretrained:\n",
    "            weights = Swin_V2_B_Weights.IMAGENET1K_V1\n",
    "        else:\n",
    "            weights = None\n",
    "        self.swin = swin_v2_b(weights=weights)\n",
    "        self.swin.head = nn.Identity()  \n",
    "\n",
    "        # Corrected channel dimensions for extra processing layers\n",
    "        self.extra_processing = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                Conv2DBlock(256, 256),  # Changed from 1024 to match input channels\n",
    "                SEBlock(256),\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                Conv2DBlock(512, 512),\n",
    "                SEBlock(512),\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                Conv2DBlock(1024, 1024),\n",
    "                SEBlock(1024),\n",
    "            )\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = []\n",
    "        for i, layer in enumerate(self.swin.features):\n",
    "            x = layer(x)\n",
    "            if i in [2, 4, 6, 7]:  \n",
    "                curr_x = x.permute(0, 3, 1, 2)  # Change from [B, H, W, C] to [B, C, H, W]\n",
    "                if len(features) < len(self.extra_processing):\n",
    "                    curr_x = self.extra_processing[len(features)](curr_x)\n",
    "                features.append(curr_x)\n",
    "        return features\n",
    "\n",
    "class FeaturePyramidNetwork(nn.Module):\n",
    "    def __init__(self, in_channels_list, out_channels):\n",
    "        super(FeaturePyramidNetwork, self).__init__()\n",
    "        self.inner_blocks = nn.ModuleList()\n",
    "        self.layer_blocks = nn.ModuleList()\n",
    "        self.extra_blocks = nn.ModuleList()  # New extra processing blocks\n",
    "\n",
    "        for in_channels in in_channels_list:\n",
    "            inner_block_module = nn.Conv2d(in_channels, out_channels, 1)\n",
    "            layer_block_module = nn.Sequential(\n",
    "                Conv2DBlock(out_channels, out_channels),\n",
    "                Conv2DBlock(out_channels, out_channels),\n",
    "                SEBlock(out_channels)\n",
    "            )\n",
    "            extra_block = nn.Sequential(\n",
    "                Conv2DBlock(out_channels, out_channels),\n",
    "                SEBlock(out_channels)\n",
    "            )\n",
    "            \n",
    "            self.inner_blocks.append(inner_block_module)\n",
    "            self.layer_blocks.append(layer_block_module)\n",
    "            self.extra_blocks.append(extra_block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        results = []\n",
    "        \n",
    "        last_inner = self.inner_blocks[-1](x[-1])\n",
    "        last_inner = self.extra_blocks[-1](last_inner)  # Extra processing\n",
    "        results.append(self.layer_blocks[-1](last_inner))\n",
    "\n",
    "        for feature, inner_block, layer_block, extra_block in zip(\n",
    "            x[:-1][::-1], \n",
    "            self.inner_blocks[:-1][::-1], \n",
    "            self.layer_blocks[:-1][::-1],\n",
    "            self.extra_blocks[:-1][::-1]\n",
    "        ):\n",
    "            if last_inner.shape[-2:] != feature.shape[-2:]:\n",
    "                inner_top_down = F.interpolate(last_inner, size=feature.shape[-2:], mode=\"nearest\")\n",
    "            else:\n",
    "                inner_top_down = last_inner\n",
    "                \n",
    "            inner_lateral = inner_block(feature)\n",
    "            last_inner = inner_lateral + inner_top_down\n",
    "            last_inner = extra_block(last_inner)  # Extra processing\n",
    "            results.insert(0, layer_block(last_inner))\n",
    "\n",
    "        return results\n",
    "\n",
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        super(AttentionBlock, self).__init__()\n",
    "        self.W_g = Conv2DBlock(F_g, F_int, kernel_size=1, padding=0)\n",
    "        self.W_x = Conv2DBlock(F_l, F_int, kernel_size=1, padding=0)\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.residual = Conv2DBlock(F_g, F_l, kernel_size=1, padding=0)\n",
    "\n",
    "    def forward(self, g, x):\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        \n",
    "        if g1.shape[2:] != x1.shape[2:]:\n",
    "            g1 = F.interpolate(g1, size=x1.shape[2:], mode='bilinear', align_corners=False)\n",
    "        \n",
    "        psi = self.relu(g1 + x1)\n",
    "        psi = self.psi(psi)\n",
    "        out = x * psi\n",
    "        out = self.residual(out)\n",
    "        return out + x\n",
    "\n",
    "\n",
    "class ASPP(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ASPP, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 1, bias=False)\n",
    "        self.conv2 = nn.Conv2d(in_channels, out_channels, 3, padding=6, dilation=6, bias=False)\n",
    "        self.conv3 = nn.Conv2d(in_channels, out_channels, 3, padding=12, dilation=12, bias=False)\n",
    "        self.conv4 = nn.Conv2d(in_channels, out_channels, 3, padding=18, dilation=18, bias=False)\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.conv5 = nn.Conv2d(in_channels, out_channels, 1, bias=False)\n",
    "        self.conv_out = nn.Conv2d(5 * out_channels, out_channels, 1, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat1 = self.conv1(x)\n",
    "        feat2 = self.conv2(x)\n",
    "        feat3 = self.conv3(x)\n",
    "        feat4 = self.conv4(x)\n",
    "        feat5 = self.conv5(self.pool(x))\n",
    "        feat5 = nn.functional.interpolate(feat5, size=x.shape[2:], mode='bilinear', align_corners=False)\n",
    "        out = torch.cat((feat1, feat2, feat3, feat4, feat5), dim=1)\n",
    "        out = self.conv_out(out)\n",
    "        out = self.bn(out)\n",
    "        return self.relu(out)\n",
    "class GlobalContextBlock(nn.Module):\n",
    "    def __init__(self, inplanes, planes, pooling_type='att'):\n",
    "        super(GlobalContextBlock, self).__init__()\n",
    "        self.inplanes = inplanes\n",
    "        self.planes = planes\n",
    "        self.pooling_type = pooling_type\n",
    "\n",
    "        if pooling_type == 'att':\n",
    "            self.conv_mask = nn.Conv2d(inplanes, 1, kernel_size=1)\n",
    "            self.softmax = nn.Softmax(dim=2)\n",
    "        else:\n",
    "            self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        self.conv_in = nn.Conv2d(inplanes, planes, kernel_size=1)\n",
    "        self.conv_out = nn.Conv2d(planes, inplanes, kernel_size=1)\n",
    "        \n",
    "        # Replace BatchNorm with LayerNorm\n",
    "        self.ln_in = nn.LayerNorm([planes, 1, 1])\n",
    "        self.ln_out = nn.LayerNorm([inplanes, 1, 1])\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def spatial_pool(self, x):\n",
    "        batch, channel, height, width = x.size()\n",
    "        if self.pooling_type == 'att':\n",
    "            input_x = x\n",
    "            input_x = input_x.view(batch, channel, height * width)\n",
    "            input_x = input_x.unsqueeze(1)\n",
    "            context_mask = self.conv_mask(x)\n",
    "            context_mask = context_mask.view(batch, 1, height * width)\n",
    "            context_mask = self.softmax(context_mask)\n",
    "            context_mask = context_mask.unsqueeze(-1)\n",
    "            context = torch.matmul(input_x, context_mask)\n",
    "            context = context.view(batch, channel, 1, 1)\n",
    "        else:\n",
    "            context = self.avg_pool(x)\n",
    "\n",
    "        return context\n",
    "\n",
    "    def forward(self, x):\n",
    "        context = self.spatial_pool(x)\n",
    "        out = self.conv_in(context)\n",
    "        out = self.ln_in(out)  # Use LayerNorm instead of BatchNorm\n",
    "        out = self.relu(out)\n",
    "        out = self.conv_out(out)\n",
    "        out = self.ln_out(out)  # Use LayerNorm instead of BatchNorm\n",
    "        \n",
    "        return x * out.expand_as(x)\n",
    "\n",
    "class ImprovedDecoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dropout_rate=0.2):\n",
    "        super(ImprovedDecoder, self).__init__()\n",
    "        self.aspp = ASPP(in_channels, 256)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        # Enhanced conv blocks with residual connections\n",
    "        self.conv_blocks = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                self._make_dense_block(256 + in_channels, 128),\n",
    "                SEBlock(128),\n",
    "                self.dropout\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                self._make_dense_block(128 + in_channels, 64),\n",
    "                SEBlock(64),\n",
    "                self.dropout\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                self._make_dense_block(64 + in_channels, 32),\n",
    "                SEBlock(32),\n",
    "                self.dropout\n",
    "            ),\n",
    "        ])\n",
    "        \n",
    "        # Additional processing path\n",
    "        self.extra_processing = nn.ModuleList([\n",
    "            Conv2DBlock(128, 128),\n",
    "            Conv2DBlock(64, 64),\n",
    "            Conv2DBlock(32, 32),\n",
    "        ])\n",
    "        \n",
    "        self.final_conv = nn.Sequential(\n",
    "            Conv2DBlock(32, 32),\n",
    "            nn.Conv2d(32, out_channels, kernel_size=1)\n",
    "        )\n",
    "        self.final_upsample = nn.Upsample(scale_factor=8, mode='bilinear', align_corners=False)\n",
    "\n",
    "    def _make_dense_block(self, in_ch, out_ch):\n",
    "        return nn.Sequential(\n",
    "            Conv2DBlock(in_ch, out_ch),\n",
    "            Conv2DBlock(out_ch, out_ch),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, features):\n",
    "        x = self.aspp(features[-1])\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        for i, (feature, conv, extra) in enumerate(zip(\n",
    "            features[-2::-1], \n",
    "            self.conv_blocks, \n",
    "            self.extra_processing\n",
    "        )):\n",
    "            x = F.interpolate(x, size=feature.shape[2:], mode='bilinear', align_corners=False)\n",
    "            x = torch.cat([x, feature], dim=1)\n",
    "            x = conv(x)\n",
    "            x = x + extra(x)  # Residual connection with extra processing\n",
    "        \n",
    "        x = self.final_conv(x)\n",
    "        x = self.final_upsample(x)\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39c33f78-2d6d-4b39-826b-5ba8892a7c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnifiedImprovedCellSwin(nn.Module):\n",
    "    def __init__(self, num_nuclei_classes=6, input_channels=3):\n",
    "        super(UnifiedImprovedCellSwin, self).__init__()\n",
    "        self.encoder = SwinEncoder(pretrained=True)\n",
    "        \n",
    "        # Modify first conv layer for flexible input channels\n",
    "        original_weight = self.encoder.swin.features[0][0].weight\n",
    "        self.encoder.swin.features[0][0] = nn.Conv2d(input_channels, 128, kernel_size=(4, 4), stride=(4, 4))\n",
    "        if input_channels <= 3:  # For 2 or 3 channel input\n",
    "            with torch.no_grad():\n",
    "                self.encoder.swin.features[0][0].weight = nn.Parameter(\n",
    "                    original_weight[:, :input_channels, :, :].clone()\n",
    "                )\n",
    "        \n",
    "        # Feature Pyramid Network\n",
    "        self.fpn = FeaturePyramidNetwork(\n",
    "            in_channels_list=[256, 512, 1024, 1024],\n",
    "            out_channels=256\n",
    "        )\n",
    "        \n",
    "        # Multiple decoders for different tasks\n",
    "        self.cell_binary_decoder = ImprovedDecoder(256, 2)  # [background, cell]\n",
    "        self.nuclei_binary_decoder = ImprovedDecoder(256, 2)  # [background, nucleus]\n",
    "        self.cell_hv_decoder = ImprovedDecoder(256, 2)  # Horizontal/Vertical maps for cells\n",
    "        self.nuclei_hv_decoder = ImprovedDecoder(256, 2)  # Horizontal/Vertical maps for nuclei\n",
    "        self.nuclei_type_decoder = ImprovedDecoder(256, num_nuclei_classes)  # Nuclei classification\n",
    "        \n",
    "        # Global context for feature enhancement\n",
    "        self.global_context = nn.Sequential(\n",
    "            GlobalContextBlock(1024, 256),\n",
    "            SEBlock(1024)\n",
    "        )\n",
    "        \n",
    "        # Tissue classifier\n",
    "        self.tissue_classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LayerNorm(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LayerNorm(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, num_nuclei_classes)\n",
    "        )\n",
    "        \n",
    "        self.num_nuclei_classes = num_nuclei_classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder features\n",
    "        features = self.encoder(x)\n",
    "        \n",
    "        # FPN features\n",
    "        fpn_features = self.fpn(features)\n",
    "        \n",
    "        # Global context\n",
    "        global_feature = self.global_context(features[-1])\n",
    "        \n",
    "        # Task-specific outputs\n",
    "        cell_binary = self.cell_binary_decoder(fpn_features)\n",
    "        nuclei_binary = self.nuclei_binary_decoder(fpn_features)\n",
    "        cell_hv = self.cell_hv_decoder(fpn_features)\n",
    "        nuclei_hv = self.nuclei_hv_decoder(fpn_features)\n",
    "        nuclei_types = self.nuclei_type_decoder(fpn_features)\n",
    "        tissue_types = self.tissue_classifier(global_feature)\n",
    "\n",
    "        out_dict = {\n",
    "            # Cell-level outputs\n",
    "            \"cell_binary_map\": cell_binary,  # [B, 2, H, W]\n",
    "            \"cell_hv_map\": cell_hv,  # [B, 2, H, W]\n",
    "            \n",
    "            # Nuclei-level outputs\n",
    "            \"nuclei_binary_map\": nuclei_binary,  # [B, 2, H, W]\n",
    "            \"nuclei_hv_map\": nuclei_hv,  # [B, 2, H, W]\n",
    "            \"nuclei_type_map\": nuclei_types,  # [B, num_nuclei_classes, H, W]\n",
    "            \n",
    "            # Tissue-level output\n",
    "            \"tissue_types\": tissue_types  # [B, num_nuclei_classes]\n",
    "        }\n",
    "\n",
    "        return out_dict\n",
    "    \n",
    "    def calculate_instance_map(self, predictions, magnification=40):\n",
    "        \"\"\"Post-processing to get instance segmentation maps\"\"\"\n",
    "        # Implementation as in your original code\n",
    "        predictions_ = predictions.copy()\n",
    "        predictions_[\"nuclei_type_map\"] = predictions_[\"nuclei_type_map\"].permute(0, 2, 3, 1)\n",
    "        predictions_[\"nuclei_binary_map\"] = predictions_[\"nuclei_binary_map\"].permute(0, 2, 3, 1)\n",
    "        predictions_[\"nuclei_hv_map\"] = predictions_[\"nuclei_hv_map\"].permute(0, 2, 3, 1)\n",
    "\n",
    "        instance_preds = []\n",
    "        type_preds = []\n",
    "\n",
    "        # Process each image in batch\n",
    "        for i in range(predictions_[\"nuclei_binary_map\"].shape[0]):\n",
    "            pred_map = np.concatenate([\n",
    "                torch.argmax(predictions_[\"nuclei_type_map\"], dim=-1)[i].detach().cpu()[..., None],\n",
    "                torch.argmax(predictions_[\"nuclei_binary_map\"], dim=-1)[i].detach().cpu()[..., None],\n",
    "                predictions_[\"nuclei_hv_map\"][i].detach().cpu(),\n",
    "            ], axis=-1)\n",
    "            \n",
    "            # You'll need to implement DetectionCellPostProcessor\n",
    "            instance_pred = self.post_process_cell_segmentation(pred_map)\n",
    "            instance_preds.append(instance_pred[0])\n",
    "            type_preds.append(instance_pred[1])\n",
    "\n",
    "        return torch.Tensor(np.stack(instance_preds)), type_preds\n",
    "\n",
    "    def freeze_encoder(self):\n",
    "        \"\"\"Freeze encoder parameters\"\"\"\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def unfreeze_encoder(self):\n",
    "        \"\"\"Unfreeze encoder parameters\"\"\"\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21071573-418a-4b1c-9533-61a00cff7a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/swin_v2_b-781e5279.pth\" to /home/yshokrollahi/.cache/torch/hub/checkpoints/swin_v2_b-781e5279.pth\n",
      "100%|██████████| 336M/336M [00:06<00:00, 51.9MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell_binary_map: torch.Size([1, 2, 256, 256])\n",
      "cell_hv_map: torch.Size([1, 2, 256, 256])\n",
      "nuclei_binary_map: torch.Size([1, 2, 256, 256])\n",
      "nuclei_hv_map: torch.Size([1, 2, 256, 256])\n",
      "nuclei_type_map: torch.Size([1, 6, 256, 256])\n",
      "tissue_types: torch.Size([1, 6])\n"
     ]
    }
   ],
   "source": [
    "# For MIF (2-channel input)\n",
    "mif_model = UnifiedImprovedCellSwin(input_channels=2)\n",
    "mif_input = torch.randn(1, 2, 256, 256)\n",
    "mif_output = mif_model(mif_input)\n",
    "\n",
    "# For H&E (3-channel input)\n",
    "he_model = UnifiedImprovedCellSwin(input_channels=3)\n",
    "he_input = torch.randn(1, 3, 256, 256)\n",
    "he_output = he_model(he_input)\n",
    "\n",
    "# Check outputs\n",
    "for key, value in mif_output.items():\n",
    "    print(f\"{key}: {value.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "533cfe46-23d0-43f4-ae9f-5b101b3ee4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/init.py:412: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing MIF input:\n",
      "cell_binary_map: torch.Size([1, 2, 256, 256])\n",
      "cell_hv_map: torch.Size([1, 2, 256, 256])\n",
      "nuclei_binary_map: torch.Size([1, 2, 256, 256])\n",
      "nuclei_hv_map: torch.Size([1, 2, 256, 256])\n",
      "nuclei_type_map: torch.Size([1, 6, 256, 256])\n",
      "tissue_types: torch.Size([1, 6])\n",
      "gates: torch.Size([1, 2])\n",
      "\n",
      "Testing H&E input:\n",
      "cell_binary_map: torch.Size([1, 2, 256, 256])\n",
      "cell_hv_map: torch.Size([1, 2, 256, 256])\n",
      "nuclei_binary_map: torch.Size([1, 2, 256, 256])\n",
      "nuclei_hv_map: torch.Size([1, 2, 256, 256])\n",
      "nuclei_type_map: torch.Size([1, 6, 256, 256])\n",
      "tissue_types: torch.Size([1, 6])\n",
      "gates: torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "class MultiModalGatingNetwork(nn.Module):\n",
    "    def __init__(self, feature_dim=128):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Feature extractors for each modality\n",
    "        self.mif_feature_extractor = nn.Sequential(\n",
    "            Conv2DBlock(2, 64),  # MIF has 2 channels\n",
    "            SEBlock(64),\n",
    "            Conv2DBlock(64, feature_dim),\n",
    "            SEBlock(feature_dim)\n",
    "        )\n",
    "        \n",
    "        self.he_feature_extractor = nn.Sequential(\n",
    "            Conv2DBlock(3, 64),  # H&E has 3 channels\n",
    "            SEBlock(64),\n",
    "            Conv2DBlock(64, feature_dim),\n",
    "            SEBlock(feature_dim)\n",
    "        )\n",
    "        \n",
    "        # Global context for better feature representation\n",
    "        self.global_context = GlobalContextBlock(feature_dim, feature_dim//2)\n",
    "        \n",
    "        # Dynamic gating mechanism\n",
    "        self.gate_generator = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(feature_dim, feature_dim//2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(feature_dim//2, 2),  # 2 gates for 2 modalities\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, modality_type):\n",
    "        if modality_type == 'mif':\n",
    "            features = self.mif_feature_extractor(x)\n",
    "        else:  # he\n",
    "            features = self.he_feature_extractor(x)\n",
    "            \n",
    "        # Apply global context\n",
    "        features = self.global_context(features)\n",
    "        \n",
    "        # Generate gating weights\n",
    "        gates = self.gate_generator(features)\n",
    "        \n",
    "        return features, gates\n",
    "\n",
    "class MultiModalExpertNetwork(nn.Module):\n",
    "    def __init__(self, num_nuclei_classes=6):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Gating network\n",
    "        self.gating_network = MultiModalGatingNetwork()\n",
    "        \n",
    "        # Expert networks for each modality\n",
    "        self.mif_expert = UnifiedImprovedCellSwin(num_nuclei_classes=num_nuclei_classes, \n",
    "                                                 input_channels=2)  # MIF expert\n",
    "        self.he_expert = UnifiedImprovedCellSwin(num_nuclei_classes=num_nuclei_classes, \n",
    "                                                input_channels=3)   # H&E expert\n",
    "        \n",
    "        # Output fusion layers\n",
    "        self.fusion_layers = nn.ModuleDict({\n",
    "            'binary_fusion': nn.Sequential(\n",
    "                Conv2DBlock(4, 2),  # Combine binary maps\n",
    "                SEBlock(2)\n",
    "            ),\n",
    "            'hv_fusion': nn.Sequential(\n",
    "                Conv2DBlock(4, 2),  # Combine HV maps\n",
    "                SEBlock(2)\n",
    "            ),\n",
    "            'type_fusion': nn.Sequential(\n",
    "                Conv2DBlock(num_nuclei_classes * 2, num_nuclei_classes),  # Combine type predictions\n",
    "                SEBlock(num_nuclei_classes)\n",
    "            )\n",
    "        })\n",
    "\n",
    "    def forward(self, x, modality_type):\n",
    "        # Get gating weights\n",
    "        features, gates = self.gating_network(x, modality_type)\n",
    "        \n",
    "        if modality_type == 'mif':\n",
    "            # MIF expert prediction\n",
    "            mif_output = self.mif_expert(x)\n",
    "            expert_output = mif_output\n",
    "        else:\n",
    "            # H&E expert prediction\n",
    "            he_output = self.he_expert(x)\n",
    "            expert_output = he_output\n",
    "\n",
    "        # Apply gating weights\n",
    "        gated_output = {}\n",
    "        for key, value in expert_output.items():\n",
    "            if isinstance(value, torch.Tensor):\n",
    "                if key == 'tissue_types':\n",
    "                    gated_output[key] = value  # Don't apply gating to tissue types\n",
    "                else:\n",
    "                    # Apply respective gate weight\n",
    "                    gate_weight = gates[:, 0] if modality_type == 'mif' else gates[:, 1]\n",
    "                    gated_output[key] = value * gate_weight.view(-1, 1, 1, 1)\n",
    "\n",
    "        # Add gates to output for monitoring\n",
    "        gated_output['gates'] = gates\n",
    "        \n",
    "        return gated_output\n",
    "\n",
    "    def freeze_experts(self):\n",
    "        \"\"\"Freeze both expert networks\"\"\"\n",
    "        for param in self.mif_expert.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.he_expert.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    def unfreeze_experts(self):\n",
    "        \"\"\"Unfreeze both expert networks\"\"\"\n",
    "        for param in self.mif_expert.parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in self.he_expert.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "# Test the multi-modal network\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize model\n",
    "    model = MultiModalExpertNetwork().cuda()\n",
    "    \n",
    "    # Test MIF input\n",
    "    mif_input = torch.randn(1, 2, 256, 256).cuda()\n",
    "    print(\"\\nTesting MIF input:\")\n",
    "    mif_output = model(mif_input, 'mif')\n",
    "    for key, value in mif_output.items():\n",
    "        if isinstance(value, torch.Tensor):\n",
    "            print(f\"{key}: {value.shape}\")\n",
    "    \n",
    "    # Test H&E input\n",
    "    he_input = torch.randn(1, 3, 256, 256).cuda()\n",
    "    print(\"\\nTesting H&E input:\")\n",
    "    he_output = model(he_input, 'he')\n",
    "    for key, value in he_output.items():\n",
    "        if isinstance(value, torch.Tensor):\n",
    "            print(f\"{key}: {value.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3044932-b7f0-490f-8d41-14b2d24cd23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Successfully loaded configuration files\n",
      "\n",
      "Setting up TissueNet datasets...\n",
      "Created train dataset with 10320 samples\n",
      "Created val dataset with 3118 samples\n",
      "Created test dataset with 1324 samples\n",
      "\n",
      "Setting up PanNuke datasets...\n",
      "Created train dataset with 5179 samples\n",
      "Created val dataset with 2722 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/init.py:412: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 262\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 262\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 236\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 236\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    237\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m validate(model, val_loader, criterion, device)\n\u001b[1;32m    239\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep(val_loss)\n",
      "Cell \u001b[0;32mIn[15], line 128\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, train_loader, optimizer, criterion, device)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;66;03m# Process MIF data\u001b[39;00m\n\u001b[1;32m    126\u001b[0m     mif_data \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmif\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    127\u001b[0m     mif_targets \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m--> 128\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcell_binary_map\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmif\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcell_mask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m(device),\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnuclei_binary_map\u001b[39m\u001b[38;5;124m'\u001b[39m: batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmif\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnuclei_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    130\u001b[0m     }\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;66;03m# Process H&E data\u001b[39;00m\n\u001b[1;32m    133\u001b[0m     he_data \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhe\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "class MultiModalLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.binary_loss = nn.CrossEntropyLoss()\n",
    "        self.hv_loss = nn.MSELoss()\n",
    "        self.type_loss = nn.CrossEntropyLoss()\n",
    "        self.tissue_loss = nn.CrossEntropyLoss()\n",
    "        self.gate_regularization = 0.1\n",
    "\n",
    "    def forward(self, predictions, targets, modality_type):\n",
    "        total_loss = 0\n",
    "        losses = {}\n",
    "        \n",
    "        # Process only available targets for each modality\n",
    "        if modality_type == 'mif':\n",
    "            if 'cell_binary_map' in predictions and 'cell_binary_map' in targets:\n",
    "                losses['cell_binary_loss'] = self.binary_loss(\n",
    "                    predictions['cell_binary_map'],\n",
    "                    targets['cell_binary_map'].long()  # Ensure target is long type\n",
    "                )\n",
    "                total_loss += losses['cell_binary_loss']\n",
    "            \n",
    "            if 'cell_hv_map' in predictions and 'cell_hv_map' in targets:\n",
    "                losses['cell_hv_loss'] = self.hv_loss(\n",
    "                    predictions['cell_hv_map'],\n",
    "                    targets['cell_hv_map']\n",
    "                )\n",
    "                total_loss += losses['cell_hv_loss']\n",
    "        \n",
    "        # Common losses for both modalities\n",
    "        if 'nuclei_binary_map' in predictions and 'nuclei_binary_map' in targets:\n",
    "            losses['nuclei_binary_loss'] = self.binary_loss(\n",
    "                predictions['nuclei_binary_map'],\n",
    "                targets['nuclei_binary_map'].long()\n",
    "            )\n",
    "            total_loss += losses['nuclei_binary_loss']\n",
    "        \n",
    "        if 'nuclei_hv_map' in predictions and 'nuclei_hv_map' in targets:\n",
    "            losses['nuclei_hv_loss'] = self.hv_loss(\n",
    "                predictions['nuclei_hv_map'],\n",
    "                targets['nuclei_hv_map']\n",
    "            )\n",
    "            total_loss += losses['nuclei_hv_loss']\n",
    "        \n",
    "        # H&E specific losses\n",
    "        if modality_type == 'he':\n",
    "            if 'nuclei_type_map' in predictions and 'nuclei_type_map' in targets:\n",
    "                losses['type_loss'] = self.type_loss(\n",
    "                    predictions['nuclei_type_map'],\n",
    "                    targets['nuclei_type_map'].long()\n",
    "                )\n",
    "                total_loss += losses['type_loss']\n",
    "            \n",
    "            if 'tissue_types' in predictions and 'tissue_types' in targets:\n",
    "                losses['tissue_loss'] = self.tissue_loss(\n",
    "                    predictions['tissue_types'],\n",
    "                    targets['tissue_types'].long()\n",
    "                )\n",
    "                total_loss += losses['tissue_loss']\n",
    "        \n",
    "        if 'gates' in predictions:\n",
    "            gates = predictions['gates']\n",
    "            losses['gate_loss'] = self.gate_regularization * torch.mean(\n",
    "                (gates - 0.5) ** 2\n",
    "            )\n",
    "            total_loss += losses['gate_loss']\n",
    "        \n",
    "        return total_loss, losses\n",
    "\n",
    "class CombinedDataLoader:\n",
    "    def __init__(self, mif_loader, he_loader):\n",
    "        self.mif_loader = mif_loader\n",
    "        self.he_loader = he_loader\n",
    "        self.mif_iterator = iter(self.mif_loader)\n",
    "        self.he_iterator = iter(self.he_loader)\n",
    "        self.length = min(len(self.mif_loader), len(self.he_loader))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.mif_iterator = iter(self.mif_loader)\n",
    "        self.he_iterator = iter(self.he_loader)\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        try:\n",
    "            mif_batch = next(self.mif_iterator)  # List of length 3\n",
    "        except StopIteration:\n",
    "            self.mif_iterator = iter(self.mif_loader)\n",
    "            mif_batch = next(self.mif_iterator)\n",
    "\n",
    "        try:\n",
    "            he_batch = next(self.he_iterator)  # List of length 4\n",
    "        except StopIteration:\n",
    "            self.he_iterator = iter(self.he_loader)\n",
    "            he_batch = next(self.he_iterator)\n",
    "\n",
    "        return {\n",
    "            'mif': {\n",
    "                'image': mif_batch[0],          # Input image\n",
    "                'cell_mask': mif_batch[1],      # Cell mask\n",
    "                'nuclei_mask': mif_batch[2],    # Nuclei mask\n",
    "            },\n",
    "            'he': {\n",
    "                'image': he_batch[0],           # Input image\n",
    "                'nuclei_mask': he_batch[1],     # Nuclei mask\n",
    "                'type_map': he_batch[2],        # Type map\n",
    "                'tissue_type': he_batch[3]      # Tissue type\n",
    "            }\n",
    "        }\n",
    "\n",
    "def train_epoch(model, train_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        # Process MIF data\n",
    "        mif_data = batch['mif']['image'].to(device)\n",
    "        mif_targets = {\n",
    "            'cell_binary_map': batch['mif']['cell_mask'].to(device),\n",
    "            'nuclei_binary_map': batch['mif']['nuclei_mask'].to(device)\n",
    "        }\n",
    "        \n",
    "        # Process H&E data\n",
    "        he_data = batch['he']['image'].to(device)\n",
    "        he_targets = {\n",
    "            'nuclei_binary_map': batch['he']['nuclei_mask'].to(device),\n",
    "            'nuclei_type_map': batch['he']['type_map'].to(device),\n",
    "            'tissue_types': batch['he']['tissue_type'].to(device)\n",
    "        }\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward passes\n",
    "        mif_output = model(mif_data, 'mif')\n",
    "        he_output = model(he_data, 'he')\n",
    "        \n",
    "        # Calculate losses\n",
    "        mif_loss, mif_losses = criterion(mif_output, mif_targets, 'mif')\n",
    "        he_loss, he_losses = criterion(he_output, he_targets, 'he')\n",
    "        \n",
    "        loss = mif_loss + he_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f'Batch [{batch_idx}/{len(train_loader)}], '\n",
    "                  f'Loss: {loss.item():.4f}, '\n",
    "                  f'MIF Loss: {mif_loss.item():.4f}, '\n",
    "                  f'H&E Loss: {he_loss.item():.4f}')\n",
    "    \n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            # Process MIF data\n",
    "            mif_data = batch['mif']['image'].to(device)\n",
    "            mif_targets = {\n",
    "                'cell_binary_map': batch['mif']['cell_mask'].to(device),\n",
    "                'nuclei_binary_map': batch['mif']['nuclei_mask'].to(device)\n",
    "            }\n",
    "            \n",
    "            # Process H&E data\n",
    "            he_data = batch['he']['image'].to(device)\n",
    "            he_targets = {\n",
    "                'nuclei_binary_map': batch['he']['nuclei_mask'].to(device),\n",
    "                'nuclei_type_map': batch['he']['type_map'].to(device),\n",
    "                'tissue_types': batch['he']['tissue_type'].to(device)\n",
    "            }\n",
    "            \n",
    "            mif_output = model(mif_data, 'mif')\n",
    "            he_output = model(he_data, 'he')\n",
    "            \n",
    "            mif_loss, _ = criterion(mif_output, mif_targets, 'mif')\n",
    "            he_loss, _ = criterion(he_output, he_targets, 'he')\n",
    "            \n",
    "            total_loss += (mif_loss + he_loss).item()\n",
    "    \n",
    "    return total_loss / len(val_loader)\n",
    "\n",
    "def main():\n",
    "    # Setup device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Initialize dataset manager\n",
    "    data_manager = MultiModalDatasetManager()\n",
    "    \n",
    "    # Setup datasets and dataloaders\n",
    "    tissuenet_datasets, tissuenet_loaders = data_manager.setup_tissuenet()\n",
    "    pannuke_datasets, pannuke_loaders = data_manager.setup_pannuke()\n",
    "    \n",
    "    # Create combined loaders\n",
    "    train_loader = CombinedDataLoader(\n",
    "        tissuenet_loaders['train'],\n",
    "        pannuke_loaders['train']\n",
    "    )\n",
    "    val_loader = CombinedDataLoader(\n",
    "        tissuenet_loaders['val'],\n",
    "        pannuke_loaders['val']\n",
    "    )\n",
    "    \n",
    "    # Initialize model\n",
    "    model = MultiModalExpertNetwork().to(device)\n",
    "    \n",
    "    # Setup training\n",
    "    criterion = MultiModalLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
    "    )\n",
    "    \n",
    "    num_epochs = 100\n",
    "    best_val_loss = float('inf')\n",
    "    save_dir = Path('./checkpoints')\n",
    "    save_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
    "        \n",
    "        train_loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        val_loss = validate(model, val_loader, criterion, device)\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        print(f'Training Loss: {train_loss:.4f}')\n",
    "        print(f'Validation Loss: {val_loss:.4f}')\n",
    "        \n",
    "        # Save checkpoint\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            checkpoint_path = save_dir / 'best_model.pth'\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'best_val_loss': best_val_loss,\n",
    "            }, checkpoint_path)\n",
    "            print(f'Saved best model to {checkpoint_path}')\n",
    "        \n",
    "        # Early stopping\n",
    "        if optimizer.param_groups[0]['lr'] < 1e-6:\n",
    "            print('Learning rate too small. Stopping training.')\n",
    "            break\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2f4079a-f9e5-4afc-ab49-4da0d29a5c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded configuration files\n",
      "\n",
      "Setting up TissueNet datasets...\n",
      "Created train dataset with 10320 samples\n",
      "Created val dataset with 3118 samples\n",
      "Created test dataset with 1324 samples\n",
      "\n",
      "Setting up PanNuke datasets...\n",
      "Created train dataset with 5179 samples\n",
      "Created val dataset with 2722 samples\n",
      "\n",
      "Inspecting TissueNet (MIF) batch:\n",
      "MIF batch type: <class 'list'>\n",
      "MIF batch length: 3\n",
      "MIF first element type: <class 'torch.Tensor'>\n",
      "MIF first element shape: torch.Size([16, 2, 256, 256])\n",
      "\n",
      "Inspecting PanNuke (H&E) batch:\n",
      "H&E batch type: <class 'list'>\n",
      "H&E batch length: 4\n",
      "H&E first element type: <class 'torch.Tensor'>\n",
      "H&E first element shape: torch.Size([16, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "# Debug dataset outputs\n",
    "def inspect_dataloaders(tissuenet_loader, pannuke_loader):\n",
    "    print(\"\\nInspecting TissueNet (MIF) batch:\")\n",
    "    mif_batch = next(iter(tissuenet_loader))\n",
    "    print(\"MIF batch type:\", type(mif_batch))\n",
    "    if isinstance(mif_batch, (list, tuple)):\n",
    "        print(\"MIF batch length:\", len(mif_batch))\n",
    "        print(\"MIF first element type:\", type(mif_batch[0]))\n",
    "        print(\"MIF first element shape:\", mif_batch[0].shape if torch.is_tensor(mif_batch[0]) else \"Not a tensor\")\n",
    "    elif isinstance(mif_batch, dict):\n",
    "        print(\"MIF batch keys:\", mif_batch.keys())\n",
    "        for k, v in mif_batch.items():\n",
    "            print(f\"Key: {k}, Type: {type(v)}, Shape: {v.shape if torch.is_tensor(v) else 'Not a tensor'}\")\n",
    "    \n",
    "    print(\"\\nInspecting PanNuke (H&E) batch:\")\n",
    "    he_batch = next(iter(pannuke_loader))\n",
    "    print(\"H&E batch type:\", type(he_batch))\n",
    "    if isinstance(he_batch, (list, tuple)):\n",
    "        print(\"H&E batch length:\", len(he_batch))\n",
    "        print(\"H&E first element type:\", type(he_batch[0]))\n",
    "        print(\"H&E first element shape:\", he_batch[0].shape if torch.is_tensor(he_batch[0]) else \"Not a tensor\")\n",
    "    elif isinstance(he_batch, dict):\n",
    "        print(\"H&E batch keys:\", he_batch.keys())\n",
    "        for k, v in he_batch.items():\n",
    "            print(f\"Key: {k}, Type: {type(v)}, Shape: {v.shape if torch.is_tensor(v) else 'Not a tensor'}\")\n",
    "\n",
    "# In your main function:\n",
    "data_manager = MultiModalDatasetManager()\n",
    "tissuenet_datasets, tissuenet_loaders = data_manager.setup_tissuenet()\n",
    "pannuke_datasets, pannuke_loaders = data_manager.setup_pannuke()\n",
    "\n",
    "inspect_dataloaders(tissuenet_loaders['train'], pannuke_loaders['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a1d490-5aa4-4731-95b6-15821f0d43ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yshokrollahi",
   "language": "python",
   "name": "yshokrollahi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
