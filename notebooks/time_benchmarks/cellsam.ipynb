{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de08a410-7980-4fff-99f6-bc05ec02336a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Install CellSAM\n",
    "# # !pip install git+https://github.com/vanvalenlab/cellSAM.git\n",
    "# # Alternative installation with all dependencies\n",
    "# !pip install torch torchvision  # Make sure PyTorch is installed first\n",
    "# !pip install git+https://github.com/vanvalenlab/cellSAM.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e8b397b-bf54-4bb6-b081-2fceb6bd404c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Working directory: /rsrch9/home/plm/idso_fa1_pathology/codes/yshokrollahi/vitamin-p-latest\n",
      "‚úÖ Using GPU: 2\n"
     ]
    }
   ],
   "source": [
    "# ALWAYS RUN THIS FIRST!\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Specify GPU 0 (out of 4 available GPUs)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "NOTEBOOK_DIR = Path(\"/rsrch9/home/plm/idso_fa1_pathology/codes/yshokrollahi/vitamin-p-latest\")\n",
    "os.chdir(NOTEBOOK_DIR)\n",
    "sys.path.insert(0, str(NOTEBOOK_DIR))\n",
    "print(f\"‚úÖ Working directory: {os.getcwd()}\")\n",
    "print(f\"‚úÖ Using GPU: {os.environ.get('CUDA_VISIBLE_DEVICES', 'Not set')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "599f35da-8de2-4a97-a0c6-d58bcef4d07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available functions in cellSAM:\n",
      "['AnchorDETR', 'CellSAM', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', '_auth', 'cellsam_pipeline', 'download_training_data', 'get_local_model', 'get_model', 'model', 'sam_inference', 'segment_cellular_image', 'utils', 'wsi']\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Check what's available in cellSAM\n",
    "import cellSAM\n",
    "print(\"Available functions in cellSAM:\")\n",
    "print(dir(cellSAM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "853b46c0-baee-4edd-843a-1e2c922100ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CellSAM model...\n",
      "Model loaded successfully!\n",
      "Image shape: (512, 512, 3)\n",
      "Image dtype: uint8\n",
      "Running segmentation...\n",
      "Mask shape: (512, 512)\n",
      "Segmentation complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from cellSAM import get_model, segment_cellular_image\n",
    "\n",
    "# Step 1: Set the access token\n",
    "os.environ['DEEPCELL_ACCESS_TOKEN'] = 'JbVVUStF.A6Ec6pe5vKsoB3RhTnSOaqXJ1thDE3B6'\n",
    "\n",
    "# Step 2: Load the model (this will download it the first time)\n",
    "print(\"Loading CellSAM model...\")\n",
    "model = get_model(model='cellsam_general')\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# Step 3: Load your test image\n",
    "img = np.array(Image.open(\"test_images/prostate-he_chunk_12.png\"))\n",
    "print(f\"Image shape: {img.shape}\")\n",
    "print(f\"Image dtype: {img.dtype}\")\n",
    "\n",
    "# Step 4: Run segmentation\n",
    "print(\"Running segmentation...\")\n",
    "mask, _, _ = segment_cellular_image(img, model=model, device='cuda')\n",
    "\n",
    "print(f\"Mask shape: {mask.shape}\")\n",
    "print(\"Segmentation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da5ddd30-c2c8-49de-8683-f67f0843960a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import torch\n",
    "# import time\n",
    "# import pandas as pd\n",
    "# from PIL import Image\n",
    "# import matplotlib.pyplot as plt\n",
    "# from cellSAM import segment_cellular_image, CellSAM\n",
    "# from cellSAM.wsi import segment_wsi\n",
    "# import psutil\n",
    "# import gc\n",
    "# import json\n",
    "# import os\n",
    "# import tifffile\n",
    "# # ============================================\n",
    "# # SETUP OUTPUT DIRECTORY\n",
    "# # ============================================\n",
    "\n",
    "# OUTPUT_DIR = \"benchmark_results/cellsam\"\n",
    "# MASKS_DIR = os.path.join(OUTPUT_DIR, \"masks\")\n",
    "# os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "# os.makedirs(MASKS_DIR, exist_ok=True)\n",
    "\n",
    "# print(f\"üìÅ Output directory: {OUTPUT_DIR}\")\n",
    "# print(f\"   Masks will be saved to: {MASKS_DIR}\")\n",
    "\n",
    "# # ============================================\n",
    "# # METRIC EXTRACTION FUNCTIONS\n",
    "# # ============================================\n",
    "\n",
    "# def compute_segmentation_metrics(mask):\n",
    "#     \"\"\"Compute detailed segmentation statistics\"\"\"\n",
    "#     unique_labels = np.unique(mask)\n",
    "#     n_cells = len(unique_labels) - 1  # exclude background (0)\n",
    "    \n",
    "#     # Cell size statistics\n",
    "#     cell_sizes = []\n",
    "#     for label in unique_labels[1:]:  # skip background\n",
    "#         cell_sizes.append(np.sum(mask == label))\n",
    "    \n",
    "#     return {\n",
    "#         'n_cells': n_cells,\n",
    "#         'mean_cell_size': np.mean(cell_sizes) if cell_sizes else 0,\n",
    "#         'median_cell_size': np.median(cell_sizes) if cell_sizes else 0,\n",
    "#         'std_cell_size': np.std(cell_sizes) if cell_sizes else 0,\n",
    "#         'min_cell_size': np.min(cell_sizes) if cell_sizes else 0,\n",
    "#         'max_cell_size': np.max(cell_sizes) if cell_sizes else 0,\n",
    "#     }\n",
    "\n",
    "# def measure_gpu_memory():\n",
    "#     \"\"\"Measure current GPU memory usage\"\"\"\n",
    "#     if torch.cuda.is_available():\n",
    "#         return {\n",
    "#             'allocated_gb': torch.cuda.memory_allocated() / 1024**3,\n",
    "#             'reserved_gb': torch.cuda.memory_reserved() / 1024**3,\n",
    "#             'max_allocated_gb': torch.cuda.max_memory_allocated() / 1024**3,\n",
    "#         }\n",
    "#     return {'allocated_gb': 0, 'reserved_gb': 0, 'max_allocated_gb': 0}\n",
    "\n",
    "# def measure_cpu_memory():\n",
    "#     \"\"\"Measure current CPU memory usage\"\"\"\n",
    "#     process = psutil.Process()\n",
    "#     return process.memory_info().rss / 1024**3  # GB\n",
    "\n",
    "# def save_mask(mask, filepath):\n",
    "#     \"\"\"Save mask as TIFF\"\"\"\n",
    "#     Image.fromarray(mask.astype(np.uint16)).save(filepath)\n",
    "\n",
    "# # ============================================\n",
    "# # LOAD MODEL\n",
    "# # ============================================\n",
    "\n",
    "# print(\"\\n\" + \"=\" * 70)\n",
    "# print(\"Loading CellSAM model...\")\n",
    "# print(\"  ‚úì Model loaded\")\n",
    "\n",
    "# # Load test images\n",
    "# tile_512 = np.array(Image.open(\"test_images/ovarian-he_chunk_92.png\"))\n",
    "# wsi_5000 = tifffile.imread(\"test_images/breat_cancer_15000x15000.tiff\")\n",
    "\n",
    "# print(f\"Tile shape: {tile_512.shape}\")\n",
    "# print(f\"WSI shape: {wsi_5000.shape}\")\n",
    "\n",
    "# # ============================================\n",
    "# # 1. SINGLE-TASK BENCHMARK: Nuclei Only\n",
    "# # ============================================\n",
    "\n",
    "# print(\"\\n\" + \"=\" * 70)\n",
    "# print(\"CELLSAM BENCHMARK 1: SINGLE-TASK (Nuclei Only, 512√ó512)\")\n",
    "# print(\"=\" * 70)\n",
    "\n",
    "# torch.cuda.reset_peak_memory_stats()\n",
    "# torch.cuda.empty_cache()\n",
    "# gc.collect()\n",
    "\n",
    "# # Warmup\n",
    "# print(\"Warmup runs...\")\n",
    "# for _ in range(3):\n",
    "#     _ = segment_cellular_image(tile_512, model=model, device='cuda')\n",
    "\n",
    "# # Benchmark\n",
    "# n_runs = 10\n",
    "# times_nuclei = []\n",
    "# memory_nuclei = []\n",
    "# n_nuclei_list = []\n",
    "\n",
    "# print(f\"Running {n_runs} timed iterations...\")\n",
    "# for i in range(n_runs):\n",
    "#     torch.cuda.reset_peak_memory_stats()\n",
    "#     torch.cuda.synchronize()\n",
    "    \n",
    "#     start = time.time()\n",
    "#     mask_nuclei, _, _ = segment_cellular_image(tile_512, model=model, device='cuda')\n",
    "#     torch.cuda.synchronize()\n",
    "#     end = time.time()\n",
    "    \n",
    "#     times_nuclei.append(end - start)\n",
    "#     memory_nuclei.append(measure_gpu_memory()['max_allocated_gb'])\n",
    "    \n",
    "#     seg_metrics = compute_segmentation_metrics(mask_nuclei)\n",
    "#     n_nuclei_list.append(seg_metrics['n_cells'])\n",
    "    \n",
    "#     print(f\"  Run {i+1}/{n_runs}: {times_nuclei[-1]:.3f}s, {memory_nuclei[-1]:.2f} GB, Nuclei: {n_nuclei_list[-1]}\")\n",
    "\n",
    "# # Save mask from last run\n",
    "# print(\"Saving nuclei masks...\")\n",
    "# save_mask(mask_nuclei, os.path.join(MASKS_DIR, 'tile_512_nuclei.tif'))\n",
    "\n",
    "# results_nuclei = {\n",
    "#     'task': 'Nuclei Only',\n",
    "#     'image_size': '512√ó512',\n",
    "#     'n_instances': n_nuclei_list[-1],\n",
    "#     'mean_time_s': np.mean(times_nuclei),\n",
    "#     'std_time_s': np.std(times_nuclei),\n",
    "#     'mean_time_ms': np.mean(times_nuclei) * 1000,\n",
    "#     'peak_memory_gb': np.mean(memory_nuclei),\n",
    "#     'instances_per_second': n_nuclei_list[-1] / np.mean(times_nuclei),\n",
    "# }\n",
    "\n",
    "# print(\"\\nRESULTS:\")\n",
    "# for key, value in results_nuclei.items():\n",
    "#     if isinstance(value, float):\n",
    "#         print(f\"  {key}: {value:.4f}\")\n",
    "#     else:\n",
    "#         print(f\"  {key}: {value}\")\n",
    "\n",
    "# # ============================================\n",
    "# # 2. SINGLE-TASK BENCHMARK: Cells Only\n",
    "# # ============================================\n",
    "\n",
    "# print(\"\\n\" + \"=\" * 70)\n",
    "# print(\"CELLSAM BENCHMARK 2: SINGLE-TASK (Cells Only, 512√ó512)\")\n",
    "# print(\"=\" * 70)\n",
    "\n",
    "# torch.cuda.reset_peak_memory_stats()\n",
    "# torch.cuda.empty_cache()\n",
    "# gc.collect()\n",
    "\n",
    "# # Warmup\n",
    "# print(\"Warmup runs...\")\n",
    "# for _ in range(3):\n",
    "#     _ = segment_cellular_image(tile_512, model=model, device='cuda')\n",
    "\n",
    "# # Benchmark\n",
    "# times_cells = []\n",
    "# memory_cells = []\n",
    "# n_cells_list = []\n",
    "\n",
    "# print(f\"Running {n_runs} timed iterations...\")\n",
    "# for i in range(n_runs):\n",
    "#     torch.cuda.reset_peak_memory_stats()\n",
    "#     torch.cuda.synchronize()\n",
    "    \n",
    "#     start = time.time()\n",
    "#     mask_cells, _, _ = segment_cellular_image(tile_512, model=model, device='cuda')\n",
    "#     torch.cuda.synchronize()\n",
    "#     end = time.time()\n",
    "    \n",
    "#     times_cells.append(end - start)\n",
    "#     memory_cells.append(measure_gpu_memory()['max_allocated_gb'])\n",
    "    \n",
    "#     seg_metrics = compute_segmentation_metrics(mask_cells)\n",
    "#     n_cells_list.append(seg_metrics['n_cells'])\n",
    "    \n",
    "#     print(f\"  Run {i+1}/{n_runs}: {times_cells[-1]:.3f}s, {memory_cells[-1]:.2f} GB, Cells: {n_cells_list[-1]}\")\n",
    "\n",
    "# # Save mask from last run\n",
    "# print(\"Saving cell masks...\")\n",
    "# save_mask(mask_cells, os.path.join(MASKS_DIR, 'tile_512_cells.tif'))\n",
    "\n",
    "# results_cells = {\n",
    "#     'task': 'Cells Only',\n",
    "#     'image_size': '512√ó512',\n",
    "#     'n_instances': n_cells_list[-1],\n",
    "#     'mean_time_s': np.mean(times_cells),\n",
    "#     'std_time_s': np.std(times_cells),\n",
    "#     'mean_time_ms': np.mean(times_cells) * 1000,\n",
    "#     'peak_memory_gb': np.mean(memory_cells),\n",
    "#     'instances_per_second': n_cells_list[-1] / np.mean(times_cells),\n",
    "# }\n",
    "\n",
    "# print(\"\\nRESULTS:\")\n",
    "# for key, value in results_cells.items():\n",
    "#     if isinstance(value, float):\n",
    "#         print(f\"  {key}: {value:.4f}\")\n",
    "#     else:\n",
    "#         print(f\"  {key}: {value}\")\n",
    "\n",
    "# # ============================================\n",
    "# # 3. DUAL-TASK SIMULATION: Run Twice\n",
    "# # ============================================\n",
    "\n",
    "# print(\"\\n\" + \"=\" * 70)\n",
    "# print(\"‚≠ê CELLSAM BENCHMARK 3: DUAL-TASK SIMULATION (Run Twice, 512√ó512)\")\n",
    "# print(\"=\" * 70)\n",
    "# print(\"Note: CellSAM requires TWO separate runs for nuclei + cells\")\n",
    "\n",
    "# torch.cuda.reset_peak_memory_stats()\n",
    "# torch.cuda.empty_cache()\n",
    "# gc.collect()\n",
    "\n",
    "# # Warmup\n",
    "# print(\"Warmup runs...\")\n",
    "# for _ in range(3):\n",
    "#     # Run 1: Nuclei\n",
    "#     _ = segment_cellular_image(tile_512, model=model, device='cuda')\n",
    "#     # Run 2: Cells\n",
    "#     _ = segment_cellular_image(tile_512, model=model, device='cuda')\n",
    "\n",
    "# # Benchmark - Run TWICE per iteration\n",
    "# times_dual = []\n",
    "# memory_dual = []\n",
    "# n_nuclei_dual = []\n",
    "# n_cells_dual = []\n",
    "\n",
    "# print(f\"Running {n_runs} timed iterations (2 runs each)...\")\n",
    "# for i in range(n_runs):\n",
    "#     torch.cuda.reset_peak_memory_stats()\n",
    "#     torch.cuda.synchronize()\n",
    "    \n",
    "#     # RUN 1: Nuclei\n",
    "#     start = time.time()\n",
    "#     mask_n, _, _ = segment_cellular_image(tile_512, model=model, device='cuda')\n",
    "#     torch.cuda.synchronize()\n",
    "#     time_nuclei = time.time() - start\n",
    "    \n",
    "#     # RUN 2: Cells\n",
    "#     start = time.time()\n",
    "#     mask_c, _, _ = segment_cellular_image(tile_512, model=model, device='cuda')\n",
    "#     torch.cuda.synchronize()\n",
    "#     time_cells = time.time() - start\n",
    "    \n",
    "#     # Total time\n",
    "#     total_time = time_nuclei + time_cells\n",
    "#     times_dual.append(total_time)\n",
    "#     memory_dual.append(measure_gpu_memory()['max_allocated_gb'])\n",
    "    \n",
    "#     # Count instances\n",
    "#     seg_n = compute_segmentation_metrics(mask_n)\n",
    "#     seg_c = compute_segmentation_metrics(mask_c)\n",
    "#     n_nuclei_dual.append(seg_n['n_cells'])\n",
    "#     n_cells_dual.append(seg_c['n_cells'])\n",
    "    \n",
    "#     print(f\"  Run {i+1}/{n_runs}: {total_time:.3f}s ({time_nuclei:.3f}s + {time_cells:.3f}s), {memory_dual[-1]:.2f} GB, Nuclei: {n_nuclei_dual[-1]}, Cells: {n_cells_dual[-1]}\")\n",
    "\n",
    "# # Save masks from last run\n",
    "# print(\"Saving dual-task masks...\")\n",
    "# save_mask(mask_n, os.path.join(MASKS_DIR, 'tile_512_dual_nuclei.tif'))\n",
    "# save_mask(mask_c, os.path.join(MASKS_DIR, 'tile_512_dual_cells.tif'))\n",
    "\n",
    "# total_instances_dual = n_nuclei_dual[-1] + n_cells_dual[-1]\n",
    "# mean_time_dual = np.mean(times_dual)\n",
    "# mean_time_single = np.mean(times_nuclei)\n",
    "\n",
    "# results_dual = {\n",
    "#     'task': 'Nuclei + Cells (Sequential)',\n",
    "#     'image_size': '512√ó512',\n",
    "#     'n_nuclei': n_nuclei_dual[-1],\n",
    "#     'n_cells': n_cells_dual[-1],\n",
    "#     'total_instances': total_instances_dual,\n",
    "#     'mean_time_s': mean_time_dual,\n",
    "#     'std_time_s': np.std(times_dual),\n",
    "#     'mean_time_ms': mean_time_dual * 1000,\n",
    "#     'peak_memory_gb': np.mean(memory_dual),\n",
    "#     'instances_per_second': total_instances_dual / mean_time_dual,\n",
    "#     'overhead_vs_single_pct': ((mean_time_dual / mean_time_single) - 1) * 100,\n",
    "# }\n",
    "\n",
    "# print(\"\\nRESULTS:\")\n",
    "# for key, value in results_dual.items():\n",
    "#     if isinstance(value, float):\n",
    "#         print(f\"  {key}: {value:.4f}\")\n",
    "#     else:\n",
    "#         print(f\"  {key}: {value}\")\n",
    "\n",
    "# print(\"\\n‚≠ê KEY INSIGHTS:\")\n",
    "# print(f\"  Single-task (nuclei only): {mean_time_single:.3f}s\")\n",
    "# print(f\"  Dual-task (2 sequential runs): {mean_time_dual:.3f}s\")\n",
    "# print(f\"  Overhead: {results_dual['overhead_vs_single_pct']:.1f}%\")\n",
    "# print(f\"  üî¥ CellSAM requires 2 separate runs (no simultaneous dual-task)\")\n",
    "\n",
    "# # ============================================\n",
    "# # 4. WSI BENCHMARK: Nuclei Only\n",
    "# # ============================================\n",
    "\n",
    "# print(\"\\n\" + \"=\" * 70)\n",
    "# print(\"CELLSAM BENCHMARK 4: WSI SINGLE-TASK (Nuclei Only, 15000√ó15000)\")\n",
    "# print(\"=\" * 70)\n",
    "\n",
    "# torch.cuda.reset_peak_memory_stats()\n",
    "# torch.cuda.empty_cache()\n",
    "# gc.collect()\n",
    "\n",
    "# cpu_mem_before = measure_cpu_memory()\n",
    "\n",
    "# start_wsi = time.time()\n",
    "# mask_wsi_nuclei = segment_wsi(\n",
    "#     wsi_5000,\n",
    "#     block_size=512,\n",
    "#     overlap=64,\n",
    "#     iou_depth=1,\n",
    "#     iou_threshold=0.5,\n",
    "#     model=model,\n",
    "#     device='cuda'\n",
    "# )\n",
    "\n",
    "# # Convert dask array if needed\n",
    "# if hasattr(mask_wsi_nuclei, 'compute'):\n",
    "#     mask_wsi_nuclei = mask_wsi_nuclei.compute()\n",
    "\n",
    "# torch.cuda.synchronize()\n",
    "# elapsed_wsi = time.time() - start_wsi\n",
    "\n",
    "# cpu_mem_after = measure_cpu_memory()\n",
    "# gpu_mem_wsi = measure_gpu_memory()\n",
    "\n",
    "# seg_metrics_wsi = compute_segmentation_metrics(mask_wsi_nuclei)\n",
    "# n_nuclei_wsi = seg_metrics_wsi['n_cells']\n",
    "\n",
    "# # Save WSI mask\n",
    "# print(\"Saving WSI nuclei masks...\")\n",
    "# save_mask(mask_wsi_nuclei, os.path.join(MASKS_DIR, 'wsi_15000_nuclei.tif'))\n",
    "\n",
    "# # Tile statistics\n",
    "# tile_size = 512\n",
    "# overlap_pixels = 64\n",
    "# stride = tile_size - overlap_pixels\n",
    "# n_tiles_x = int(np.ceil(wsi_5000.shape[1] / stride))\n",
    "# n_tiles_y = int(np.ceil(wsi_5000.shape[0] / stride))\n",
    "# total_tiles = n_tiles_x * n_tiles_y\n",
    "\n",
    "# results_wsi_nuclei = {\n",
    "#     'task': 'Nuclei Only',\n",
    "#     'image_size': '15000√ó15000',\n",
    "#     'n_tiles': total_tiles,\n",
    "#     'tile_size': '512√ó512',\n",
    "#     'n_instances': n_nuclei_wsi,\n",
    "#     'total_time_s': elapsed_wsi,\n",
    "#     'total_time_min': elapsed_wsi / 60,\n",
    "#     'time_per_tile_ms': (elapsed_wsi / total_tiles) * 1000,\n",
    "#     'peak_gpu_memory_gb': gpu_mem_wsi['max_allocated_gb'],\n",
    "#     'instances_per_second': n_nuclei_wsi / elapsed_wsi,\n",
    "#     'throughput_mpx_per_min': (15000 * 15000 / 1e6) / (elapsed_wsi / 60),\n",
    "# }\n",
    "\n",
    "# print(\"\\nRESULTS:\")\n",
    "# for key, value in results_wsi_nuclei.items():\n",
    "#     if isinstance(value, float):\n",
    "#         print(f\"  {key}: {value:.4f}\")\n",
    "#     else:\n",
    "#         print(f\"  {key}: {value}\")\n",
    "\n",
    "# # ============================================\n",
    "# # 5. WSI BENCHMARK: Dual-Task Simulation\n",
    "# # ============================================\n",
    "\n",
    "# print(\"\\n\" + \"=\" * 70)\n",
    "# print(\"‚≠ê CELLSAM BENCHMARK 5: WSI DUAL-TASK SIMULATION (15000√ó15000)\")\n",
    "# print(\"=\" * 70)\n",
    "# print(\"Note: Running CellSAM TWICE for nuclei + cells\")\n",
    "\n",
    "# torch.cuda.reset_peak_memory_stats()\n",
    "# torch.cuda.empty_cache()\n",
    "# gc.collect()\n",
    "\n",
    "# # RUN 1: Nuclei\n",
    "# print(\"Running nuclei segmentation...\")\n",
    "# start = time.time()\n",
    "# mask_wsi_n = segment_wsi(\n",
    "#     wsi_5000,\n",
    "#     block_size=512,\n",
    "#     overlap=64,\n",
    "#     iou_depth=1,\n",
    "#     iou_threshold=0.5,\n",
    "#     model=model,\n",
    "#     device='cuda'\n",
    "# )\n",
    "# if hasattr(mask_wsi_n, 'compute'):\n",
    "#     mask_wsi_n = mask_wsi_n.compute()\n",
    "# torch.cuda.synchronize()\n",
    "# time_wsi_nuclei = time.time() - start\n",
    "\n",
    "# # RUN 2: Cells\n",
    "# print(\"Running cell segmentation...\")\n",
    "# start = time.time()\n",
    "# mask_wsi_c = segment_wsi(\n",
    "#     wsi_5000,\n",
    "#     block_size=512,\n",
    "#     overlap=64,\n",
    "#     iou_depth=1,\n",
    "#     iou_threshold=0.5,\n",
    "#     model=model,\n",
    "#     device='cuda'\n",
    "# )\n",
    "# if hasattr(mask_wsi_c, 'compute'):\n",
    "#     mask_wsi_c = mask_wsi_c.compute()\n",
    "# torch.cuda.synchronize()\n",
    "# time_wsi_cells = time.time() - start\n",
    "\n",
    "# elapsed_wsi_dual = time_wsi_nuclei + time_wsi_cells\n",
    "# gpu_mem_wsi_dual = measure_gpu_memory()\n",
    "\n",
    "# seg_n_wsi = compute_segmentation_metrics(mask_wsi_n)\n",
    "# seg_c_wsi = compute_segmentation_metrics(mask_wsi_c)\n",
    "# n_nuclei_wsi_dual = seg_n_wsi['n_cells']\n",
    "# n_cells_wsi_dual = seg_c_wsi['n_cells']\n",
    "# total_instances_wsi = n_nuclei_wsi_dual + n_cells_wsi_dual\n",
    "\n",
    "# # Save WSI dual masks\n",
    "# print(\"Saving WSI dual-task masks...\")\n",
    "# save_mask(mask_wsi_n, os.path.join(MASKS_DIR, 'wsi_15000_dual_nuclei.tif'))\n",
    "# save_mask(mask_wsi_c, os.path.join(MASKS_DIR, 'wsi_15000_dual_cells.tif'))\n",
    "\n",
    "# results_wsi_dual = {\n",
    "#     'task': 'Nuclei + Cells (Sequential)',\n",
    "#     'image_size': '15000√ó15000',\n",
    "#     'n_tiles': total_tiles,\n",
    "#     'tile_size': '512√ó512',\n",
    "#     'n_nuclei': n_nuclei_wsi_dual,\n",
    "#     'n_cells': n_cells_wsi_dual,\n",
    "#     'total_instances': total_instances_wsi,\n",
    "#     'total_time_s': elapsed_wsi_dual,\n",
    "#     'total_time_min': elapsed_wsi_dual / 60,\n",
    "#     'time_per_tile_ms': (elapsed_wsi_dual / total_tiles) * 1000,\n",
    "#     'peak_gpu_memory_gb': gpu_mem_wsi_dual['max_allocated_gb'],\n",
    "#     'instances_per_second': total_instances_wsi / elapsed_wsi_dual,\n",
    "#     'throughput_mpx_per_min': (15000 * 15000 / 1e6) / (elapsed_wsi_dual / 60),\n",
    "#     'overhead_vs_single_pct': ((elapsed_wsi_dual / elapsed_wsi) - 1) * 100,\n",
    "# }\n",
    "\n",
    "# print(\"\\nRESULTS:\")\n",
    "# for key, value in results_wsi_dual.items():\n",
    "#     if isinstance(value, float):\n",
    "#         print(f\"  {key}: {value:.4f}\")\n",
    "#     else:\n",
    "#         print(f\"  {key}: {value}\")\n",
    "\n",
    "# print(\"\\n‚≠ê KEY INSIGHTS:\")\n",
    "# print(f\"  Single-task WSI: {elapsed_wsi / 60:.2f} min\")\n",
    "# print(f\"  Dual-task WSI (2 sequential runs): {elapsed_wsi_dual / 60:.2f} min ({time_wsi_nuclei / 60:.2f} + {time_wsi_cells / 60:.2f})\")\n",
    "# print(f\"  Overhead: {results_wsi_dual['overhead_vs_single_pct']:.1f}%\")\n",
    "# print(f\"  üî¥ CellSAM requires 2 separate runs (no simultaneous dual-task)\")\n",
    "\n",
    "# # ============================================\n",
    "# # 6. COMPILE ALL RESULTS\n",
    "# # ============================================\n",
    "\n",
    "# print(\"\\n\" + \"=\" * 70)\n",
    "# print(\"CELLSAM COMPREHENSIVE BENCHMARK SUMMARY\")\n",
    "# print(\"=\" * 70)\n",
    "\n",
    "# summary_df = pd.DataFrame([\n",
    "#     {\n",
    "#         'Test': 'Single Tile - Nuclei',\n",
    "#         'Task': 'Nuclei',\n",
    "#         'Size': '512√ó512',\n",
    "#         'Instances': results_nuclei['n_instances'],\n",
    "#         'Time (s)': results_nuclei['mean_time_s'],\n",
    "#         'Memory (GB)': results_nuclei['peak_memory_gb'],\n",
    "#         'Inst/sec': results_nuclei['instances_per_second'],\n",
    "#     },\n",
    "#     {\n",
    "#         'Test': 'Single Tile - Cells',\n",
    "#         'Task': 'Cells',\n",
    "#         'Size': '512√ó512',\n",
    "#         'Instances': results_cells['n_instances'],\n",
    "#         'Time (s)': results_cells['mean_time_s'],\n",
    "#         'Memory (GB)': results_cells['peak_memory_gb'],\n",
    "#         'Inst/sec': results_cells['instances_per_second'],\n",
    "#     },\n",
    "#     {\n",
    "#         'Test': 'Single Tile - DUAL',\n",
    "#         'Task': 'Both (2 runs)',\n",
    "#         'Size': '512√ó512',\n",
    "#         'Instances': results_dual['total_instances'],\n",
    "#         'Time (s)': results_dual['mean_time_s'],\n",
    "#         'Memory (GB)': results_dual['peak_memory_gb'],\n",
    "#         'Inst/sec': results_dual['instances_per_second'],\n",
    "#     },\n",
    "#     {\n",
    "#         'Test': 'WSI - Nuclei',\n",
    "#         'Task': 'Nuclei',\n",
    "#         'Size': '15000√ó15000',\n",
    "#         'Instances': results_wsi_nuclei['n_instances'],\n",
    "#         'Time (s)': results_wsi_nuclei['total_time_s'],\n",
    "#         'Memory (GB)': results_wsi_nuclei['peak_gpu_memory_gb'],\n",
    "#         'Inst/sec': results_wsi_nuclei['instances_per_second'],\n",
    "#     },\n",
    "#     {\n",
    "#         'Test': 'WSI - DUAL',\n",
    "#         'Task': 'Both (2 runs)',\n",
    "#         'Size': '15000√ó15000',\n",
    "#         'Instances': results_wsi_dual['total_instances'],\n",
    "#         'Time (s)': results_wsi_dual['total_time_s'],\n",
    "#         'Memory (GB)': results_wsi_dual['peak_gpu_memory_gb'],\n",
    "#         'Inst/sec': results_wsi_dual['instances_per_second'],\n",
    "#     }\n",
    "# ])\n",
    "\n",
    "# print(\"\\n\" + summary_df.to_string(index=False))\n",
    "\n",
    "# # ============================================\n",
    "# # 7. SAVE ALL RESULTS\n",
    "# # ============================================\n",
    "\n",
    "# print(\"\\n\" + \"=\" * 70)\n",
    "# print(\"SAVING RESULTS...\")\n",
    "# print(\"=\" * 70)\n",
    "\n",
    "# # Save CSV\n",
    "# csv_path = os.path.join(OUTPUT_DIR, 'cellsam_benchmark_summary.csv')\n",
    "# summary_df.to_csv(csv_path, index=False)\n",
    "# print(f\"‚úì Saved CSV: {csv_path}\")\n",
    "\n",
    "# # Save JSON\n",
    "# all_results = {\n",
    "#     'single_tile_nuclei': results_nuclei,\n",
    "#     'single_tile_cells': results_cells,\n",
    "#     'single_tile_dual': results_dual,\n",
    "#     'wsi_nuclei': results_wsi_nuclei,\n",
    "#     'wsi_dual': results_wsi_dual,\n",
    "#     'hardware': {\n",
    "#         'gpu': torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'N/A',\n",
    "#         'gpu_memory_total_gb': torch.cuda.get_device_properties(0).total_memory / 1024**3 if torch.cuda.is_available() else 0,\n",
    "#     },\n",
    "#     'benchmark_date': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "# }\n",
    "\n",
    "# json_path = os.path.join(OUTPUT_DIR, 'cellsam_benchmark_complete.json')\n",
    "# with open(json_path, 'w') as f:\n",
    "#     json.dump(all_results, f, indent=2)\n",
    "# print(f\"‚úì Saved JSON: {json_path}\")\n",
    "\n",
    "# # ============================================\n",
    "# # 8. VISUALIZATION\n",
    "# # ============================================\n",
    "\n",
    "# print(\"\\nGenerating plots...\")\n",
    "\n",
    "# fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# # Plot 1: Single Tile Comparison\n",
    "# tasks = ['Nuclei\\nOnly', 'Cells\\nOnly', 'Both\\n(2 runs)']\n",
    "# times = [results_nuclei['mean_time_ms'], results_cells['mean_time_ms'], results_dual['mean_time_ms']]\n",
    "# axes[0, 0].bar(tasks, times, color=['steelblue', 'coral', 'red'])\n",
    "# axes[0, 0].set_ylabel('Time (ms)', fontsize=12)\n",
    "# axes[0, 0].set_title('Single Tile Processing Time (512√ó512)', fontsize=14, fontweight='bold')\n",
    "# axes[0, 0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# # Plot 2: WSI Comparison\n",
    "# wsi_tasks = ['Nuclei\\nOnly', 'Both\\n(2 runs)']\n",
    "# wsi_times = [\n",
    "#     results_wsi_nuclei['total_time_min'],\n",
    "#     results_wsi_dual['total_time_min']\n",
    "# ]\n",
    "# axes[0, 1].bar(wsi_tasks, wsi_times, color=['steelblue', 'red'])\n",
    "# axes[0, 1].set_ylabel('Time (minutes)', fontsize=12)\n",
    "# axes[0, 1].set_title('WSI Processing Time (15000√ó15000)', fontsize=14, fontweight='bold')\n",
    "# axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# # Plot 3: Throughput\n",
    "# throughputs = [\n",
    "#     results_nuclei['instances_per_second'],\n",
    "#     results_cells['instances_per_second'],\n",
    "#     results_dual['instances_per_second']\n",
    "# ]\n",
    "# axes[1, 0].bar(tasks, throughputs, color=['steelblue', 'coral', 'red'])\n",
    "# axes[1, 0].set_ylabel('Instances/Second', fontsize=12)\n",
    "# axes[1, 0].set_title('Segmentation Throughput', fontsize=14, fontweight='bold')\n",
    "# axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# # Plot 4: Memory Usage\n",
    "# memory_vals = [\n",
    "#     results_nuclei['peak_memory_gb'],\n",
    "#     results_cells['peak_memory_gb'],\n",
    "#     results_dual['peak_memory_gb']\n",
    "# ]\n",
    "# axes[1, 1].bar(tasks, memory_vals, color=['steelblue', 'coral', 'red'])\n",
    "# axes[1, 1].set_ylabel('Peak GPU Memory (GB)', fontsize=12)\n",
    "# axes[1, 1].set_title('Memory Usage', fontsize=14, fontweight='bold')\n",
    "# axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plot_path = os.path.join(OUTPUT_DIR, 'cellsam_benchmark_plots.png')\n",
    "# plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "# print(f\"‚úì Saved plot: {plot_path}\")\n",
    "# plt.close()\n",
    "\n",
    "# # ============================================\n",
    "# # 9. LIST SAVED MASK FILES\n",
    "# # ============================================\n",
    "\n",
    "# print(\"\\nüìÅ Saved mask files:\")\n",
    "# mask_files = sorted([f for f in os.listdir(MASKS_DIR) if f.endswith('.tif')])\n",
    "# for mf in mask_files:\n",
    "#     size_mb = os.path.getsize(os.path.join(MASKS_DIR, mf)) / (1024**2)\n",
    "#     print(f\"  - {mf} ({size_mb:.2f} MB)\")\n",
    "\n",
    "# print(\"\\n\" + \"=\" * 70)\n",
    "# print(\"BENCHMARK COMPLETE!\")\n",
    "# print(\"=\" * 70)\n",
    "# print(f\"\\nüìÅ All results saved to: {os.path.abspath(OUTPUT_DIR)}\")\n",
    "# print(\"\\n‚≠ê KEY FINDINGS:\")\n",
    "# print(f\"  Single Tile - Nuclei: {results_nuclei['mean_time_ms']:.1f} ms\")\n",
    "# print(f\"  Single Tile - Dual (2 runs): {results_dual['mean_time_ms']:.1f} ms\")\n",
    "# print(f\"  WSI - Nuclei: {results_wsi_nuclei['total_time_min']:.2f} min\")\n",
    "# print(f\"  WSI - Dual (2 runs): {results_wsi_dual['total_time_min']:.2f} min\")\n",
    "# print(f\"  üî¥ CellSAM requires 2 separate runs for nuclei + cells\")\n",
    "# print(\"\\nüìä Files created:\")\n",
    "# print(f\"  - {os.path.basename(csv_path)}\")\n",
    "# print(f\"  - {os.path.basename(json_path)}\")\n",
    "# print(f\"  - {os.path.basename(plot_path)}\")\n",
    "# print(f\"  - masks/ folder with {len(mask_files)} segmentation outputs\")\n",
    "# print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1bc26d-69c6-4522-9e28-6ea946604118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Output directory: benchmark_results/cellsam\n",
      "   Masks will be saved to: benchmark_results/cellsam/masks\n",
      "\n",
      "======================================================================\n",
      "Loading CellSAM model...\n",
      "  ‚úì Model loaded successfully\n",
      "Tile shape: (512, 512, 3)\n",
      "WSI shape: (15000, 15000, 3)\n",
      "\n",
      "======================================================================\n",
      "CELLSAM BENCHMARK 1: SINGLE-TASK (Nuclei Only, 512√ó512)\n",
      "======================================================================\n",
      "Warmup runs...\n",
      "Running 10 timed iterations...\n",
      "  Run 1/10: 1.133s, 3.48 GB, Nuclei: 125\n",
      "  Run 2/10: 1.258s, 3.48 GB, Nuclei: 125\n",
      "  Run 3/10: 1.293s, 3.48 GB, Nuclei: 125\n",
      "  Run 4/10: 1.217s, 3.48 GB, Nuclei: 125\n",
      "  Run 5/10: 1.228s, 3.48 GB, Nuclei: 125\n",
      "  Run 6/10: 1.205s, 3.48 GB, Nuclei: 125\n",
      "  Run 7/10: 1.207s, 3.48 GB, Nuclei: 125\n",
      "  Run 8/10: 1.218s, 3.48 GB, Nuclei: 125\n",
      "  Run 9/10: 1.239s, 3.48 GB, Nuclei: 125\n",
      "  Run 10/10: 1.248s, 3.48 GB, Nuclei: 125\n",
      "Saving nuclei masks...\n",
      "\n",
      "RESULTS:\n",
      "  task: Nuclei Only\n",
      "  image_size: 512√ó512\n",
      "  n_instances: 125\n",
      "  mean_time_s: 1.2246\n",
      "  std_time_s: 0.0397\n",
      "  mean_time_ms: 1224.5991\n",
      "  peak_memory_gb: 3.4841\n",
      "  instances_per_second: 102.0742\n",
      "\n",
      "======================================================================\n",
      "CELLSAM BENCHMARK 2: SINGLE-TASK (Cells Only, 512√ó512)\n",
      "======================================================================\n",
      "Warmup runs...\n",
      "Running 10 timed iterations...\n",
      "  Run 1/10: 1.231s, 3.48 GB, Cells: 125\n",
      "  Run 2/10: 1.161s, 3.48 GB, Cells: 125\n",
      "  Run 3/10: 1.315s, 3.48 GB, Cells: 125\n",
      "  Run 4/10: 1.221s, 3.48 GB, Cells: 125\n",
      "  Run 5/10: 1.225s, 3.48 GB, Cells: 125\n",
      "  Run 6/10: 1.205s, 3.48 GB, Cells: 125\n",
      "  Run 7/10: 1.206s, 3.48 GB, Cells: 125\n",
      "  Run 8/10: 1.300s, 3.48 GB, Cells: 125\n",
      "  Run 9/10: 1.234s, 3.48 GB, Cells: 125\n",
      "  Run 10/10: 1.231s, 3.48 GB, Cells: 125\n",
      "Saving cell masks...\n",
      "\n",
      "RESULTS:\n",
      "  task: Cells Only\n",
      "  image_size: 512√ó512\n",
      "  n_instances: 125\n",
      "  mean_time_s: 1.2330\n",
      "  std_time_s: 0.0427\n",
      "  mean_time_ms: 1232.9504\n",
      "  peak_memory_gb: 3.4841\n",
      "  instances_per_second: 101.3828\n",
      "\n",
      "======================================================================\n",
      "‚≠ê CELLSAM BENCHMARK 3: DUAL-TASK SIMULATION (Run Twice, 512√ó512)\n",
      "======================================================================\n",
      "Note: CellSAM requires TWO separate runs for nuclei + cells\n",
      "Warmup runs...\n",
      "Running 10 timed iterations (2 runs each)...\n",
      "  Run 1/10: 2.527s (1.244s + 1.283s), 3.48 GB, Nuclei: 125, Cells: 125\n",
      "  Run 2/10: 2.490s (1.232s + 1.258s), 3.48 GB, Nuclei: 125, Cells: 125\n",
      "  Run 3/10: 2.509s (1.247s + 1.262s), 3.48 GB, Nuclei: 125, Cells: 125\n",
      "  Run 4/10: 2.313s (1.156s + 1.156s), 3.48 GB, Nuclei: 125, Cells: 125\n",
      "  Run 5/10: 2.515s (1.274s + 1.241s), 3.48 GB, Nuclei: 125, Cells: 125\n",
      "  Run 6/10: 2.434s (1.205s + 1.229s), 3.48 GB, Nuclei: 125, Cells: 125\n",
      "  Run 7/10: 2.485s (1.214s + 1.271s), 3.48 GB, Nuclei: 125, Cells: 125\n",
      "  Run 8/10: 2.457s (1.234s + 1.223s), 3.48 GB, Nuclei: 125, Cells: 125\n",
      "  Run 9/10: 2.422s (1.204s + 1.217s), 3.48 GB, Nuclei: 125, Cells: 125\n",
      "  Run 10/10: 2.470s (1.233s + 1.237s), 3.48 GB, Nuclei: 125, Cells: 125\n",
      "Saving dual-task masks...\n",
      "\n",
      "RESULTS:\n",
      "  task: Nuclei + Cells (Sequential)\n",
      "  image_size: 512√ó512\n",
      "  n_nuclei: 125\n",
      "  n_cells: 125\n",
      "  total_instances: 250\n",
      "  mean_time_s: 2.4622\n",
      "  std_time_s: 0.0596\n",
      "  mean_time_ms: 2462.1825\n",
      "  peak_memory_gb: 3.4841\n",
      "  instances_per_second: 101.5359\n",
      "  overhead_vs_single_pct: 101.0603\n",
      "\n",
      "‚≠ê KEY INSIGHTS:\n",
      "  Single-task (nuclei only): 1.225s\n",
      "  Dual-task (2 sequential runs): 2.462s\n",
      "  Overhead: 101.1%\n",
      "  üî¥ CellSAM requires 2 separate runs (no simultaneous dual-task)\n",
      "\n",
      "======================================================================\n",
      "CELLSAM BENCHMARK 4: WSI SINGLE-TASK (Nuclei Only, 15000√ó15000)\n",
      "======================================================================\n",
      "‚è±Ô∏è  This will take a while - please be patient...\n",
      "Total blocks: 900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "532it [11:59,  1.37it/s]ERROR:root:Error segmenting chunk: 'NoneType' object has no attribute 'ndim'\n",
      "560it [12:29,  1.03s/it]ERROR:root:Error segmenting chunk: 'NoneType' object has no attribute 'ndim'\n",
      "564it [12:31,  1.82it/s]ERROR:root:Error segmenting chunk: 'NoneType' object has no attribute 'ndim'\n",
      "589it [13:01,  1.11s/it]ERROR:root:Error segmenting chunk: 'NoneType' object has no attribute 'ndim'\n",
      "590it [13:01,  1.13it/s]ERROR:root:Error segmenting chunk: 'NoneType' object has no attribute 'ndim'\n",
      "618it [13:35,  1.07s/it]ERROR:root:Error segmenting chunk: 'NoneType' object has no attribute 'ndim'\n",
      "621it [13:37,  1.57it/s]ERROR:root:Error segmenting chunk: 'NoneType' object has no attribute 'ndim'\n",
      "648it [14:14,  1.11it/s]ERROR:root:Error segmenting chunk: 'NoneType' object has no attribute 'ndim'\n",
      "672it [14:45,  1.07s/it]ERROR:root:Error segmenting chunk: 'NoneType' object has no attribute 'ndim'\n",
      "673it [14:45,  1.16it/s]ERROR:root:Error segmenting chunk: 'NoneType' object has no attribute 'ndim'\n",
      "678it [14:49,  1.26it/s]ERROR:root:Error segmenting chunk: 'NoneType' object has no attribute 'ndim'\n",
      "679it [14:49,  1.50it/s]ERROR:root:Error segmenting chunk: 'NoneType' object has no attribute 'ndim'\n",
      "708it [15:19,  1.19it/s]ERROR:root:Error segmenting chunk: 'NoneType' object has no attribute 'ndim'\n",
      "733it [15:39,  1.65it/s]ERROR:root:Error segmenting chunk: 'NoneType' object has no attribute 'ndim'\n",
      "759it [16:04,  1.84it/s]ERROR:root:Error segmenting chunk: 'NoneType' object has no attribute 'ndim'\n",
      "821it [17:09,  1.40s/it]ERROR:root:Error segmenting chunk: 'NoneType' object has no attribute 'ndim'\n",
      "823it [17:10,  1.02s/it]ERROR:root:Error segmenting chunk: 'NoneType' object has no attribute 'ndim'\n",
      "900it [18:32,  1.24s/it]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1740/1740 [00:30<00:00, 57.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Computing segmentation metrics (forces computation)...\n",
      "  Saving WSI nuclei masks...\n",
      "\n",
      "RESULTS:\n",
      "  task: Nuclei Only\n",
      "  image_size: 15000√ó15000\n",
      "  n_tiles: 1156\n",
      "  tile_size: 512√ó512\n",
      "  n_instances: 60197\n",
      "  total_time_s: 11441.3129\n",
      "  total_time_min: 190.6885\n",
      "  time_per_tile_ms: 9897.3295\n",
      "  peak_gpu_memory_gb: 3.4858\n",
      "  instances_per_second: 5.2614\n",
      "  throughput_mpx_per_min: 1.1799\n",
      "\n",
      "======================================================================\n",
      "‚≠ê CELLSAM BENCHMARK 5: WSI DUAL-TASK SIMULATION (15000√ó15000)\n",
      "======================================================================\n",
      "Note: Running CellSAM TWICE for nuclei + cells\n",
      "‚è±Ô∏è  This will take even longer - please be patient...\n",
      "\n",
      "üî¨ Running nuclei segmentation...\n",
      "Total blocks: 900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "532it [11:55,  1.38it/s]ERROR:root:Error segmenting chunk: 'NoneType' object has no attribute 'ndim'\n",
      "560it [12:25,  1.05s/it]ERROR:root:Error segmenting chunk: 'NoneType' object has no attribute 'ndim'\n",
      "564it [12:27,  1.78it/s]ERROR:root:Error segmenting chunk: 'NoneType' object has no attribute 'ndim'\n",
      "589it [12:57,  1.11s/it]ERROR:root:Error segmenting chunk: 'NoneType' object has no attribute 'ndim'\n",
      "590it [12:58,  1.12it/s]ERROR:root:Error segmenting chunk: 'NoneType' object has no attribute 'ndim'\n",
      "618it [13:32,  1.08s/it]ERROR:root:Error segmenting chunk: 'NoneType' object has no attribute 'ndim'\n",
      "621it [13:33,  1.56it/s]ERROR:root:Error segmenting chunk: 'NoneType' object has no attribute 'ndim'\n",
      "648it [14:11,  1.11it/s]ERROR:root:Error segmenting chunk: 'NoneType' object has no attribute 'ndim'\n",
      "672it [14:42,  1.06s/it]ERROR:root:Error segmenting chunk: 'NoneType' object has no attribute 'ndim'\n",
      "673it [14:42,  1.16it/s]ERROR:root:Error segmenting chunk: 'NoneType' object has no attribute 'ndim'\n",
      "678it [14:46,  1.25it/s]ERROR:root:Error segmenting chunk: 'NoneType' object has no attribute 'ndim'\n",
      "679it [14:46,  1.47it/s]ERROR:root:Error segmenting chunk: 'NoneType' object has no attribute 'ndim'\n",
      "708it [15:16,  1.17it/s]ERROR:root:Error segmenting chunk: 'NoneType' object has no attribute 'ndim'\n",
      "733it [15:37,  1.63it/s]ERROR:root:Error segmenting chunk: 'NoneType' object has no attribute 'ndim'\n",
      "759it [16:01,  1.86it/s]ERROR:root:Error segmenting chunk: 'NoneType' object has no attribute 'ndim'\n",
      "821it [17:07,  1.38s/it]ERROR:root:Error segmenting chunk: 'NoneType' object has no attribute 'ndim'\n",
      "823it [17:08,  1.02s/it]ERROR:root:Error segmenting chunk: 'NoneType' object has no attribute 'ndim'\n",
      "900it [18:30,  1.23s/it]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1740/1740 [00:32<00:00, 54.19it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Computing nuclei metrics...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from cellSAM import segment_cellular_image, CellSAM\n",
    "from cellSAM.wsi import segment_wsi\n",
    "import psutil\n",
    "import gc\n",
    "import json\n",
    "import os\n",
    "import tifffile\n",
    "\n",
    "# ============================================\n",
    "# SETUP OUTPUT DIRECTORY\n",
    "# ============================================\n",
    "\n",
    "OUTPUT_DIR = \"benchmark_results/cellsam\"\n",
    "MASKS_DIR = os.path.join(OUTPUT_DIR, \"masks\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(MASKS_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"   Masks will be saved to: {MASKS_DIR}\")\n",
    "\n",
    "# ============================================\n",
    "# METRIC EXTRACTION FUNCTIONS\n",
    "# ============================================\n",
    "\n",
    "def compute_segmentation_metrics(mask):\n",
    "    \"\"\"Compute detailed segmentation statistics\"\"\"\n",
    "    unique_labels = np.unique(mask)\n",
    "    n_cells = len(unique_labels) - 1  # exclude background (0)\n",
    "    \n",
    "    # Cell size statistics\n",
    "    cell_sizes = []\n",
    "    for label in unique_labels[1:]:  # skip background\n",
    "        cell_sizes.append(np.sum(mask == label))\n",
    "    \n",
    "    return {\n",
    "        'n_cells': n_cells,\n",
    "        'mean_cell_size': np.mean(cell_sizes) if cell_sizes else 0,\n",
    "        'median_cell_size': np.median(cell_sizes) if cell_sizes else 0,\n",
    "        'std_cell_size': np.std(cell_sizes) if cell_sizes else 0,\n",
    "        'min_cell_size': np.min(cell_sizes) if cell_sizes else 0,\n",
    "        'max_cell_size': np.max(cell_sizes) if cell_sizes else 0,\n",
    "    }\n",
    "\n",
    "def measure_gpu_memory():\n",
    "    \"\"\"Measure current GPU memory usage\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return {\n",
    "            'allocated_gb': torch.cuda.memory_allocated() / 1024**3,\n",
    "            'reserved_gb': torch.cuda.memory_reserved() / 1024**3,\n",
    "            'max_allocated_gb': torch.cuda.max_memory_allocated() / 1024**3,\n",
    "        }\n",
    "    return {'allocated_gb': 0, 'reserved_gb': 0, 'max_allocated_gb': 0}\n",
    "\n",
    "def measure_cpu_memory():\n",
    "    \"\"\"Measure current CPU memory usage\"\"\"\n",
    "    process = psutil.Process()\n",
    "    return process.memory_info().rss / 1024**3  # GB\n",
    "\n",
    "def save_mask(mask, filepath):\n",
    "    \"\"\"Save mask as TIFF\"\"\"\n",
    "    Image.fromarray(mask.astype(np.uint16)).save(filepath)\n",
    "\n",
    "# ============================================\n",
    "# LOAD MODEL & TEST IMAGES\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Loading CellSAM model...\")\n",
    "\n",
    "# Set the access token\n",
    "os.environ['DEEPCELL_ACCESS_TOKEN'] = 'JbVVUStF.A6Ec6pe5vKsoB3RhTnSOaqXJ1thDE3B6'\n",
    "\n",
    "# Load the model using get_model\n",
    "from cellSAM import get_model\n",
    "model = get_model(model='cellsam_general')\n",
    "print(\"  ‚úì Model loaded successfully\")\n",
    "\n",
    "# Load test images\n",
    "tile_512 = np.array(Image.open(\"test_images/ovarian-he_chunk_92.png\"))\n",
    "wsi_5000 = tifffile.imread(\"test_images/breat_cancer_15000x15000.tiff\")\n",
    "\n",
    "print(f\"Tile shape: {tile_512.shape}\")\n",
    "print(f\"WSI shape: {wsi_5000.shape}\")\n",
    "\n",
    "# ============================================\n",
    "# 1. SINGLE-TASK BENCHMARK: Nuclei Only\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CELLSAM BENCHMARK 1: SINGLE-TASK (Nuclei Only, 512√ó512)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# Warmup\n",
    "print(\"Warmup runs...\")\n",
    "for _ in range(3):\n",
    "    _ = segment_cellular_image(tile_512, model=model, device='cuda')\n",
    "\n",
    "# Benchmark\n",
    "n_runs = 10\n",
    "times_nuclei = []\n",
    "memory_nuclei = []\n",
    "n_nuclei_list = []\n",
    "\n",
    "print(f\"Running {n_runs} timed iterations...\")\n",
    "for i in range(n_runs):\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "    start = time.time()\n",
    "    mask_nuclei, _, _ = segment_cellular_image(tile_512, model=model, device='cuda')\n",
    "    torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "    \n",
    "    times_nuclei.append(end - start)\n",
    "    memory_nuclei.append(measure_gpu_memory()['max_allocated_gb'])\n",
    "    \n",
    "    seg_metrics = compute_segmentation_metrics(mask_nuclei)\n",
    "    n_nuclei_list.append(seg_metrics['n_cells'])\n",
    "    \n",
    "    print(f\"  Run {i+1}/{n_runs}: {times_nuclei[-1]:.3f}s, {memory_nuclei[-1]:.2f} GB, Nuclei: {n_nuclei_list[-1]}\")\n",
    "\n",
    "# Save mask from last run\n",
    "print(\"Saving nuclei masks...\")\n",
    "save_mask(mask_nuclei, os.path.join(MASKS_DIR, 'tile_512_nuclei.tif'))\n",
    "\n",
    "results_nuclei = {\n",
    "    'task': 'Nuclei Only',\n",
    "    'image_size': '512√ó512',\n",
    "    'n_instances': n_nuclei_list[-1],\n",
    "    'mean_time_s': np.mean(times_nuclei),\n",
    "    'std_time_s': np.std(times_nuclei),\n",
    "    'mean_time_ms': np.mean(times_nuclei) * 1000,\n",
    "    'peak_memory_gb': np.mean(memory_nuclei),\n",
    "    'instances_per_second': n_nuclei_list[-1] / np.mean(times_nuclei),\n",
    "}\n",
    "\n",
    "print(\"\\nRESULTS:\")\n",
    "for key, value in results_nuclei.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {key}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "# ============================================\n",
    "# 2. SINGLE-TASK BENCHMARK: Cells Only\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CELLSAM BENCHMARK 2: SINGLE-TASK (Cells Only, 512√ó512)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# Warmup\n",
    "print(\"Warmup runs...\")\n",
    "for _ in range(3):\n",
    "    _ = segment_cellular_image(tile_512, model=model, device='cuda')\n",
    "\n",
    "# Benchmark\n",
    "times_cells = []\n",
    "memory_cells = []\n",
    "n_cells_list = []\n",
    "\n",
    "print(f\"Running {n_runs} timed iterations...\")\n",
    "for i in range(n_runs):\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "    start = time.time()\n",
    "    mask_cells, _, _ = segment_cellular_image(tile_512, model=model, device='cuda')\n",
    "    torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "    \n",
    "    times_cells.append(end - start)\n",
    "    memory_cells.append(measure_gpu_memory()['max_allocated_gb'])\n",
    "    \n",
    "    seg_metrics = compute_segmentation_metrics(mask_cells)\n",
    "    n_cells_list.append(seg_metrics['n_cells'])\n",
    "    \n",
    "    print(f\"  Run {i+1}/{n_runs}: {times_cells[-1]:.3f}s, {memory_cells[-1]:.2f} GB, Cells: {n_cells_list[-1]}\")\n",
    "\n",
    "# Save mask from last run\n",
    "print(\"Saving cell masks...\")\n",
    "save_mask(mask_cells, os.path.join(MASKS_DIR, 'tile_512_cells.tif'))\n",
    "\n",
    "results_cells = {\n",
    "    'task': 'Cells Only',\n",
    "    'image_size': '512√ó512',\n",
    "    'n_instances': n_cells_list[-1],\n",
    "    'mean_time_s': np.mean(times_cells),\n",
    "    'std_time_s': np.std(times_cells),\n",
    "    'mean_time_ms': np.mean(times_cells) * 1000,\n",
    "    'peak_memory_gb': np.mean(memory_cells),\n",
    "    'instances_per_second': n_cells_list[-1] / np.mean(times_cells),\n",
    "}\n",
    "\n",
    "print(\"\\nRESULTS:\")\n",
    "for key, value in results_cells.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {key}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "# ============================================\n",
    "# 3. DUAL-TASK SIMULATION: Run Twice\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚≠ê CELLSAM BENCHMARK 3: DUAL-TASK SIMULATION (Run Twice, 512√ó512)\")\n",
    "print(\"=\" * 70)\n",
    "print(\"Note: CellSAM requires TWO separate runs for nuclei + cells\")\n",
    "\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# Warmup\n",
    "print(\"Warmup runs...\")\n",
    "for _ in range(3):\n",
    "    # Run 1: Nuclei\n",
    "    _ = segment_cellular_image(tile_512, model=model, device='cuda')\n",
    "    # Run 2: Cells\n",
    "    _ = segment_cellular_image(tile_512, model=model, device='cuda')\n",
    "\n",
    "# Benchmark - Run TWICE per iteration\n",
    "times_dual = []\n",
    "memory_dual = []\n",
    "n_nuclei_dual = []\n",
    "n_cells_dual = []\n",
    "\n",
    "print(f\"Running {n_runs} timed iterations (2 runs each)...\")\n",
    "for i in range(n_runs):\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "    # RUN 1: Nuclei\n",
    "    start = time.time()\n",
    "    mask_n, _, _ = segment_cellular_image(tile_512, model=model, device='cuda')\n",
    "    torch.cuda.synchronize()\n",
    "    time_nuclei = time.time() - start\n",
    "    \n",
    "    # RUN 2: Cells\n",
    "    start = time.time()\n",
    "    mask_c, _, _ = segment_cellular_image(tile_512, model=model, device='cuda')\n",
    "    torch.cuda.synchronize()\n",
    "    time_cells = time.time() - start\n",
    "    \n",
    "    # Total time\n",
    "    total_time = time_nuclei + time_cells\n",
    "    times_dual.append(total_time)\n",
    "    memory_dual.append(measure_gpu_memory()['max_allocated_gb'])\n",
    "    \n",
    "    # Count instances\n",
    "    seg_n = compute_segmentation_metrics(mask_n)\n",
    "    seg_c = compute_segmentation_metrics(mask_c)\n",
    "    n_nuclei_dual.append(seg_n['n_cells'])\n",
    "    n_cells_dual.append(seg_c['n_cells'])\n",
    "    \n",
    "    print(f\"  Run {i+1}/{n_runs}: {total_time:.3f}s ({time_nuclei:.3f}s + {time_cells:.3f}s), {memory_dual[-1]:.2f} GB, Nuclei: {n_nuclei_dual[-1]}, Cells: {n_cells_dual[-1]}\")\n",
    "\n",
    "# Save masks from last run\n",
    "print(\"Saving dual-task masks...\")\n",
    "save_mask(mask_n, os.path.join(MASKS_DIR, 'tile_512_dual_nuclei.tif'))\n",
    "save_mask(mask_c, os.path.join(MASKS_DIR, 'tile_512_dual_cells.tif'))\n",
    "\n",
    "total_instances_dual = n_nuclei_dual[-1] + n_cells_dual[-1]\n",
    "mean_time_dual = np.mean(times_dual)\n",
    "mean_time_single = np.mean(times_nuclei)\n",
    "\n",
    "results_dual = {\n",
    "    'task': 'Nuclei + Cells (Sequential)',\n",
    "    'image_size': '512√ó512',\n",
    "    'n_nuclei': n_nuclei_dual[-1],\n",
    "    'n_cells': n_cells_dual[-1],\n",
    "    'total_instances': total_instances_dual,\n",
    "    'mean_time_s': mean_time_dual,\n",
    "    'std_time_s': np.std(times_dual),\n",
    "    'mean_time_ms': mean_time_dual * 1000,\n",
    "    'peak_memory_gb': np.mean(memory_dual),\n",
    "    'instances_per_second': total_instances_dual / mean_time_dual,\n",
    "    'overhead_vs_single_pct': ((mean_time_dual / mean_time_single) - 1) * 100,\n",
    "}\n",
    "\n",
    "print(\"\\nRESULTS:\")\n",
    "for key, value in results_dual.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {key}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\n‚≠ê KEY INSIGHTS:\")\n",
    "print(f\"  Single-task (nuclei only): {mean_time_single:.3f}s\")\n",
    "print(f\"  Dual-task (2 sequential runs): {mean_time_dual:.3f}s\")\n",
    "print(f\"  Overhead: {results_dual['overhead_vs_single_pct']:.1f}%\")\n",
    "print(f\"  üî¥ CellSAM requires 2 separate runs (no simultaneous dual-task)\")\n",
    "\n",
    "# ============================================\n",
    "# 4. WSI BENCHMARK: Nuclei Only\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CELLSAM BENCHMARK 4: WSI SINGLE-TASK (Nuclei Only, 15000√ó15000)\")\n",
    "print(\"=\" * 70)\n",
    "print(\"‚è±Ô∏è  This will take a while - please be patient...\")\n",
    "\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "cpu_mem_before = measure_cpu_memory()\n",
    "\n",
    "# Start timing - INCLUDE EVERYTHING\n",
    "start_wsi = time.time()\n",
    "\n",
    "mask_wsi_nuclei = segment_wsi(\n",
    "    wsi_5000,\n",
    "    block_size=512,\n",
    "    overlap=64,\n",
    "    iou_depth=1,\n",
    "    iou_threshold=0.5,\n",
    "    model=model,\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "# Convert dask array if needed\n",
    "if hasattr(mask_wsi_nuclei, 'compute'):\n",
    "    mask_wsi_nuclei = mask_wsi_nuclei.compute()\n",
    "\n",
    "# Force ALL computation to complete\n",
    "print(\"  Computing segmentation metrics (forces computation)...\")\n",
    "seg_metrics_wsi = compute_segmentation_metrics(mask_wsi_nuclei)\n",
    "n_nuclei_wsi = seg_metrics_wsi['n_cells']\n",
    "\n",
    "# Synchronize GPU\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "# Save masks (this might also take time)\n",
    "print(\"  Saving WSI nuclei masks...\")\n",
    "save_mask(mask_wsi_nuclei, os.path.join(MASKS_DIR, 'wsi_15000_nuclei.tif'))\n",
    "\n",
    "# Final sync and time\n",
    "torch.cuda.synchronize()\n",
    "elapsed_wsi = time.time() - start_wsi\n",
    "\n",
    "cpu_mem_after = measure_cpu_memory()\n",
    "gpu_mem_wsi = measure_gpu_memory()\n",
    "\n",
    "# Tile statistics\n",
    "tile_size = 512\n",
    "overlap_pixels = 64\n",
    "stride = tile_size - overlap_pixels\n",
    "n_tiles_x = int(np.ceil(wsi_5000.shape[1] / stride))\n",
    "n_tiles_y = int(np.ceil(wsi_5000.shape[0] / stride))\n",
    "total_tiles = n_tiles_x * n_tiles_y\n",
    "\n",
    "results_wsi_nuclei = {\n",
    "    'task': 'Nuclei Only',\n",
    "    'image_size': '15000√ó15000',\n",
    "    'n_tiles': total_tiles,\n",
    "    'tile_size': '512√ó512',\n",
    "    'n_instances': n_nuclei_wsi,\n",
    "    'total_time_s': elapsed_wsi,\n",
    "    'total_time_min': elapsed_wsi / 60,\n",
    "    'time_per_tile_ms': (elapsed_wsi / total_tiles) * 1000,\n",
    "    'peak_gpu_memory_gb': gpu_mem_wsi['max_allocated_gb'],\n",
    "    'instances_per_second': n_nuclei_wsi / elapsed_wsi,\n",
    "    'throughput_mpx_per_min': (15000 * 15000 / 1e6) / (elapsed_wsi / 60),\n",
    "}\n",
    "\n",
    "print(\"\\nRESULTS:\")\n",
    "for key, value in results_wsi_nuclei.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {key}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "# ============================================\n",
    "# 5. WSI BENCHMARK: Dual-Task Simulation\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚≠ê CELLSAM BENCHMARK 5: WSI DUAL-TASK SIMULATION (15000√ó15000)\")\n",
    "print(\"=\" * 70)\n",
    "print(\"Note: Running CellSAM TWICE for nuclei + cells\")\n",
    "print(\"‚è±Ô∏è  This will take even longer - please be patient...\")\n",
    "\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# RUN 1: Nuclei\n",
    "print(\"\\nüî¨ Running nuclei segmentation...\")\n",
    "start_total = time.time()\n",
    "\n",
    "start = time.time()\n",
    "mask_wsi_n = segment_wsi(\n",
    "    wsi_5000,\n",
    "    block_size=512,\n",
    "    overlap=64,\n",
    "    iou_depth=1,\n",
    "    iou_threshold=0.5,\n",
    "    model=model,\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "if hasattr(mask_wsi_n, 'compute'):\n",
    "    mask_wsi_n = mask_wsi_n.compute()\n",
    "\n",
    "# Force computation\n",
    "print(\"  Computing nuclei metrics...\")\n",
    "seg_n_wsi = compute_segmentation_metrics(mask_wsi_n)\n",
    "n_nuclei_wsi_dual = seg_n_wsi['n_cells']\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "# Save nuclei masks\n",
    "print(\"  Saving nuclei masks...\")\n",
    "save_mask(mask_wsi_n, os.path.join(MASKS_DIR, 'wsi_15000_dual_nuclei.tif'))\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "time_wsi_nuclei = time.time() - start\n",
    "print(f\"  ‚úì Nuclei complete: {time_wsi_nuclei / 60:.2f} min\")\n",
    "\n",
    "# RUN 2: Cells\n",
    "print(\"\\nüî¨ Running cell segmentation...\")\n",
    "start = time.time()\n",
    "mask_wsi_c = segment_wsi(\n",
    "    wsi_5000,\n",
    "    block_size=512,\n",
    "    overlap=64,\n",
    "    iou_depth=1,\n",
    "    iou_threshold=0.5,\n",
    "    model=model,\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "if hasattr(mask_wsi_c, 'compute'):\n",
    "    mask_wsi_c = mask_wsi_c.compute()\n",
    "\n",
    "# Force computation\n",
    "print(\"  Computing cell metrics...\")\n",
    "seg_c_wsi = compute_segmentation_metrics(mask_wsi_c)\n",
    "n_cells_wsi_dual = seg_c_wsi['n_cells']\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "# Save cell masks\n",
    "print(\"  Saving cell masks...\")\n",
    "save_mask(mask_wsi_c, os.path.join(MASKS_DIR, 'wsi_15000_dual_cells.tif'))\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "time_wsi_cells = time.time() - start\n",
    "print(f\"  ‚úì Cells complete: {time_wsi_cells / 60:.2f} min\")\n",
    "\n",
    "elapsed_wsi_dual = time.time() - start_total\n",
    "gpu_mem_wsi_dual = measure_gpu_memory()\n",
    "\n",
    "total_instances_wsi = n_nuclei_wsi_dual + n_cells_wsi_dual\n",
    "\n",
    "results_wsi_dual = {\n",
    "    'task': 'Nuclei + Cells (Sequential)',\n",
    "    'image_size': '15000√ó15000',\n",
    "    'n_tiles': total_tiles,\n",
    "    'tile_size': '512√ó512',\n",
    "    'n_nuclei': n_nuclei_wsi_dual,\n",
    "    'n_cells': n_cells_wsi_dual,\n",
    "    'total_instances': total_instances_wsi,\n",
    "    'total_time_s': elapsed_wsi_dual,\n",
    "    'total_time_min': elapsed_wsi_dual / 60,\n",
    "    'time_per_tile_ms': (elapsed_wsi_dual / total_tiles) * 1000,\n",
    "    'peak_gpu_memory_gb': gpu_mem_wsi_dual['max_allocated_gb'],\n",
    "    'instances_per_second': total_instances_wsi / elapsed_wsi_dual,\n",
    "    'throughput_mpx_per_min': (15000 * 15000 / 1e6) / (elapsed_wsi_dual / 60),\n",
    "    'overhead_vs_single_pct': ((elapsed_wsi_dual / elapsed_wsi) - 1) * 100,\n",
    "}\n",
    "\n",
    "print(\"\\nRESULTS:\")\n",
    "for key, value in results_wsi_dual.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {key}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\n‚≠ê KEY INSIGHTS:\")\n",
    "print(f\"  Single-task WSI: {elapsed_wsi / 60:.2f} min\")\n",
    "print(f\"  Dual-task WSI (2 sequential runs): {elapsed_wsi_dual / 60:.2f} min ({time_wsi_nuclei / 60:.2f} + {time_wsi_cells / 60:.2f})\")\n",
    "print(f\"  Overhead: {results_wsi_dual['overhead_vs_single_pct']:.1f}%\")\n",
    "print(f\"  üî¥ CellSAM requires 2 separate runs (no simultaneous dual-task)\")\n",
    "\n",
    "# ============================================\n",
    "# 6. COMPILE ALL RESULTS\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CELLSAM COMPREHENSIVE BENCHMARK SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "summary_df = pd.DataFrame([\n",
    "    {\n",
    "        'Test': 'Single Tile - Nuclei',\n",
    "        'Task': 'Nuclei',\n",
    "        'Size': '512√ó512',\n",
    "        'Instances': results_nuclei['n_instances'],\n",
    "        'Time (s)': results_nuclei['mean_time_s'],\n",
    "        'Memory (GB)': results_nuclei['peak_memory_gb'],\n",
    "        'Inst/sec': results_nuclei['instances_per_second'],\n",
    "    },\n",
    "    {\n",
    "        'Test': 'Single Tile - Cells',\n",
    "        'Task': 'Cells',\n",
    "        'Size': '512√ó512',\n",
    "        'Instances': results_cells['n_instances'],\n",
    "        'Time (s)': results_cells['mean_time_s'],\n",
    "        'Memory (GB)': results_cells['peak_memory_gb'],\n",
    "        'Inst/sec': results_cells['instances_per_second'],\n",
    "    },\n",
    "    {\n",
    "        'Test': 'Single Tile - DUAL',\n",
    "        'Task': 'Both (2 runs)',\n",
    "        'Size': '512√ó512',\n",
    "        'Instances': results_dual['total_instances'],\n",
    "        'Time (s)': results_dual['mean_time_s'],\n",
    "        'Memory (GB)': results_dual['peak_memory_gb'],\n",
    "        'Inst/sec': results_dual['instances_per_second'],\n",
    "    },\n",
    "    {\n",
    "        'Test': 'WSI - Nuclei',\n",
    "        'Task': 'Nuclei',\n",
    "        'Size': '15000√ó15000',\n",
    "        'Instances': results_wsi_nuclei['n_instances'],\n",
    "        'Time (s)': results_wsi_nuclei['total_time_s'],\n",
    "        'Memory (GB)': results_wsi_nuclei['peak_gpu_memory_gb'],\n",
    "        'Inst/sec': results_wsi_nuclei['instances_per_second'],\n",
    "    },\n",
    "    {\n",
    "        'Test': 'WSI - DUAL',\n",
    "        'Task': 'Both (2 runs)',\n",
    "        'Size': '15000√ó15000',\n",
    "        'Instances': results_wsi_dual['total_instances'],\n",
    "        'Time (s)': results_wsi_dual['total_time_s'],\n",
    "        'Memory (GB)': results_wsi_dual['peak_gpu_memory_gb'],\n",
    "        'Inst/sec': results_wsi_dual['instances_per_second'],\n",
    "    }\n",
    "])\n",
    "\n",
    "print(\"\\n\" + summary_df.to_string(index=False))\n",
    "\n",
    "# ============================================\n",
    "# 7. SAVE ALL RESULTS\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SAVING RESULTS...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Save CSV\n",
    "csv_path = os.path.join(OUTPUT_DIR, 'cellsam_benchmark_summary.csv')\n",
    "summary_df.to_csv(csv_path, index=False)\n",
    "print(f\"‚úì Saved CSV: {csv_path}\")\n",
    "\n",
    "# Save JSON\n",
    "all_results = {\n",
    "    'single_tile_nuclei': results_nuclei,\n",
    "    'single_tile_cells': results_cells,\n",
    "    'single_tile_dual': results_dual,\n",
    "    'wsi_nuclei': results_wsi_nuclei,\n",
    "    'wsi_dual': results_wsi_dual,\n",
    "    'hardware': {\n",
    "        'gpu': torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'N/A',\n",
    "        'gpu_memory_total_gb': torch.cuda.get_device_properties(0).total_memory / 1024**3 if torch.cuda.is_available() else 0,\n",
    "    },\n",
    "    'benchmark_date': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "}\n",
    "\n",
    "json_path = os.path.join(OUTPUT_DIR, 'cellsam_benchmark_complete.json')\n",
    "with open(json_path, 'w') as f:\n",
    "    json.dump(all_results, f, indent=2)\n",
    "print(f\"‚úì Saved JSON: {json_path}\")\n",
    "\n",
    "# ============================================\n",
    "# 8. VISUALIZATION\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nGenerating plots...\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: Single Tile Comparison\n",
    "tasks = ['Nuclei\\nOnly', 'Cells\\nOnly', 'Both\\n(2 runs)']\n",
    "times = [results_nuclei['mean_time_ms'], results_cells['mean_time_ms'], results_dual['mean_time_ms']]\n",
    "axes[0, 0].bar(tasks, times, color=['steelblue', 'coral', 'red'])\n",
    "axes[0, 0].set_ylabel('Time (ms)', fontsize=12)\n",
    "axes[0, 0].set_title('Single Tile Processing Time (512√ó512)', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 2: WSI Comparison\n",
    "wsi_tasks = ['Nuclei\\nOnly', 'Both\\n(2 runs)']\n",
    "wsi_times = [\n",
    "    results_wsi_nuclei['total_time_min'],\n",
    "    results_wsi_dual['total_time_min']\n",
    "]\n",
    "axes[0, 1].bar(wsi_tasks, wsi_times, color=['steelblue', 'red'])\n",
    "axes[0, 1].set_ylabel('Time (minutes)', fontsize=12)\n",
    "axes[0, 1].set_title('WSI Processing Time (15000√ó15000)', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 3: Throughput\n",
    "throughputs = [\n",
    "    results_nuclei['instances_per_second'],\n",
    "    results_cells['instances_per_second'],\n",
    "    results_dual['instances_per_second']\n",
    "]\n",
    "axes[1, 0].bar(tasks, throughputs, color=['steelblue', 'coral', 'red'])\n",
    "axes[1, 0].set_ylabel('Instances/Second', fontsize=12)\n",
    "axes[1, 0].set_title('Segmentation Throughput', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 4: Memory Usage\n",
    "memory_vals = [\n",
    "    results_nuclei['peak_memory_gb'],\n",
    "    results_cells['peak_memory_gb'],\n",
    "    results_dual['peak_memory_gb']\n",
    "]\n",
    "axes[1, 1].bar(tasks, memory_vals, color=['steelblue', 'coral', 'red'])\n",
    "axes[1, 1].set_ylabel('Peak GPU Memory (GB)', fontsize=12)\n",
    "axes[1, 1].set_title('Memory Usage', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plot_path = os.path.join(OUTPUT_DIR, 'cellsam_benchmark_plots.png')\n",
    "plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"‚úì Saved plot: {plot_path}\")\n",
    "plt.close()\n",
    "\n",
    "# ============================================\n",
    "# 9. LIST SAVED MASK FILES\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nüìÅ Saved mask files:\")\n",
    "mask_files = sorted([f for f in os.listdir(MASKS_DIR) if f.endswith('.tif')])\n",
    "for mf in mask_files:\n",
    "    size_mb = os.path.getsize(os.path.join(MASKS_DIR, mf)) / (1024**2)\n",
    "    print(f\"  - {mf} ({size_mb:.2f} MB)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"BENCHMARK COMPLETE!\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nüìÅ All results saved to: {os.path.abspath(OUTPUT_DIR)}\")\n",
    "print(\"\\n‚≠ê KEY FINDINGS:\")\n",
    "print(f\"  Single Tile - Nuclei: {results_nuclei['mean_time_ms']:.1f} ms\")\n",
    "print(f\"  Single Tile - Dual (2 runs): {results_dual['mean_time_ms']:.1f} ms\")\n",
    "print(f\"  WSI - Nuclei: {results_wsi_nuclei['total_time_min']:.2f} min\")\n",
    "print(f\"  WSI - Dual (2 runs): {results_wsi_dual['total_time_min']:.2f} min\")\n",
    "print(f\"  üî¥ CellSAM requires 2 separate runs for nuclei + cells\")\n",
    "print(\"\\nüìä Files created:\")\n",
    "print(f\"  - {os.path.basename(csv_path)}\")\n",
    "print(f\"  - {os.path.basename(json_path)}\")\n",
    "print(f\"  - {os.path.basename(plot_path)}\")\n",
    "print(f\"  - masks/ folder with {len(mask_files)} segmentation outputs\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yshokrollahi (py3.11.0rc1)",
   "language": "python",
   "name": "yshokrollahi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
